{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad M2.5\n",
    "\n",
    "### Diego Alberto Baños Lopez A01275100\n",
    "\n",
    "## Resumen\n",
    "\n",
    "En este reporte, se exploran diferentes arquitecturas e hiperparámetros de Redes Neuronales Convolucionales (CNNs) para la clasificación de imágenes utilizando el conjunto de datos CIFAR-10. Se implementa un modelo CNN base y se realizan experimentos variando la arquitectura e hiperparámetros para analizar su impacto en el rendimiento. Los resultados muestran que agregar más capas convolucionales, aumentar el número de filtros y ajustar hiperparámetros como la tasa de aprendizaje, el tamaño de lote y el número de épocas, permite mejorar significativamente la precisión del modelo base. Este trabajo demuestra la importancia de explorar diferentes configuraciones en las CNNs para obtener un buen desempeño en tareas de clasificación de imágenes.\n",
    "\n",
    "\n",
    "## Introducción\n",
    "Las Redes Neuronales Convolucionales (CNNs) han demostrado ser muy efectivas en tareas de visión por computadora, especialmente en la clasificación de imágenes. Su capacidad para aprender características jerárquicas directamente de los datos las hace muy adecuadas para procesar imágenes.\n",
    "En este trabajo, se explora el impacto de diferentes arquitecturas e hiperparámetros en el rendimiento de las CNNs utilizando el conjunto de datos CIFAR-10 y usando el framework de Tensorflow. Se parte de un modelo CNN base y se realizan experimentos variando componentes como el número de capas convolucionales, número de filtros, capas de dropout, así como hiperparámetros como la tasa de aprendizaje, tamaño de lote y número de épocas. El objetivo es analizar cómo estos cambios afectan la capacidad del modelo para clasificar correctamente las imágenes.\n",
    "\n",
    "## Metodología\n",
    "\n",
    "### 1. Uso de la GPU\n",
    "Primeramente, el autor de este reporte descubrio que Tensorflow puede trabajar de forma más eficiente si puede hacer uso de la GPU, asi que verificamos si el framework anteriormente mencionado detecta el dispositivo, que en este caso es una RTX 3070, cabe recalcar que este paso no es obligatorio y simplemente ayuda a realizar con mayor rapidez los modelos de este reporte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-11 02:03:35.096039: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-11 02:03:35.633251: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "2.16.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-11 02:03:36.121436: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-11 02:03:36.140988: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-11 02:03:36.141173: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "#Checamos si podemos usar la GPU\n",
    "# !pip install --upgrade pip\n",
    "# !pip install 'tensorflow[and-cuda]'\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "print(\"Num GPUs Available: \" , len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Conjunto de datos\n",
    "Se utiliza el conjunto de datos CIFAR-10, que consiste en 60 000 imágenes a color de 32x32 píxeles, divididas en 10 clases: avión, automóvil, pájaro, gato, ciervo, perro, rana, caballo, barco y camión. Hay 50 000 imágenes de entrenamiento y 10 000 imágenes de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide los datos en donde X son las imagenes del dataset y Y son las etiquetas de entrenamiento para las imagenes\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# !pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Imprimir la imagen seleccionada\n",
    "plt.imshow(x_train[51])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de datos en x_train:  50000\n",
      "Numero de datos en y_train:  50000\n",
      "Numero de datos en x_test:  10000\n",
      "Numero de datos en y_test:  10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Numero de datos en x_train: \", len(x_train))\n",
    "print(\"Numero de datos en y_train: \", len(y_train))\n",
    "print(\"Numero de datos en x_test: \", len(x_test))\n",
    "print(\"Numero de datos en y_test: \", len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preprocesamiento\n",
    "\n",
    "Las imágenes se normalizan dividiendo los valores de píxeles entre 255 para escalarlos al rango. Además, las etiquetas se codifican en one-hot encoding para ser compatibles con la capa de salida softmax del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar los datos de entrada\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# Convertir las etiquetas a one-hot encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Modelo base\n",
    "El modelo base consiste en la siguiente arquitectura:\n",
    "- Capa convolucional con 32 filtros de 3x3 y activación ReLU\n",
    "- Capa de max pooling de 2x2\n",
    "- Capa flatten\n",
    "- Capa densa con 128 unidades y activación ReLU\n",
    "- Capa de salida densa con activación softmax\n",
    "\n",
    "El modelo se compila utilizando el optimizador Adam, la función de pérdida categorical crossentropy y se mide la precisión como métrica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/upijijis/.conda/envs/MLenv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-05-11 02:03:36.364929: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-11 02:03:36.365117: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-11 02:03:36.365232: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-11 02:03:36.418361: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-11 02:03:36.418515: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-11 02:03:36.418640: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-11 02:03:36.418744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5464 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:09:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Definir el modelo base de CNN\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentos\n",
    "\n",
    "### Experimento 1: Modelo base\n",
    "El modelo base se entrena por 10 épocas con un tamaño de lote de 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-11 02:03:37.011021: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 614400000 exceeds 10% of free system memory.\n",
      "2024-05-11 02:03:37.137180: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 614400000 exceeds 10% of free system memory.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1715414617.773692   74435 service.cc:145] XLA service 0x7752e0004ca0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1715414617.773756   74435 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 3070, Compute Capability 8.6\n",
      "2024-05-11 02:03:37.794273: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-05-11 02:03:37.880218: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 84/391\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2239 - loss: 2.1285"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1715414619.872896   74435 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m361/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3391 - loss: 1.8289"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1715414621.614706   74544 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_222', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.3458 - loss: 1.8116 - val_accuracy: 0.5053 - val_loss: 1.3696\n",
      "Epoch 2/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5390 - loss: 1.3118 - val_accuracy: 0.5709 - val_loss: 1.2298\n",
      "Epoch 3/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5953 - loss: 1.1626 - val_accuracy: 0.5896 - val_loss: 1.1685\n",
      "Epoch 4/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6231 - loss: 1.0735 - val_accuracy: 0.6074 - val_loss: 1.1147\n",
      "Epoch 5/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6444 - loss: 1.0164 - val_accuracy: 0.6104 - val_loss: 1.1057\n",
      "Epoch 6/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6638 - loss: 0.9648 - val_accuracy: 0.6356 - val_loss: 1.0502\n",
      "Epoch 7/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6816 - loss: 0.9187 - val_accuracy: 0.6262 - val_loss: 1.0896\n",
      "Epoch 8/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6922 - loss: 0.8827 - val_accuracy: 0.6304 - val_loss: 1.0698\n",
      "Epoch 9/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7118 - loss: 0.8376 - val_accuracy: 0.6511 - val_loss: 1.0089\n",
      "Epoch 10/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7259 - loss: 0.8002 - val_accuracy: 0.6568 - val_loss: 1.0102\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "history = model.fit(x_train, y_train, \n",
    "                    batch_size=128, epochs=10, \n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 767us/step - accuracy: 0.6643 - loss: 0.9884\n",
      "Test accuracy: 0.6567999720573425\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en el conjunto de test\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez completado la evaluación se obtiene una precisión de 65.68% en el conjunto de prueba, indicando que el modelo base puede predecir mas de la mitad de los datos de prueba de manera correcta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento 2: Cambio de arquitectura\n",
    "Se modifica la arquitectura base agregando más capas convolucionales, aumentando el número de filtros y agregando una capa de dropout:[^25^][25]\n",
    "- Conv2D con 32 filtros de 3x3 y activación ReLU\n",
    "- Conv2D con 64 filtros de 3x3 y activación ReLU\n",
    "- MaxPooling de 2x2\n",
    "- Conv2D con 64 filtros de 3x3 y activación ReLU\n",
    "- MaxPooling de 2x2\n",
    "- Conv2D con 64 filtros de 3x3 y activación ReLU\n",
    "- Flatten\n",
    "- Dense con 64 unidades y activación ReLU\n",
    "- Dropout con tasa de 0.5\n",
    "- Dense de salida con activación softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir un modelo modificado de CNN\n",
    "model_v2 = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-11 02:03:51.368667: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 614400000 exceeds 10% of free system memory.\n",
      "2024-05-11 02:03:51.496583: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 614400000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.2534 - loss: 1.9949 - val_accuracy: 0.5068 - val_loss: 1.3608\n",
      "Epoch 2/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4819 - loss: 1.4412 - val_accuracy: 0.5666 - val_loss: 1.2127\n",
      "Epoch 3/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5508 - loss: 1.2608 - val_accuracy: 0.6097 - val_loss: 1.0784\n",
      "Epoch 4/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5922 - loss: 1.1457 - val_accuracy: 0.6513 - val_loss: 0.9765\n",
      "Epoch 5/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6230 - loss: 1.0701 - val_accuracy: 0.6659 - val_loss: 0.9638\n",
      "Epoch 6/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6547 - loss: 0.9846 - val_accuracy: 0.6903 - val_loss: 0.8851\n",
      "Epoch 7/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6773 - loss: 0.9286 - val_accuracy: 0.6981 - val_loss: 0.8593\n",
      "Epoch 8/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6920 - loss: 0.8816 - val_accuracy: 0.7141 - val_loss: 0.8127\n",
      "Epoch 9/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7062 - loss: 0.8424 - val_accuracy: 0.7122 - val_loss: 0.8130\n",
      "Epoch 10/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7234 - loss: 0.8003 - val_accuracy: 0.7296 - val_loss: 0.7769\n"
     ]
    }
   ],
   "source": [
    "# Compilar y entrenar el modelo modificado\n",
    "model_v2.compile(optimizer='adam',\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "history_v2 = model_v2.fit(x_train, y_train, \n",
    "                          batch_size=128, epochs=10, \n",
    "                          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 951us/step - accuracy: 0.7288 - loss: 0.7646\n",
      "Test accuracy (modelo modificado): 0.7296000123023987\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo modificado en el conjunto de test\n",
    "test_loss_v2, test_acc_v2 = model_v2.evaluate(x_test, y_test)\n",
    "print('Test accuracy (modelo modificado):', test_acc_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con las modificaciones al modelo se logra una precisión de 72.96% en el conjunto de prueba, mejorando en más de 7 puntos porcentuales al modelo base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento 3: Ajuste de hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando las bases del modelo modificado se exploran diferentes valores para la tasa de aprendizaje (0.1, 0.01, 0.001, 0.0001), tamaño de lote (32, 64, 128, 256) y número de épocas (10, 20, 30, 50). Se evalua cada uno para asi determinar cual es la mejor configuración de hiperparametros para entrenar el modelo anteriormente mencionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el modelo con hiperparámetros variables\n",
    "def create_model(learning_rate):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los valores de los hiperparámetros a explorar\n",
    "learning_rates = [0.0001,0.001, 0.01, 0.1]\n",
    "batch_sizes = [32, 64, 128, 256]\n",
    "epochs = [10, 20, 30, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-11 02:04:17.138667: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 614400000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.2191 - loss: 2.0755 - val_accuracy: 0.4131 - val_loss: 1.6405\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3763 - loss: 1.6981 - val_accuracy: 0.4806 - val_loss: 1.4489\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4286 - loss: 1.5636 - val_accuracy: 0.5251 - val_loss: 1.3414\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4797 - loss: 1.4460 - val_accuracy: 0.5544 - val_loss: 1.2638\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5084 - loss: 1.3771 - val_accuracy: 0.5825 - val_loss: 1.1983\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5262 - loss: 1.3143 - val_accuracy: 0.5950 - val_loss: 1.1477\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5490 - loss: 1.2699 - val_accuracy: 0.6119 - val_loss: 1.1072\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5784 - loss: 1.2064 - val_accuracy: 0.6153 - val_loss: 1.1000\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5891 - loss: 1.1654 - val_accuracy: 0.6356 - val_loss: 1.0356\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6032 - loss: 1.1324 - val_accuracy: 0.6514 - val_loss: 0.9927\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.6517 - loss: 0.9838\n",
      "Epoch 1/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.2056 - loss: 2.1039 - val_accuracy: 0.4289 - val_loss: 1.6004\n",
      "Epoch 2/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3852 - loss: 1.6776 - val_accuracy: 0.4929 - val_loss: 1.4246\n",
      "Epoch 3/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4402 - loss: 1.5344 - val_accuracy: 0.5180 - val_loss: 1.3360\n",
      "Epoch 4/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4841 - loss: 1.4360 - val_accuracy: 0.5499 - val_loss: 1.2755\n",
      "Epoch 5/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5095 - loss: 1.3713 - val_accuracy: 0.5722 - val_loss: 1.2088\n",
      "Epoch 6/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5359 - loss: 1.3153 - val_accuracy: 0.5930 - val_loss: 1.1512\n",
      "Epoch 7/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5555 - loss: 1.2661 - val_accuracy: 0.6091 - val_loss: 1.1071\n",
      "Epoch 8/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5698 - loss: 1.2198 - val_accuracy: 0.6180 - val_loss: 1.0814\n",
      "Epoch 9/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5897 - loss: 1.1697 - val_accuracy: 0.6376 - val_loss: 1.0321\n",
      "Epoch 10/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6054 - loss: 1.1383 - val_accuracy: 0.6358 - val_loss: 1.0192\n",
      "Epoch 11/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6128 - loss: 1.1063 - val_accuracy: 0.6608 - val_loss: 0.9668\n",
      "Epoch 12/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6222 - loss: 1.0743 - val_accuracy: 0.6646 - val_loss: 0.9510\n",
      "Epoch 13/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6338 - loss: 1.0475 - val_accuracy: 0.6707 - val_loss: 0.9337\n",
      "Epoch 14/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6477 - loss: 1.0163 - val_accuracy: 0.6785 - val_loss: 0.9227\n",
      "Epoch 15/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6527 - loss: 0.9909 - val_accuracy: 0.6883 - val_loss: 0.8978\n",
      "Epoch 16/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6661 - loss: 0.9621 - val_accuracy: 0.6952 - val_loss: 0.8937\n",
      "Epoch 17/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6672 - loss: 0.9475 - val_accuracy: 0.7045 - val_loss: 0.8494\n",
      "Epoch 18/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6816 - loss: 0.9183 - val_accuracy: 0.7090 - val_loss: 0.8452\n",
      "Epoch 19/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6905 - loss: 0.9031 - val_accuracy: 0.7114 - val_loss: 0.8231\n",
      "Epoch 20/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6954 - loss: 0.8829 - val_accuracy: 0.7198 - val_loss: 0.8211\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.7207 - loss: 0.8117\n",
      "Epoch 1/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.2054 - loss: 2.1014 - val_accuracy: 0.4312 - val_loss: 1.6086\n",
      "Epoch 2/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3917 - loss: 1.6763 - val_accuracy: 0.4938 - val_loss: 1.4375\n",
      "Epoch 3/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4444 - loss: 1.5415 - val_accuracy: 0.5159 - val_loss: 1.3545\n",
      "Epoch 4/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4737 - loss: 1.4653 - val_accuracy: 0.5410 - val_loss: 1.2945\n",
      "Epoch 5/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4995 - loss: 1.4048 - val_accuracy: 0.5551 - val_loss: 1.2633\n",
      "Epoch 6/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5278 - loss: 1.3370 - val_accuracy: 0.5877 - val_loss: 1.1750\n",
      "Epoch 7/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5461 - loss: 1.2901 - val_accuracy: 0.6026 - val_loss: 1.1228\n",
      "Epoch 8/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5613 - loss: 1.2412 - val_accuracy: 0.6115 - val_loss: 1.1016\n",
      "Epoch 9/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5738 - loss: 1.2018 - val_accuracy: 0.6320 - val_loss: 1.0430\n",
      "Epoch 10/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5976 - loss: 1.1560 - val_accuracy: 0.6352 - val_loss: 1.0265\n",
      "Epoch 11/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6077 - loss: 1.1237 - val_accuracy: 0.6472 - val_loss: 1.0074\n",
      "Epoch 12/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6156 - loss: 1.0966 - val_accuracy: 0.6551 - val_loss: 0.9759\n",
      "Epoch 13/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6239 - loss: 1.0767 - val_accuracy: 0.6691 - val_loss: 0.9379\n",
      "Epoch 14/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6366 - loss: 1.0424 - val_accuracy: 0.6720 - val_loss: 0.9343\n",
      "Epoch 15/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6488 - loss: 1.0153 - val_accuracy: 0.6762 - val_loss: 0.9138\n",
      "Epoch 16/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6520 - loss: 0.9959 - val_accuracy: 0.6831 - val_loss: 0.8998\n",
      "Epoch 17/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6611 - loss: 0.9709 - val_accuracy: 0.6923 - val_loss: 0.8739\n",
      "Epoch 18/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6719 - loss: 0.9469 - val_accuracy: 0.6914 - val_loss: 0.8665\n",
      "Epoch 19/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6794 - loss: 0.9226 - val_accuracy: 0.7000 - val_loss: 0.8522\n",
      "Epoch 20/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6888 - loss: 0.8964 - val_accuracy: 0.7095 - val_loss: 0.8281\n",
      "Epoch 21/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6872 - loss: 0.8906 - val_accuracy: 0.7076 - val_loss: 0.8159\n",
      "Epoch 22/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6972 - loss: 0.8642 - val_accuracy: 0.7144 - val_loss: 0.8064\n",
      "Epoch 23/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7052 - loss: 0.8509 - val_accuracy: 0.7172 - val_loss: 0.7959\n",
      "Epoch 24/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7077 - loss: 0.8364 - val_accuracy: 0.7184 - val_loss: 0.7962\n",
      "Epoch 25/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7122 - loss: 0.8233 - val_accuracy: 0.7244 - val_loss: 0.7767\n",
      "Epoch 26/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7155 - loss: 0.8166 - val_accuracy: 0.7255 - val_loss: 0.7805\n",
      "Epoch 27/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7249 - loss: 0.7978 - val_accuracy: 0.7272 - val_loss: 0.7813\n",
      "Epoch 28/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7310 - loss: 0.7747 - val_accuracy: 0.7318 - val_loss: 0.7580\n",
      "Epoch 29/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7287 - loss: 0.7748 - val_accuracy: 0.7251 - val_loss: 0.7813\n",
      "Epoch 30/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7351 - loss: 0.7615 - val_accuracy: 0.7376 - val_loss: 0.7479\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.7416 - loss: 0.7392\n",
      "Epoch 1/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.2147 - loss: 2.1000 - val_accuracy: 0.4287 - val_loss: 1.6050\n",
      "Epoch 2/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3859 - loss: 1.6891 - val_accuracy: 0.4926 - val_loss: 1.4269\n",
      "Epoch 3/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4504 - loss: 1.5247 - val_accuracy: 0.5218 - val_loss: 1.3451\n",
      "Epoch 4/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4903 - loss: 1.4357 - val_accuracy: 0.5577 - val_loss: 1.2519\n",
      "Epoch 5/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5182 - loss: 1.3568 - val_accuracy: 0.5860 - val_loss: 1.1832\n",
      "Epoch 6/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5392 - loss: 1.2978 - val_accuracy: 0.5917 - val_loss: 1.1486\n",
      "Epoch 7/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5661 - loss: 1.2316 - val_accuracy: 0.6272 - val_loss: 1.0704\n",
      "Epoch 8/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5832 - loss: 1.1843 - val_accuracy: 0.5901 - val_loss: 1.1382\n",
      "Epoch 9/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6034 - loss: 1.1334 - val_accuracy: 0.6272 - val_loss: 1.0434\n",
      "Epoch 10/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6152 - loss: 1.1068 - val_accuracy: 0.6624 - val_loss: 0.9733\n",
      "Epoch 11/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6231 - loss: 1.0724 - val_accuracy: 0.6653 - val_loss: 0.9551\n",
      "Epoch 12/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6384 - loss: 1.0375 - val_accuracy: 0.6733 - val_loss: 0.9410\n",
      "Epoch 13/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6468 - loss: 1.0116 - val_accuracy: 0.6872 - val_loss: 0.8984\n",
      "Epoch 14/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6624 - loss: 0.9795 - val_accuracy: 0.6912 - val_loss: 0.8847\n",
      "Epoch 15/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6661 - loss: 0.9593 - val_accuracy: 0.6916 - val_loss: 0.8844\n",
      "Epoch 16/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6807 - loss: 0.9252 - val_accuracy: 0.6981 - val_loss: 0.8606\n",
      "Epoch 17/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6849 - loss: 0.9033 - val_accuracy: 0.6984 - val_loss: 0.8508\n",
      "Epoch 18/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6918 - loss: 0.8923 - val_accuracy: 0.7092 - val_loss: 0.8264\n",
      "Epoch 19/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6950 - loss: 0.8776 - val_accuracy: 0.7128 - val_loss: 0.8205\n",
      "Epoch 20/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7068 - loss: 0.8489 - val_accuracy: 0.7160 - val_loss: 0.8119\n",
      "Epoch 21/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7084 - loss: 0.8428 - val_accuracy: 0.7212 - val_loss: 0.8025\n",
      "Epoch 22/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7151 - loss: 0.8277 - val_accuracy: 0.7256 - val_loss: 0.7869\n",
      "Epoch 23/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7183 - loss: 0.8139 - val_accuracy: 0.7302 - val_loss: 0.7820\n",
      "Epoch 24/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7273 - loss: 0.7978 - val_accuracy: 0.7346 - val_loss: 0.7727\n",
      "Epoch 25/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7295 - loss: 0.7791 - val_accuracy: 0.7364 - val_loss: 0.7641\n",
      "Epoch 26/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7380 - loss: 0.7640 - val_accuracy: 0.7353 - val_loss: 0.7543\n",
      "Epoch 27/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7363 - loss: 0.7621 - val_accuracy: 0.7421 - val_loss: 0.7373\n",
      "Epoch 28/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7475 - loss: 0.7300 - val_accuracy: 0.7373 - val_loss: 0.7622\n",
      "Epoch 29/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7507 - loss: 0.7256 - val_accuracy: 0.7453 - val_loss: 0.7359\n",
      "Epoch 30/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7506 - loss: 0.7232 - val_accuracy: 0.7465 - val_loss: 0.7434\n",
      "Epoch 31/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7553 - loss: 0.7107 - val_accuracy: 0.7502 - val_loss: 0.7248\n",
      "Epoch 32/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7616 - loss: 0.6906 - val_accuracy: 0.7519 - val_loss: 0.7225\n",
      "Epoch 33/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7671 - loss: 0.6764 - val_accuracy: 0.7475 - val_loss: 0.7248\n",
      "Epoch 34/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7718 - loss: 0.6675 - val_accuracy: 0.7513 - val_loss: 0.7202\n",
      "Epoch 35/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7743 - loss: 0.6605 - val_accuracy: 0.7461 - val_loss: 0.7366\n",
      "Epoch 36/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7718 - loss: 0.6527 - val_accuracy: 0.7523 - val_loss: 0.7283\n",
      "Epoch 37/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7759 - loss: 0.6522 - val_accuracy: 0.7546 - val_loss: 0.7141\n",
      "Epoch 38/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7810 - loss: 0.6319 - val_accuracy: 0.7530 - val_loss: 0.7169\n",
      "Epoch 39/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7801 - loss: 0.6244 - val_accuracy: 0.7529 - val_loss: 0.7171\n",
      "Epoch 40/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7847 - loss: 0.6162 - val_accuracy: 0.7604 - val_loss: 0.6925\n",
      "Epoch 41/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7880 - loss: 0.6070 - val_accuracy: 0.7558 - val_loss: 0.7120\n",
      "Epoch 42/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7913 - loss: 0.5987 - val_accuracy: 0.7627 - val_loss: 0.7094\n",
      "Epoch 43/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7888 - loss: 0.5899 - val_accuracy: 0.7604 - val_loss: 0.6979\n",
      "Epoch 44/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7966 - loss: 0.5778 - val_accuracy: 0.7593 - val_loss: 0.7108\n",
      "Epoch 45/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8019 - loss: 0.5700 - val_accuracy: 0.7619 - val_loss: 0.7012\n",
      "Epoch 46/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8048 - loss: 0.5607 - val_accuracy: 0.7639 - val_loss: 0.7008\n",
      "Epoch 47/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8078 - loss: 0.5515 - val_accuracy: 0.7617 - val_loss: 0.7067\n",
      "Epoch 48/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8069 - loss: 0.5488 - val_accuracy: 0.7676 - val_loss: 0.7056\n",
      "Epoch 49/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8127 - loss: 0.5288 - val_accuracy: 0.7625 - val_loss: 0.7054\n",
      "Epoch 50/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8133 - loss: 0.5333 - val_accuracy: 0.7624 - val_loss: 0.7249\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.7646 - loss: 0.7199\n",
      "Epoch 1/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1885 - loss: 2.1528 - val_accuracy: 0.4023 - val_loss: 1.6781\n",
      "Epoch 2/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3708 - loss: 1.7159 - val_accuracy: 0.4736 - val_loss: 1.4863\n",
      "Epoch 3/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4240 - loss: 1.5898 - val_accuracy: 0.5050 - val_loss: 1.3996\n",
      "Epoch 4/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4519 - loss: 1.5093 - val_accuracy: 0.5171 - val_loss: 1.3352\n",
      "Epoch 5/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4762 - loss: 1.4477 - val_accuracy: 0.5450 - val_loss: 1.2828\n",
      "Epoch 6/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5005 - loss: 1.3934 - val_accuracy: 0.5652 - val_loss: 1.2403\n",
      "Epoch 7/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5199 - loss: 1.3571 - val_accuracy: 0.5658 - val_loss: 1.2179\n",
      "Epoch 8/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5324 - loss: 1.3140 - val_accuracy: 0.5838 - val_loss: 1.1743\n",
      "Epoch 9/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5464 - loss: 1.2844 - val_accuracy: 0.5863 - val_loss: 1.1547\n",
      "Epoch 10/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5558 - loss: 1.2518 - val_accuracy: 0.6027 - val_loss: 1.1408\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 983us/step - accuracy: 0.6031 - loss: 1.1306\n",
      "Epoch 1/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.1923 - loss: 2.1425 - val_accuracy: 0.3918 - val_loss: 1.7100\n",
      "Epoch 2/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3534 - loss: 1.7682 - val_accuracy: 0.4576 - val_loss: 1.5187\n",
      "Epoch 3/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4008 - loss: 1.6353 - val_accuracy: 0.4920 - val_loss: 1.4367\n",
      "Epoch 4/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4319 - loss: 1.5561 - val_accuracy: 0.5046 - val_loss: 1.3882\n",
      "Epoch 5/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4629 - loss: 1.4826 - val_accuracy: 0.5196 - val_loss: 1.3493\n",
      "Epoch 6/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4863 - loss: 1.4291 - val_accuracy: 0.5517 - val_loss: 1.2620\n",
      "Epoch 7/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5008 - loss: 1.3964 - val_accuracy: 0.5502 - val_loss: 1.2772\n",
      "Epoch 8/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5125 - loss: 1.3559 - val_accuracy: 0.5764 - val_loss: 1.1992\n",
      "Epoch 9/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5350 - loss: 1.3020 - val_accuracy: 0.5870 - val_loss: 1.1951\n",
      "Epoch 10/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5517 - loss: 1.2582 - val_accuracy: 0.6066 - val_loss: 1.1274\n",
      "Epoch 11/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5568 - loss: 1.2397 - val_accuracy: 0.5855 - val_loss: 1.1559\n",
      "Epoch 12/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5702 - loss: 1.2173 - val_accuracy: 0.6200 - val_loss: 1.0857\n",
      "Epoch 13/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5859 - loss: 1.1801 - val_accuracy: 0.6290 - val_loss: 1.0611\n",
      "Epoch 14/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5934 - loss: 1.1583 - val_accuracy: 0.6357 - val_loss: 1.0415\n",
      "Epoch 15/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5961 - loss: 1.1373 - val_accuracy: 0.6392 - val_loss: 1.0320\n",
      "Epoch 16/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6060 - loss: 1.1254 - val_accuracy: 0.6487 - val_loss: 1.0031\n",
      "Epoch 17/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6135 - loss: 1.0853 - val_accuracy: 0.6572 - val_loss: 0.9814\n",
      "Epoch 18/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6259 - loss: 1.0711 - val_accuracy: 0.6523 - val_loss: 0.9855\n",
      "Epoch 19/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6325 - loss: 1.0475 - val_accuracy: 0.6522 - val_loss: 0.9906\n",
      "Epoch 20/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6352 - loss: 1.0362 - val_accuracy: 0.6693 - val_loss: 0.9548\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 0.6727 - loss: 0.9469\n",
      "Epoch 1/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.2098 - loss: 2.1054 - val_accuracy: 0.4150 - val_loss: 1.6743\n",
      "Epoch 2/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3727 - loss: 1.7185 - val_accuracy: 0.4696 - val_loss: 1.4844\n",
      "Epoch 3/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4259 - loss: 1.5816 - val_accuracy: 0.4818 - val_loss: 1.4615\n",
      "Epoch 4/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4572 - loss: 1.4978 - val_accuracy: 0.5272 - val_loss: 1.3156\n",
      "Epoch 5/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4881 - loss: 1.4240 - val_accuracy: 0.5445 - val_loss: 1.2656\n",
      "Epoch 6/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5083 - loss: 1.3600 - val_accuracy: 0.5773 - val_loss: 1.1977\n",
      "Epoch 7/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5351 - loss: 1.2965 - val_accuracy: 0.5954 - val_loss: 1.1582\n",
      "Epoch 8/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5486 - loss: 1.2663 - val_accuracy: 0.5985 - val_loss: 1.1313\n",
      "Epoch 9/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5651 - loss: 1.2236 - val_accuracy: 0.6203 - val_loss: 1.0929\n",
      "Epoch 10/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5831 - loss: 1.1800 - val_accuracy: 0.6306 - val_loss: 1.0574\n",
      "Epoch 11/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5978 - loss: 1.1413 - val_accuracy: 0.6381 - val_loss: 1.0401\n",
      "Epoch 12/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6003 - loss: 1.1324 - val_accuracy: 0.6330 - val_loss: 1.0295\n",
      "Epoch 13/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6114 - loss: 1.1046 - val_accuracy: 0.6437 - val_loss: 1.0137\n",
      "Epoch 14/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6272 - loss: 1.0669 - val_accuracy: 0.6600 - val_loss: 0.9726\n",
      "Epoch 15/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6265 - loss: 1.0601 - val_accuracy: 0.6513 - val_loss: 0.9968\n",
      "Epoch 16/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6328 - loss: 1.0425 - val_accuracy: 0.6709 - val_loss: 0.9409\n",
      "Epoch 17/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6408 - loss: 1.0229 - val_accuracy: 0.6541 - val_loss: 0.9767\n",
      "Epoch 18/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6493 - loss: 1.0002 - val_accuracy: 0.6707 - val_loss: 0.9351\n",
      "Epoch 19/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6552 - loss: 0.9941 - val_accuracy: 0.6830 - val_loss: 0.8993\n",
      "Epoch 20/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6624 - loss: 0.9644 - val_accuracy: 0.6911 - val_loss: 0.8813\n",
      "Epoch 21/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6682 - loss: 0.9544 - val_accuracy: 0.6984 - val_loss: 0.8697\n",
      "Epoch 22/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6715 - loss: 0.9461 - val_accuracy: 0.7010 - val_loss: 0.8640\n",
      "Epoch 23/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6823 - loss: 0.9200 - val_accuracy: 0.7056 - val_loss: 0.8531\n",
      "Epoch 24/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6891 - loss: 0.8892 - val_accuracy: 0.6940 - val_loss: 0.8706\n",
      "Epoch 25/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6893 - loss: 0.9056 - val_accuracy: 0.7079 - val_loss: 0.8335\n",
      "Epoch 26/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6950 - loss: 0.8743 - val_accuracy: 0.7068 - val_loss: 0.8250\n",
      "Epoch 27/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6982 - loss: 0.8747 - val_accuracy: 0.7097 - val_loss: 0.8308\n",
      "Epoch 28/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6987 - loss: 0.8671 - val_accuracy: 0.7071 - val_loss: 0.8348\n",
      "Epoch 29/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7073 - loss: 0.8369 - val_accuracy: 0.7159 - val_loss: 0.8107\n",
      "Epoch 30/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7096 - loss: 0.8360 - val_accuracy: 0.7155 - val_loss: 0.8089\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7222 - loss: 0.7940\n",
      "Epoch 1/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.1858 - loss: 2.1493 - val_accuracy: 0.4109 - val_loss: 1.7058\n",
      "Epoch 2/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3581 - loss: 1.7582 - val_accuracy: 0.4583 - val_loss: 1.5251\n",
      "Epoch 3/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4196 - loss: 1.6057 - val_accuracy: 0.5004 - val_loss: 1.4076\n",
      "Epoch 4/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4504 - loss: 1.5205 - val_accuracy: 0.5297 - val_loss: 1.3481\n",
      "Epoch 5/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4771 - loss: 1.4575 - val_accuracy: 0.5464 - val_loss: 1.3067\n",
      "Epoch 6/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4959 - loss: 1.4086 - val_accuracy: 0.5583 - val_loss: 1.2508\n",
      "Epoch 7/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5129 - loss: 1.3717 - val_accuracy: 0.5660 - val_loss: 1.2256\n",
      "Epoch 8/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5281 - loss: 1.3305 - val_accuracy: 0.5799 - val_loss: 1.1816\n",
      "Epoch 9/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5426 - loss: 1.2887 - val_accuracy: 0.5968 - val_loss: 1.1434\n",
      "Epoch 10/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5533 - loss: 1.2641 - val_accuracy: 0.6070 - val_loss: 1.1191\n",
      "Epoch 11/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5695 - loss: 1.2232 - val_accuracy: 0.6040 - val_loss: 1.1293\n",
      "Epoch 12/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5726 - loss: 1.2025 - val_accuracy: 0.6101 - val_loss: 1.0965\n",
      "Epoch 13/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5797 - loss: 1.1920 - val_accuracy: 0.6209 - val_loss: 1.0720\n",
      "Epoch 14/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5916 - loss: 1.1565 - val_accuracy: 0.6295 - val_loss: 1.0553\n",
      "Epoch 15/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6049 - loss: 1.1358 - val_accuracy: 0.6430 - val_loss: 1.0070\n",
      "Epoch 16/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6122 - loss: 1.1033 - val_accuracy: 0.6469 - val_loss: 0.9881\n",
      "Epoch 17/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6204 - loss: 1.0867 - val_accuracy: 0.6604 - val_loss: 0.9838\n",
      "Epoch 18/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6244 - loss: 1.0733 - val_accuracy: 0.6635 - val_loss: 0.9556\n",
      "Epoch 19/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6327 - loss: 1.0538 - val_accuracy: 0.6675 - val_loss: 0.9478\n",
      "Epoch 20/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6397 - loss: 1.0349 - val_accuracy: 0.6735 - val_loss: 0.9317\n",
      "Epoch 21/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6499 - loss: 1.0166 - val_accuracy: 0.6700 - val_loss: 0.9280\n",
      "Epoch 22/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6470 - loss: 1.0065 - val_accuracy: 0.6864 - val_loss: 0.8998\n",
      "Epoch 23/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6575 - loss: 0.9782 - val_accuracy: 0.6865 - val_loss: 0.8930\n",
      "Epoch 24/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6620 - loss: 0.9746 - val_accuracy: 0.6918 - val_loss: 0.8782\n",
      "Epoch 25/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6657 - loss: 0.9522 - val_accuracy: 0.6953 - val_loss: 0.8773\n",
      "Epoch 26/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6745 - loss: 0.9381 - val_accuracy: 0.6976 - val_loss: 0.8646\n",
      "Epoch 27/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6789 - loss: 0.9312 - val_accuracy: 0.7066 - val_loss: 0.8470\n",
      "Epoch 28/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6845 - loss: 0.9095 - val_accuracy: 0.7024 - val_loss: 0.8638\n",
      "Epoch 29/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6913 - loss: 0.8940 - val_accuracy: 0.7085 - val_loss: 0.8382\n",
      "Epoch 30/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6945 - loss: 0.8839 - val_accuracy: 0.7159 - val_loss: 0.8148\n",
      "Epoch 31/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6967 - loss: 0.8750 - val_accuracy: 0.7180 - val_loss: 0.8163\n",
      "Epoch 32/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7002 - loss: 0.8643 - val_accuracy: 0.7180 - val_loss: 0.8055\n",
      "Epoch 33/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7029 - loss: 0.8494 - val_accuracy: 0.7213 - val_loss: 0.8073\n",
      "Epoch 34/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7104 - loss: 0.8411 - val_accuracy: 0.7246 - val_loss: 0.7940\n",
      "Epoch 35/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7091 - loss: 0.8371 - val_accuracy: 0.7266 - val_loss: 0.7867\n",
      "Epoch 36/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7148 - loss: 0.8141 - val_accuracy: 0.7205 - val_loss: 0.7997\n",
      "Epoch 37/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7203 - loss: 0.8053 - val_accuracy: 0.7258 - val_loss: 0.7829\n",
      "Epoch 38/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7232 - loss: 0.7958 - val_accuracy: 0.7301 - val_loss: 0.7694\n",
      "Epoch 39/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7231 - loss: 0.7959 - val_accuracy: 0.7280 - val_loss: 0.7715\n",
      "Epoch 40/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7284 - loss: 0.7812 - val_accuracy: 0.7298 - val_loss: 0.7689\n",
      "Epoch 41/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7347 - loss: 0.7673 - val_accuracy: 0.7354 - val_loss: 0.7630\n",
      "Epoch 42/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7364 - loss: 0.7555 - val_accuracy: 0.7279 - val_loss: 0.7718\n",
      "Epoch 43/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7385 - loss: 0.7575 - val_accuracy: 0.7361 - val_loss: 0.7570\n",
      "Epoch 44/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7424 - loss: 0.7509 - val_accuracy: 0.7348 - val_loss: 0.7603\n",
      "Epoch 45/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7480 - loss: 0.7309 - val_accuracy: 0.7411 - val_loss: 0.7412\n",
      "Epoch 46/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7419 - loss: 0.7372 - val_accuracy: 0.7345 - val_loss: 0.7741\n",
      "Epoch 47/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7468 - loss: 0.7339 - val_accuracy: 0.7442 - val_loss: 0.7362\n",
      "Epoch 48/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7496 - loss: 0.7235 - val_accuracy: 0.7457 - val_loss: 0.7320\n",
      "Epoch 49/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7487 - loss: 0.7179 - val_accuracy: 0.7454 - val_loss: 0.7267\n",
      "Epoch 50/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7546 - loss: 0.7036 - val_accuracy: 0.7439 - val_loss: 0.7342\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.7479 - loss: 0.7218\n",
      "Epoch 1/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.1690 - loss: 2.2092 - val_accuracy: 0.3744 - val_loss: 1.7604\n",
      "Epoch 2/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3277 - loss: 1.8289 - val_accuracy: 0.4318 - val_loss: 1.6025\n",
      "Epoch 3/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3803 - loss: 1.6864 - val_accuracy: 0.4707 - val_loss: 1.4880\n",
      "Epoch 4/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4192 - loss: 1.5957 - val_accuracy: 0.4919 - val_loss: 1.4282\n",
      "Epoch 5/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4334 - loss: 1.5466 - val_accuracy: 0.5070 - val_loss: 1.3807\n",
      "Epoch 6/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4524 - loss: 1.5045 - val_accuracy: 0.5191 - val_loss: 1.3478\n",
      "Epoch 7/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4752 - loss: 1.4569 - val_accuracy: 0.5350 - val_loss: 1.3135\n",
      "Epoch 8/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4878 - loss: 1.4273 - val_accuracy: 0.5454 - val_loss: 1.2823\n",
      "Epoch 9/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5002 - loss: 1.4045 - val_accuracy: 0.5557 - val_loss: 1.2550\n",
      "Epoch 10/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5024 - loss: 1.3824 - val_accuracy: 0.5625 - val_loss: 1.2493\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 960us/step - accuracy: 0.5682 - loss: 1.2448\n",
      "Epoch 1/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.1812 - loss: 2.1760 - val_accuracy: 0.3611 - val_loss: 1.7779\n",
      "Epoch 2/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3227 - loss: 1.8220 - val_accuracy: 0.4273 - val_loss: 1.6155\n",
      "Epoch 3/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3740 - loss: 1.7017 - val_accuracy: 0.4659 - val_loss: 1.5095\n",
      "Epoch 4/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4144 - loss: 1.6133 - val_accuracy: 0.4887 - val_loss: 1.4396\n",
      "Epoch 5/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4375 - loss: 1.5562 - val_accuracy: 0.5010 - val_loss: 1.4019\n",
      "Epoch 6/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4500 - loss: 1.5063 - val_accuracy: 0.5115 - val_loss: 1.3556\n",
      "Epoch 7/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4728 - loss: 1.4665 - val_accuracy: 0.5282 - val_loss: 1.3137\n",
      "Epoch 8/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4861 - loss: 1.4315 - val_accuracy: 0.5412 - val_loss: 1.2857\n",
      "Epoch 9/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4999 - loss: 1.3962 - val_accuracy: 0.5565 - val_loss: 1.2520\n",
      "Epoch 10/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5186 - loss: 1.3556 - val_accuracy: 0.5641 - val_loss: 1.2193\n",
      "Epoch 11/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5248 - loss: 1.3323 - val_accuracy: 0.5733 - val_loss: 1.1940\n",
      "Epoch 12/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5346 - loss: 1.3122 - val_accuracy: 0.5885 - val_loss: 1.1661\n",
      "Epoch 13/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5458 - loss: 1.2907 - val_accuracy: 0.5973 - val_loss: 1.1463\n",
      "Epoch 14/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5493 - loss: 1.2713 - val_accuracy: 0.5938 - val_loss: 1.1410\n",
      "Epoch 15/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5597 - loss: 1.2406 - val_accuracy: 0.5993 - val_loss: 1.1325\n",
      "Epoch 16/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5717 - loss: 1.2203 - val_accuracy: 0.6204 - val_loss: 1.0851\n",
      "Epoch 17/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5789 - loss: 1.1915 - val_accuracy: 0.6244 - val_loss: 1.0640\n",
      "Epoch 18/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5883 - loss: 1.1669 - val_accuracy: 0.6199 - val_loss: 1.0779\n",
      "Epoch 19/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5965 - loss: 1.1462 - val_accuracy: 0.6385 - val_loss: 1.0361\n",
      "Epoch 20/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6028 - loss: 1.1336 - val_accuracy: 0.6427 - val_loss: 1.0307\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 982us/step - accuracy: 0.6401 - loss: 1.0241\n",
      "Epoch 1/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.1794 - loss: 2.1888 - val_accuracy: 0.3879 - val_loss: 1.7531\n",
      "Epoch 2/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3296 - loss: 1.8070 - val_accuracy: 0.4532 - val_loss: 1.5299\n",
      "Epoch 3/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3984 - loss: 1.6494 - val_accuracy: 0.4785 - val_loss: 1.4575\n",
      "Epoch 4/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4309 - loss: 1.5715 - val_accuracy: 0.5083 - val_loss: 1.3821\n",
      "Epoch 5/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4517 - loss: 1.5160 - val_accuracy: 0.5273 - val_loss: 1.3376\n",
      "Epoch 6/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4736 - loss: 1.4648 - val_accuracy: 0.5297 - val_loss: 1.3348\n",
      "Epoch 7/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4881 - loss: 1.4274 - val_accuracy: 0.5300 - val_loss: 1.3088\n",
      "Epoch 8/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5018 - loss: 1.3939 - val_accuracy: 0.5373 - val_loss: 1.2798\n",
      "Epoch 9/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5123 - loss: 1.3655 - val_accuracy: 0.5756 - val_loss: 1.2110\n",
      "Epoch 10/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5288 - loss: 1.3331 - val_accuracy: 0.5815 - val_loss: 1.2015\n",
      "Epoch 11/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5390 - loss: 1.2961 - val_accuracy: 0.5909 - val_loss: 1.1658\n",
      "Epoch 12/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5482 - loss: 1.2786 - val_accuracy: 0.5952 - val_loss: 1.1542\n",
      "Epoch 13/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5614 - loss: 1.2436 - val_accuracy: 0.5985 - val_loss: 1.1411\n",
      "Epoch 14/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5632 - loss: 1.2279 - val_accuracy: 0.6159 - val_loss: 1.1008\n",
      "Epoch 15/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5765 - loss: 1.2050 - val_accuracy: 0.6211 - val_loss: 1.0800\n",
      "Epoch 16/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5842 - loss: 1.1816 - val_accuracy: 0.6269 - val_loss: 1.0621\n",
      "Epoch 17/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5929 - loss: 1.1583 - val_accuracy: 0.6215 - val_loss: 1.0805\n",
      "Epoch 18/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5959 - loss: 1.1495 - val_accuracy: 0.6355 - val_loss: 1.0367\n",
      "Epoch 19/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6024 - loss: 1.1296 - val_accuracy: 0.6278 - val_loss: 1.0443\n",
      "Epoch 20/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6062 - loss: 1.1200 - val_accuracy: 0.6502 - val_loss: 1.0066\n",
      "Epoch 21/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6090 - loss: 1.1096 - val_accuracy: 0.6540 - val_loss: 0.9906\n",
      "Epoch 22/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6203 - loss: 1.0835 - val_accuracy: 0.6536 - val_loss: 0.9872\n",
      "Epoch 23/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6218 - loss: 1.0754 - val_accuracy: 0.6450 - val_loss: 0.9944\n",
      "Epoch 24/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6230 - loss: 1.0700 - val_accuracy: 0.6595 - val_loss: 0.9618\n",
      "Epoch 25/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6343 - loss: 1.0459 - val_accuracy: 0.6619 - val_loss: 0.9603\n",
      "Epoch 26/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6384 - loss: 1.0411 - val_accuracy: 0.6710 - val_loss: 0.9426\n",
      "Epoch 27/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6417 - loss: 1.0274 - val_accuracy: 0.6643 - val_loss: 0.9494\n",
      "Epoch 28/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6456 - loss: 1.0143 - val_accuracy: 0.6761 - val_loss: 0.9296\n",
      "Epoch 29/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6464 - loss: 1.0117 - val_accuracy: 0.6674 - val_loss: 0.9360\n",
      "Epoch 30/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6526 - loss: 0.9936 - val_accuracy: 0.6776 - val_loss: 0.9185\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6775 - loss: 0.9145\n",
      "Epoch 1/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.1788 - loss: 2.1763 - val_accuracy: 0.3586 - val_loss: 1.7817\n",
      "Epoch 2/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3128 - loss: 1.8389 - val_accuracy: 0.4241 - val_loss: 1.6147\n",
      "Epoch 3/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3682 - loss: 1.7095 - val_accuracy: 0.4578 - val_loss: 1.5229\n",
      "Epoch 4/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3964 - loss: 1.6303 - val_accuracy: 0.4820 - val_loss: 1.4689\n",
      "Epoch 5/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4269 - loss: 1.5769 - val_accuracy: 0.4959 - val_loss: 1.3956\n",
      "Epoch 6/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4498 - loss: 1.5130 - val_accuracy: 0.5183 - val_loss: 1.3614\n",
      "Epoch 7/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4681 - loss: 1.4748 - val_accuracy: 0.5302 - val_loss: 1.3079\n",
      "Epoch 8/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4848 - loss: 1.4300 - val_accuracy: 0.5470 - val_loss: 1.2746\n",
      "Epoch 9/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4972 - loss: 1.3988 - val_accuracy: 0.5514 - val_loss: 1.2573\n",
      "Epoch 10/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5033 - loss: 1.3841 - val_accuracy: 0.5550 - val_loss: 1.2493\n",
      "Epoch 11/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5172 - loss: 1.3519 - val_accuracy: 0.5685 - val_loss: 1.2099\n",
      "Epoch 12/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5222 - loss: 1.3302 - val_accuracy: 0.5653 - val_loss: 1.2002\n",
      "Epoch 13/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5345 - loss: 1.3034 - val_accuracy: 0.5866 - val_loss: 1.1623\n",
      "Epoch 14/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5424 - loss: 1.2818 - val_accuracy: 0.5908 - val_loss: 1.1505\n",
      "Epoch 15/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5491 - loss: 1.2640 - val_accuracy: 0.5945 - val_loss: 1.1460\n",
      "Epoch 16/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5603 - loss: 1.2401 - val_accuracy: 0.6018 - val_loss: 1.1192\n",
      "Epoch 17/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5680 - loss: 1.2282 - val_accuracy: 0.6018 - val_loss: 1.1200\n",
      "Epoch 18/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5699 - loss: 1.2145 - val_accuracy: 0.6150 - val_loss: 1.0883\n",
      "Epoch 19/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5806 - loss: 1.1843 - val_accuracy: 0.6184 - val_loss: 1.0781\n",
      "Epoch 20/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5828 - loss: 1.1766 - val_accuracy: 0.6176 - val_loss: 1.0769\n",
      "Epoch 21/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5876 - loss: 1.1686 - val_accuracy: 0.6291 - val_loss: 1.0510\n",
      "Epoch 22/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5950 - loss: 1.1418 - val_accuracy: 0.6326 - val_loss: 1.0436\n",
      "Epoch 23/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6011 - loss: 1.1313 - val_accuracy: 0.6318 - val_loss: 1.0332\n",
      "Epoch 24/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6029 - loss: 1.1192 - val_accuracy: 0.6452 - val_loss: 1.0039\n",
      "Epoch 25/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6090 - loss: 1.1017 - val_accuracy: 0.6473 - val_loss: 1.0046\n",
      "Epoch 26/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6197 - loss: 1.0874 - val_accuracy: 0.6368 - val_loss: 1.0266\n",
      "Epoch 27/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6206 - loss: 1.0829 - val_accuracy: 0.6554 - val_loss: 0.9833\n",
      "Epoch 28/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6246 - loss: 1.0657 - val_accuracy: 0.6634 - val_loss: 0.9599\n",
      "Epoch 29/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6278 - loss: 1.0566 - val_accuracy: 0.6594 - val_loss: 0.9600\n",
      "Epoch 30/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6306 - loss: 1.0534 - val_accuracy: 0.6637 - val_loss: 0.9480\n",
      "Epoch 31/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6387 - loss: 1.0308 - val_accuracy: 0.6652 - val_loss: 0.9515\n",
      "Epoch 32/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6412 - loss: 1.0287 - val_accuracy: 0.6751 - val_loss: 0.9227\n",
      "Epoch 33/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6460 - loss: 1.0143 - val_accuracy: 0.6622 - val_loss: 0.9407\n",
      "Epoch 34/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6437 - loss: 1.0123 - val_accuracy: 0.6787 - val_loss: 0.9122\n",
      "Epoch 35/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6507 - loss: 0.9960 - val_accuracy: 0.6828 - val_loss: 0.9015\n",
      "Epoch 36/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6532 - loss: 0.9911 - val_accuracy: 0.6866 - val_loss: 0.8947\n",
      "Epoch 37/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6583 - loss: 0.9831 - val_accuracy: 0.6840 - val_loss: 0.8909\n",
      "Epoch 38/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6648 - loss: 0.9687 - val_accuracy: 0.6818 - val_loss: 0.8915\n",
      "Epoch 39/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6661 - loss: 0.9551 - val_accuracy: 0.6896 - val_loss: 0.8795\n",
      "Epoch 40/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6699 - loss: 0.9516 - val_accuracy: 0.6850 - val_loss: 0.8854\n",
      "Epoch 41/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6701 - loss: 0.9463 - val_accuracy: 0.6967 - val_loss: 0.8571\n",
      "Epoch 42/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6769 - loss: 0.9343 - val_accuracy: 0.6943 - val_loss: 0.8650\n",
      "Epoch 43/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6803 - loss: 0.9183 - val_accuracy: 0.6980 - val_loss: 0.8562\n",
      "Epoch 44/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6841 - loss: 0.9123 - val_accuracy: 0.7029 - val_loss: 0.8423\n",
      "Epoch 45/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6850 - loss: 0.9047 - val_accuracy: 0.7000 - val_loss: 0.8411\n",
      "Epoch 46/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6840 - loss: 0.9087 - val_accuracy: 0.7039 - val_loss: 0.8497\n",
      "Epoch 47/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6890 - loss: 0.8947 - val_accuracy: 0.7068 - val_loss: 0.8276\n",
      "Epoch 48/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6911 - loss: 0.8871 - val_accuracy: 0.7031 - val_loss: 0.8400\n",
      "Epoch 49/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6953 - loss: 0.8781 - val_accuracy: 0.7087 - val_loss: 0.8246\n",
      "Epoch 50/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7000 - loss: 0.8670 - val_accuracy: 0.7107 - val_loss: 0.8175\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - accuracy: 0.7141 - loss: 0.8079\n",
      "Epoch 1/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.1401 - loss: 2.2568 - val_accuracy: 0.3375 - val_loss: 1.9272\n",
      "Epoch 2/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.2794 - loss: 1.9416 - val_accuracy: 0.4085 - val_loss: 1.7086\n",
      "Epoch 3/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.3323 - loss: 1.8080 - val_accuracy: 0.4369 - val_loss: 1.6097\n",
      "Epoch 4/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.3636 - loss: 1.7294 - val_accuracy: 0.4507 - val_loss: 1.5718\n",
      "Epoch 5/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.3899 - loss: 1.6780 - val_accuracy: 0.4756 - val_loss: 1.4993\n",
      "Epoch 6/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4160 - loss: 1.6096 - val_accuracy: 0.4869 - val_loss: 1.4546\n",
      "Epoch 7/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4304 - loss: 1.5778 - val_accuracy: 0.4985 - val_loss: 1.4245\n",
      "Epoch 8/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4441 - loss: 1.5519 - val_accuracy: 0.5021 - val_loss: 1.4088\n",
      "Epoch 9/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4580 - loss: 1.5196 - val_accuracy: 0.5151 - val_loss: 1.3681\n",
      "Epoch 10/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4678 - loss: 1.4768 - val_accuracy: 0.5319 - val_loss: 1.3454\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5334 - loss: 1.3395\n",
      "Epoch 1/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.1428 - loss: 2.2679 - val_accuracy: 0.2829 - val_loss: 2.0258\n",
      "Epoch 2/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.2480 - loss: 2.0345 - val_accuracy: 0.3665 - val_loss: 1.7788\n",
      "Epoch 3/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.3109 - loss: 1.8597 - val_accuracy: 0.4138 - val_loss: 1.6475\n",
      "Epoch 4/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.3603 - loss: 1.7376 - val_accuracy: 0.4523 - val_loss: 1.5430\n",
      "Epoch 5/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.3910 - loss: 1.6514 - val_accuracy: 0.4761 - val_loss: 1.4838\n",
      "Epoch 6/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4169 - loss: 1.5982 - val_accuracy: 0.4828 - val_loss: 1.4546\n",
      "Epoch 7/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4329 - loss: 1.5551 - val_accuracy: 0.5018 - val_loss: 1.3959\n",
      "Epoch 8/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4530 - loss: 1.5106 - val_accuracy: 0.5257 - val_loss: 1.3579\n",
      "Epoch 9/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4668 - loss: 1.4837 - val_accuracy: 0.5293 - val_loss: 1.3296\n",
      "Epoch 10/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4780 - loss: 1.4462 - val_accuracy: 0.5376 - val_loss: 1.3068\n",
      "Epoch 11/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4913 - loss: 1.4140 - val_accuracy: 0.5438 - val_loss: 1.2991\n",
      "Epoch 12/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4953 - loss: 1.4059 - val_accuracy: 0.5538 - val_loss: 1.2590\n",
      "Epoch 13/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5027 - loss: 1.3917 - val_accuracy: 0.5637 - val_loss: 1.2362\n",
      "Epoch 14/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5146 - loss: 1.3580 - val_accuracy: 0.5649 - val_loss: 1.2308\n",
      "Epoch 15/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5266 - loss: 1.3269 - val_accuracy: 0.5733 - val_loss: 1.2112\n",
      "Epoch 16/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5276 - loss: 1.3312 - val_accuracy: 0.5790 - val_loss: 1.1959\n",
      "Epoch 17/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5359 - loss: 1.3056 - val_accuracy: 0.5876 - val_loss: 1.1782\n",
      "Epoch 18/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5455 - loss: 1.2843 - val_accuracy: 0.5887 - val_loss: 1.1772\n",
      "Epoch 19/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5443 - loss: 1.2821 - val_accuracy: 0.5929 - val_loss: 1.1648\n",
      "Epoch 20/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5512 - loss: 1.2681 - val_accuracy: 0.6007 - val_loss: 1.1370\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.6057 - loss: 1.1297\n",
      "Epoch 1/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.1547 - loss: 2.2480 - val_accuracy: 0.3214 - val_loss: 1.9525\n",
      "Epoch 2/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.2758 - loss: 1.9747 - val_accuracy: 0.3916 - val_loss: 1.7631\n",
      "Epoch 3/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.3288 - loss: 1.8337 - val_accuracy: 0.4255 - val_loss: 1.6480\n",
      "Epoch 4/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.3591 - loss: 1.7452 - val_accuracy: 0.4558 - val_loss: 1.5558\n",
      "Epoch 5/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.3916 - loss: 1.6714 - val_accuracy: 0.4720 - val_loss: 1.4913\n",
      "Epoch 6/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4197 - loss: 1.6055 - val_accuracy: 0.4928 - val_loss: 1.4337\n",
      "Epoch 7/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4326 - loss: 1.5629 - val_accuracy: 0.4973 - val_loss: 1.4291\n",
      "Epoch 8/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4457 - loss: 1.5334 - val_accuracy: 0.5134 - val_loss: 1.3741\n",
      "Epoch 9/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4591 - loss: 1.5042 - val_accuracy: 0.5208 - val_loss: 1.3546\n",
      "Epoch 10/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4655 - loss: 1.4809 - val_accuracy: 0.5265 - val_loss: 1.3274\n",
      "Epoch 11/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4822 - loss: 1.4466 - val_accuracy: 0.5437 - val_loss: 1.2986\n",
      "Epoch 12/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4911 - loss: 1.4281 - val_accuracy: 0.5509 - val_loss: 1.2752\n",
      "Epoch 13/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4961 - loss: 1.4054 - val_accuracy: 0.5521 - val_loss: 1.2581\n",
      "Epoch 14/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5087 - loss: 1.3731 - val_accuracy: 0.5593 - val_loss: 1.2531\n",
      "Epoch 15/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5118 - loss: 1.3635 - val_accuracy: 0.5710 - val_loss: 1.2192\n",
      "Epoch 16/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5265 - loss: 1.3360 - val_accuracy: 0.5745 - val_loss: 1.2065\n",
      "Epoch 17/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5308 - loss: 1.3225 - val_accuracy: 0.5740 - val_loss: 1.2095\n",
      "Epoch 18/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5335 - loss: 1.3190 - val_accuracy: 0.5868 - val_loss: 1.1650\n",
      "Epoch 19/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5479 - loss: 1.2813 - val_accuracy: 0.5928 - val_loss: 1.1647\n",
      "Epoch 20/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5493 - loss: 1.2804 - val_accuracy: 0.5875 - val_loss: 1.1666\n",
      "Epoch 21/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5559 - loss: 1.2647 - val_accuracy: 0.5896 - val_loss: 1.1408\n",
      "Epoch 22/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5609 - loss: 1.2486 - val_accuracy: 0.5969 - val_loss: 1.1388\n",
      "Epoch 23/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5653 - loss: 1.2336 - val_accuracy: 0.6039 - val_loss: 1.1184\n",
      "Epoch 24/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5736 - loss: 1.2158 - val_accuracy: 0.5978 - val_loss: 1.1223\n",
      "Epoch 25/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5776 - loss: 1.2100 - val_accuracy: 0.6199 - val_loss: 1.0829\n",
      "Epoch 26/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5791 - loss: 1.1901 - val_accuracy: 0.6149 - val_loss: 1.0797\n",
      "Epoch 27/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5863 - loss: 1.1836 - val_accuracy: 0.6243 - val_loss: 1.0675\n",
      "Epoch 28/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5890 - loss: 1.1731 - val_accuracy: 0.6302 - val_loss: 1.0531\n",
      "Epoch 29/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5939 - loss: 1.1708 - val_accuracy: 0.6253 - val_loss: 1.0667\n",
      "Epoch 30/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5945 - loss: 1.1501 - val_accuracy: 0.6334 - val_loss: 1.0442\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6343 - loss: 1.0373\n",
      "Epoch 1/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.1547 - loss: 2.2441 - val_accuracy: 0.3045 - val_loss: 1.9267\n",
      "Epoch 2/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.2932 - loss: 1.9278 - val_accuracy: 0.3974 - val_loss: 1.7214\n",
      "Epoch 3/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.3379 - loss: 1.8074 - val_accuracy: 0.4261 - val_loss: 1.6291\n",
      "Epoch 4/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.3678 - loss: 1.7310 - val_accuracy: 0.4463 - val_loss: 1.5567\n",
      "Epoch 5/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.3925 - loss: 1.6593 - val_accuracy: 0.4693 - val_loss: 1.4947\n",
      "Epoch 6/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4178 - loss: 1.6068 - val_accuracy: 0.4784 - val_loss: 1.4673\n",
      "Epoch 7/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4343 - loss: 1.5609 - val_accuracy: 0.4991 - val_loss: 1.4193\n",
      "Epoch 8/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4414 - loss: 1.5312 - val_accuracy: 0.5153 - val_loss: 1.3756\n",
      "Epoch 9/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4583 - loss: 1.4900 - val_accuracy: 0.5151 - val_loss: 1.3706\n",
      "Epoch 10/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4679 - loss: 1.4722 - val_accuracy: 0.5303 - val_loss: 1.3359\n",
      "Epoch 11/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4802 - loss: 1.4375 - val_accuracy: 0.5475 - val_loss: 1.2893\n",
      "Epoch 12/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4933 - loss: 1.4127 - val_accuracy: 0.5555 - val_loss: 1.2694\n",
      "Epoch 13/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5034 - loss: 1.3891 - val_accuracy: 0.5559 - val_loss: 1.2623\n",
      "Epoch 14/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5092 - loss: 1.3664 - val_accuracy: 0.5624 - val_loss: 1.2415\n",
      "Epoch 15/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5153 - loss: 1.3439 - val_accuracy: 0.5686 - val_loss: 1.2272\n",
      "Epoch 16/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5288 - loss: 1.3241 - val_accuracy: 0.5776 - val_loss: 1.2106\n",
      "Epoch 17/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5367 - loss: 1.3003 - val_accuracy: 0.5841 - val_loss: 1.1777\n",
      "Epoch 18/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5379 - loss: 1.2990 - val_accuracy: 0.5891 - val_loss: 1.1728\n",
      "Epoch 19/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5445 - loss: 1.2809 - val_accuracy: 0.5906 - val_loss: 1.1598\n",
      "Epoch 20/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5522 - loss: 1.2673 - val_accuracy: 0.5991 - val_loss: 1.1494\n",
      "Epoch 21/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5576 - loss: 1.2380 - val_accuracy: 0.6004 - val_loss: 1.1454\n",
      "Epoch 22/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5619 - loss: 1.2320 - val_accuracy: 0.6077 - val_loss: 1.1173\n",
      "Epoch 23/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5643 - loss: 1.2299 - val_accuracy: 0.6079 - val_loss: 1.1206\n",
      "Epoch 24/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5750 - loss: 1.2067 - val_accuracy: 0.6155 - val_loss: 1.1067\n",
      "Epoch 25/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5756 - loss: 1.1896 - val_accuracy: 0.6115 - val_loss: 1.0965\n",
      "Epoch 26/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5774 - loss: 1.1911 - val_accuracy: 0.6243 - val_loss: 1.0748\n",
      "Epoch 27/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5864 - loss: 1.1793 - val_accuracy: 0.6208 - val_loss: 1.0810\n",
      "Epoch 28/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5857 - loss: 1.1686 - val_accuracy: 0.6122 - val_loss: 1.0856\n",
      "Epoch 29/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5949 - loss: 1.1537 - val_accuracy: 0.6318 - val_loss: 1.0510\n",
      "Epoch 30/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5946 - loss: 1.1446 - val_accuracy: 0.6314 - val_loss: 1.0485\n",
      "Epoch 31/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5972 - loss: 1.1388 - val_accuracy: 0.6328 - val_loss: 1.0374\n",
      "Epoch 32/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6035 - loss: 1.1239 - val_accuracy: 0.6382 - val_loss: 1.0254\n",
      "Epoch 33/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6060 - loss: 1.1181 - val_accuracy: 0.6376 - val_loss: 1.0185\n",
      "Epoch 34/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6063 - loss: 1.1193 - val_accuracy: 0.6411 - val_loss: 1.0160\n",
      "Epoch 35/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6172 - loss: 1.0886 - val_accuracy: 0.6469 - val_loss: 1.0088\n",
      "Epoch 36/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6160 - loss: 1.0876 - val_accuracy: 0.6456 - val_loss: 1.0051\n",
      "Epoch 37/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6201 - loss: 1.0716 - val_accuracy: 0.6516 - val_loss: 0.9958\n",
      "Epoch 38/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6197 - loss: 1.0724 - val_accuracy: 0.6574 - val_loss: 0.9816\n",
      "Epoch 39/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6250 - loss: 1.0687 - val_accuracy: 0.6489 - val_loss: 0.9894\n",
      "Epoch 40/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6241 - loss: 1.0628 - val_accuracy: 0.6537 - val_loss: 0.9768\n",
      "Epoch 41/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6313 - loss: 1.0495 - val_accuracy: 0.6619 - val_loss: 0.9597\n",
      "Epoch 42/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6342 - loss: 1.0453 - val_accuracy: 0.6601 - val_loss: 0.9653\n",
      "Epoch 43/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6376 - loss: 1.0413 - val_accuracy: 0.6689 - val_loss: 0.9508\n",
      "Epoch 44/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6364 - loss: 1.0290 - val_accuracy: 0.6687 - val_loss: 0.9433\n",
      "Epoch 45/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6420 - loss: 1.0174 - val_accuracy: 0.6715 - val_loss: 0.9459\n",
      "Epoch 46/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6411 - loss: 1.0159 - val_accuracy: 0.6658 - val_loss: 0.9591\n",
      "Epoch 47/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6448 - loss: 1.0180 - val_accuracy: 0.6643 - val_loss: 0.9497\n",
      "Epoch 48/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6463 - loss: 1.0067 - val_accuracy: 0.6752 - val_loss: 0.9250\n",
      "Epoch 49/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6484 - loss: 0.9994 - val_accuracy: 0.6760 - val_loss: 0.9212\n",
      "Epoch 50/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6451 - loss: 1.0095 - val_accuracy: 0.6578 - val_loss: 0.9554\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - accuracy: 0.6628 - loss: 0.9431\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.2961 - loss: 1.8766 - val_accuracy: 0.5357 - val_loss: 1.2611\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5504 - loss: 1.2733 - val_accuracy: 0.6459 - val_loss: 1.0256\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6266 - loss: 1.0680 - val_accuracy: 0.6765 - val_loss: 0.9076\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6717 - loss: 0.9491 - val_accuracy: 0.7065 - val_loss: 0.8493\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6991 - loss: 0.8724 - val_accuracy: 0.7206 - val_loss: 0.8119\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7227 - loss: 0.8052 - val_accuracy: 0.7342 - val_loss: 0.7722\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7400 - loss: 0.7505 - val_accuracy: 0.7387 - val_loss: 0.7578\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7517 - loss: 0.7191 - val_accuracy: 0.7463 - val_loss: 0.7438\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7722 - loss: 0.6709 - val_accuracy: 0.7443 - val_loss: 0.7601\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7773 - loss: 0.6394 - val_accuracy: 0.7530 - val_loss: 0.7329\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.7553 - loss: 0.7274\n",
      "Epoch 1/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.2992 - loss: 1.8714 - val_accuracy: 0.5398 - val_loss: 1.3002\n",
      "Epoch 2/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5289 - loss: 1.3234 - val_accuracy: 0.6236 - val_loss: 1.0591\n",
      "Epoch 3/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6038 - loss: 1.1266 - val_accuracy: 0.6631 - val_loss: 0.9658\n",
      "Epoch 4/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6490 - loss: 1.0073 - val_accuracy: 0.6852 - val_loss: 0.9119\n",
      "Epoch 5/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6759 - loss: 0.9352 - val_accuracy: 0.7010 - val_loss: 0.8521\n",
      "Epoch 6/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7023 - loss: 0.8655 - val_accuracy: 0.7130 - val_loss: 0.8394\n",
      "Epoch 7/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7163 - loss: 0.8112 - val_accuracy: 0.7229 - val_loss: 0.7982\n",
      "Epoch 8/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7364 - loss: 0.7591 - val_accuracy: 0.7216 - val_loss: 0.8078\n",
      "Epoch 9/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7472 - loss: 0.7264 - val_accuracy: 0.7305 - val_loss: 0.7867\n",
      "Epoch 10/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7611 - loss: 0.6883 - val_accuracy: 0.7288 - val_loss: 0.7823\n",
      "Epoch 11/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7706 - loss: 0.6585 - val_accuracy: 0.7447 - val_loss: 0.7823\n",
      "Epoch 12/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7778 - loss: 0.6342 - val_accuracy: 0.7376 - val_loss: 0.7876\n",
      "Epoch 13/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7893 - loss: 0.5980 - val_accuracy: 0.7465 - val_loss: 0.8027\n",
      "Epoch 14/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7977 - loss: 0.5750 - val_accuracy: 0.7392 - val_loss: 0.8128\n",
      "Epoch 15/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7993 - loss: 0.5645 - val_accuracy: 0.7481 - val_loss: 0.7844\n",
      "Epoch 16/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8089 - loss: 0.5447 - val_accuracy: 0.7453 - val_loss: 0.8210\n",
      "Epoch 17/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8094 - loss: 0.5271 - val_accuracy: 0.7488 - val_loss: 0.8102\n",
      "Epoch 18/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8195 - loss: 0.5044 - val_accuracy: 0.7525 - val_loss: 0.8301\n",
      "Epoch 19/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8213 - loss: 0.4964 - val_accuracy: 0.7420 - val_loss: 0.8621\n",
      "Epoch 20/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8289 - loss: 0.4828 - val_accuracy: 0.7491 - val_loss: 0.8291\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - accuracy: 0.7497 - loss: 0.8191\n",
      "Epoch 1/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.2755 - loss: 1.9362 - val_accuracy: 0.5209 - val_loss: 1.3077\n",
      "Epoch 2/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5238 - loss: 1.3309 - val_accuracy: 0.6131 - val_loss: 1.1048\n",
      "Epoch 3/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5964 - loss: 1.1553 - val_accuracy: 0.6559 - val_loss: 0.9707\n",
      "Epoch 4/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6395 - loss: 1.0376 - val_accuracy: 0.6713 - val_loss: 0.9239\n",
      "Epoch 5/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6662 - loss: 0.9593 - val_accuracy: 0.6830 - val_loss: 0.9080\n",
      "Epoch 6/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6892 - loss: 0.8908 - val_accuracy: 0.7117 - val_loss: 0.8301\n",
      "Epoch 7/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7032 - loss: 0.8511 - val_accuracy: 0.7045 - val_loss: 0.8476\n",
      "Epoch 8/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7186 - loss: 0.8067 - val_accuracy: 0.7239 - val_loss: 0.8087\n",
      "Epoch 9/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7329 - loss: 0.7686 - val_accuracy: 0.7232 - val_loss: 0.7985\n",
      "Epoch 10/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7452 - loss: 0.7334 - val_accuracy: 0.7335 - val_loss: 0.7952\n",
      "Epoch 11/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7526 - loss: 0.7109 - val_accuracy: 0.7373 - val_loss: 0.7710\n",
      "Epoch 12/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7587 - loss: 0.6951 - val_accuracy: 0.7341 - val_loss: 0.7997\n",
      "Epoch 13/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7675 - loss: 0.6638 - val_accuracy: 0.7301 - val_loss: 0.8121\n",
      "Epoch 14/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7700 - loss: 0.6531 - val_accuracy: 0.7410 - val_loss: 0.7940\n",
      "Epoch 15/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7789 - loss: 0.6337 - val_accuracy: 0.7253 - val_loss: 0.8564\n",
      "Epoch 16/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7812 - loss: 0.6089 - val_accuracy: 0.7358 - val_loss: 0.8246\n",
      "Epoch 17/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7929 - loss: 0.5882 - val_accuracy: 0.7334 - val_loss: 0.8341\n",
      "Epoch 18/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7925 - loss: 0.5800 - val_accuracy: 0.7432 - val_loss: 0.8450\n",
      "Epoch 19/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7999 - loss: 0.5581 - val_accuracy: 0.7441 - val_loss: 0.7996\n",
      "Epoch 20/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8066 - loss: 0.5416 - val_accuracy: 0.7443 - val_loss: 0.8280\n",
      "Epoch 21/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8108 - loss: 0.5363 - val_accuracy: 0.7402 - val_loss: 0.8736\n",
      "Epoch 22/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8137 - loss: 0.5181 - val_accuracy: 0.7391 - val_loss: 0.8834\n",
      "Epoch 23/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8144 - loss: 0.5140 - val_accuracy: 0.7371 - val_loss: 0.8997\n",
      "Epoch 24/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8187 - loss: 0.5021 - val_accuracy: 0.7303 - val_loss: 0.9312\n",
      "Epoch 25/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8208 - loss: 0.4935 - val_accuracy: 0.7394 - val_loss: 0.8801\n",
      "Epoch 26/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8296 - loss: 0.4771 - val_accuracy: 0.7440 - val_loss: 0.9389\n",
      "Epoch 27/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8343 - loss: 0.4602 - val_accuracy: 0.7442 - val_loss: 0.9441\n",
      "Epoch 28/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8395 - loss: 0.4427 - val_accuracy: 0.7370 - val_loss: 0.9730\n",
      "Epoch 29/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8356 - loss: 0.4567 - val_accuracy: 0.7312 - val_loss: 0.9653\n",
      "Epoch 30/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8402 - loss: 0.4351 - val_accuracy: 0.7416 - val_loss: 0.9565\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.7457 - loss: 0.9537\n",
      "Epoch 1/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.2764 - loss: 1.9350 - val_accuracy: 0.5230 - val_loss: 1.3436\n",
      "Epoch 2/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4976 - loss: 1.3923 - val_accuracy: 0.5963 - val_loss: 1.1356\n",
      "Epoch 3/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5781 - loss: 1.1991 - val_accuracy: 0.6544 - val_loss: 0.9995\n",
      "Epoch 4/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6289 - loss: 1.0620 - val_accuracy: 0.6681 - val_loss: 0.9552\n",
      "Epoch 5/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6704 - loss: 0.9524 - val_accuracy: 0.6964 - val_loss: 0.8800\n",
      "Epoch 6/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6897 - loss: 0.8991 - val_accuracy: 0.6893 - val_loss: 0.8951\n",
      "Epoch 7/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7119 - loss: 0.8294 - val_accuracy: 0.7172 - val_loss: 0.8299\n",
      "Epoch 8/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7218 - loss: 0.8000 - val_accuracy: 0.7222 - val_loss: 0.8124\n",
      "Epoch 9/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7375 - loss: 0.7581 - val_accuracy: 0.7169 - val_loss: 0.8359\n",
      "Epoch 10/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7428 - loss: 0.7370 - val_accuracy: 0.7247 - val_loss: 0.8254\n",
      "Epoch 11/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7574 - loss: 0.7044 - val_accuracy: 0.7350 - val_loss: 0.7916\n",
      "Epoch 12/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7647 - loss: 0.6676 - val_accuracy: 0.7323 - val_loss: 0.7982\n",
      "Epoch 13/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7675 - loss: 0.6599 - val_accuracy: 0.7473 - val_loss: 0.7729\n",
      "Epoch 14/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7843 - loss: 0.6187 - val_accuracy: 0.7392 - val_loss: 0.8097\n",
      "Epoch 15/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7847 - loss: 0.6115 - val_accuracy: 0.7302 - val_loss: 0.8419\n",
      "Epoch 16/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7928 - loss: 0.5849 - val_accuracy: 0.7405 - val_loss: 0.7976\n",
      "Epoch 17/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8011 - loss: 0.5710 - val_accuracy: 0.7401 - val_loss: 0.8182\n",
      "Epoch 18/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8046 - loss: 0.5527 - val_accuracy: 0.7287 - val_loss: 0.8944\n",
      "Epoch 19/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8108 - loss: 0.5340 - val_accuracy: 0.7397 - val_loss: 0.9122\n",
      "Epoch 20/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8154 - loss: 0.5191 - val_accuracy: 0.7432 - val_loss: 0.8849\n",
      "Epoch 21/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8143 - loss: 0.5181 - val_accuracy: 0.7415 - val_loss: 0.8539\n",
      "Epoch 22/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8192 - loss: 0.4992 - val_accuracy: 0.7438 - val_loss: 0.8577\n",
      "Epoch 23/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8246 - loss: 0.4848 - val_accuracy: 0.7414 - val_loss: 0.9071\n",
      "Epoch 24/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8304 - loss: 0.4726 - val_accuracy: 0.7400 - val_loss: 0.8708\n",
      "Epoch 25/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8356 - loss: 0.4555 - val_accuracy: 0.7452 - val_loss: 0.9352\n",
      "Epoch 26/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8373 - loss: 0.4525 - val_accuracy: 0.7486 - val_loss: 0.9420\n",
      "Epoch 27/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8448 - loss: 0.4352 - val_accuracy: 0.7428 - val_loss: 0.9281\n",
      "Epoch 28/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8445 - loss: 0.4334 - val_accuracy: 0.7442 - val_loss: 0.9349\n",
      "Epoch 29/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8449 - loss: 0.4326 - val_accuracy: 0.7417 - val_loss: 0.9517\n",
      "Epoch 30/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8500 - loss: 0.4125 - val_accuracy: 0.7394 - val_loss: 1.0234\n",
      "Epoch 31/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8523 - loss: 0.4046 - val_accuracy: 0.7452 - val_loss: 0.9946\n",
      "Epoch 32/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8518 - loss: 0.4044 - val_accuracy: 0.7430 - val_loss: 1.0055\n",
      "Epoch 33/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8508 - loss: 0.4073 - val_accuracy: 0.7448 - val_loss: 1.0349\n",
      "Epoch 34/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8585 - loss: 0.3864 - val_accuracy: 0.7483 - val_loss: 1.0025\n",
      "Epoch 35/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8645 - loss: 0.3737 - val_accuracy: 0.7422 - val_loss: 1.0361\n",
      "Epoch 36/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8625 - loss: 0.3716 - val_accuracy: 0.7382 - val_loss: 1.0355\n",
      "Epoch 37/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8657 - loss: 0.3674 - val_accuracy: 0.7414 - val_loss: 1.0974\n",
      "Epoch 38/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8676 - loss: 0.3604 - val_accuracy: 0.7433 - val_loss: 1.0748\n",
      "Epoch 39/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8743 - loss: 0.3482 - val_accuracy: 0.7390 - val_loss: 1.0919\n",
      "Epoch 40/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8712 - loss: 0.3485 - val_accuracy: 0.7369 - val_loss: 1.1434\n",
      "Epoch 41/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8808 - loss: 0.3305 - val_accuracy: 0.7479 - val_loss: 1.1577\n",
      "Epoch 42/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8794 - loss: 0.3392 - val_accuracy: 0.7436 - val_loss: 1.1569\n",
      "Epoch 43/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8796 - loss: 0.3316 - val_accuracy: 0.7323 - val_loss: 1.2335\n",
      "Epoch 44/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8775 - loss: 0.3367 - val_accuracy: 0.7342 - val_loss: 1.1624\n",
      "Epoch 45/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8797 - loss: 0.3282 - val_accuracy: 0.7407 - val_loss: 1.1713\n",
      "Epoch 46/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8853 - loss: 0.3169 - val_accuracy: 0.7446 - val_loss: 1.1456\n",
      "Epoch 47/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8909 - loss: 0.3024 - val_accuracy: 0.7422 - val_loss: 1.1782\n",
      "Epoch 48/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8886 - loss: 0.3065 - val_accuracy: 0.7418 - val_loss: 1.2411\n",
      "Epoch 49/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8889 - loss: 0.3043 - val_accuracy: 0.7396 - val_loss: 1.2561\n",
      "Epoch 50/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8871 - loss: 0.3113 - val_accuracy: 0.7395 - val_loss: 1.2745\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - accuracy: 0.7414 - loss: 1.2791\n",
      "Epoch 1/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.2757 - loss: 1.9383 - val_accuracy: 0.4480 - val_loss: 1.5625\n",
      "Epoch 2/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4846 - loss: 1.4353 - val_accuracy: 0.5775 - val_loss: 1.1787\n",
      "Epoch 3/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5595 - loss: 1.2349 - val_accuracy: 0.6347 - val_loss: 1.0317\n",
      "Epoch 4/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6069 - loss: 1.1241 - val_accuracy: 0.6559 - val_loss: 0.9724\n",
      "Epoch 5/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6433 - loss: 1.0204 - val_accuracy: 0.6850 - val_loss: 0.8962\n",
      "Epoch 6/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6763 - loss: 0.9288 - val_accuracy: 0.7066 - val_loss: 0.8408\n",
      "Epoch 7/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6972 - loss: 0.8785 - val_accuracy: 0.7041 - val_loss: 0.8584\n",
      "Epoch 8/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7079 - loss: 0.8369 - val_accuracy: 0.7177 - val_loss: 0.8184\n",
      "Epoch 9/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7240 - loss: 0.7929 - val_accuracy: 0.7262 - val_loss: 0.7870\n",
      "Epoch 10/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7371 - loss: 0.7486 - val_accuracy: 0.7354 - val_loss: 0.7708\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.7412 - loss: 0.7615\n",
      "Epoch 1/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.2803 - loss: 1.9382 - val_accuracy: 0.5423 - val_loss: 1.2664\n",
      "Epoch 2/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5310 - loss: 1.3180 - val_accuracy: 0.6191 - val_loss: 1.0519\n",
      "Epoch 3/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5963 - loss: 1.1494 - val_accuracy: 0.6704 - val_loss: 0.9267\n",
      "Epoch 4/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6511 - loss: 1.0001 - val_accuracy: 0.6871 - val_loss: 0.8909\n",
      "Epoch 5/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6749 - loss: 0.9265 - val_accuracy: 0.7107 - val_loss: 0.8211\n",
      "Epoch 6/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7066 - loss: 0.8545 - val_accuracy: 0.7173 - val_loss: 0.8009\n",
      "Epoch 7/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7198 - loss: 0.8119 - val_accuracy: 0.7362 - val_loss: 0.7741\n",
      "Epoch 8/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7336 - loss: 0.7605 - val_accuracy: 0.7296 - val_loss: 0.7995\n",
      "Epoch 9/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7537 - loss: 0.7112 - val_accuracy: 0.7441 - val_loss: 0.7542\n",
      "Epoch 10/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7647 - loss: 0.6805 - val_accuracy: 0.7491 - val_loss: 0.7421\n",
      "Epoch 11/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7758 - loss: 0.6470 - val_accuracy: 0.7356 - val_loss: 0.7861\n",
      "Epoch 12/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7819 - loss: 0.6204 - val_accuracy: 0.7528 - val_loss: 0.7558\n",
      "Epoch 13/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7911 - loss: 0.5946 - val_accuracy: 0.7442 - val_loss: 0.7679\n",
      "Epoch 14/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7970 - loss: 0.5739 - val_accuracy: 0.7490 - val_loss: 0.7824\n",
      "Epoch 15/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8065 - loss: 0.5508 - val_accuracy: 0.7630 - val_loss: 0.7468\n",
      "Epoch 16/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8100 - loss: 0.5292 - val_accuracy: 0.7513 - val_loss: 0.7868\n",
      "Epoch 17/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8173 - loss: 0.5122 - val_accuracy: 0.7579 - val_loss: 0.7777\n",
      "Epoch 18/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8265 - loss: 0.4862 - val_accuracy: 0.7614 - val_loss: 0.7676\n",
      "Epoch 19/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8276 - loss: 0.4823 - val_accuracy: 0.7587 - val_loss: 0.7790\n",
      "Epoch 20/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8338 - loss: 0.4542 - val_accuracy: 0.7561 - val_loss: 0.8478\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.7648 - loss: 0.8233\n",
      "Epoch 1/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.2551 - loss: 1.9742 - val_accuracy: 0.4934 - val_loss: 1.4184\n",
      "Epoch 2/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4821 - loss: 1.4333 - val_accuracy: 0.5947 - val_loss: 1.1230\n",
      "Epoch 3/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5691 - loss: 1.2139 - val_accuracy: 0.6520 - val_loss: 0.9892\n",
      "Epoch 4/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6130 - loss: 1.0946 - val_accuracy: 0.6673 - val_loss: 0.9580\n",
      "Epoch 5/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6577 - loss: 0.9812 - val_accuracy: 0.6796 - val_loss: 0.9074\n",
      "Epoch 6/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6759 - loss: 0.9211 - val_accuracy: 0.7139 - val_loss: 0.8192\n",
      "Epoch 7/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6970 - loss: 0.8680 - val_accuracy: 0.7150 - val_loss: 0.8198\n",
      "Epoch 8/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7083 - loss: 0.8365 - val_accuracy: 0.7188 - val_loss: 0.8007\n",
      "Epoch 9/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7286 - loss: 0.7781 - val_accuracy: 0.7257 - val_loss: 0.7954\n",
      "Epoch 10/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7385 - loss: 0.7596 - val_accuracy: 0.7248 - val_loss: 0.7948\n",
      "Epoch 11/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7537 - loss: 0.7049 - val_accuracy: 0.7342 - val_loss: 0.7735\n",
      "Epoch 12/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6809 - val_accuracy: 0.7470 - val_loss: 0.7480\n",
      "Epoch 13/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7731 - loss: 0.6527 - val_accuracy: 0.7379 - val_loss: 0.7606\n",
      "Epoch 14/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7816 - loss: 0.6280 - val_accuracy: 0.7405 - val_loss: 0.7890\n",
      "Epoch 15/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7895 - loss: 0.6049 - val_accuracy: 0.7445 - val_loss: 0.7633\n",
      "Epoch 16/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7986 - loss: 0.5728 - val_accuracy: 0.7521 - val_loss: 0.7900\n",
      "Epoch 17/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8025 - loss: 0.5538 - val_accuracy: 0.7564 - val_loss: 0.7534\n",
      "Epoch 18/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8131 - loss: 0.5279 - val_accuracy: 0.7413 - val_loss: 0.8078\n",
      "Epoch 19/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8157 - loss: 0.5240 - val_accuracy: 0.7507 - val_loss: 0.7950\n",
      "Epoch 20/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8223 - loss: 0.4977 - val_accuracy: 0.7515 - val_loss: 0.8096\n",
      "Epoch 21/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8270 - loss: 0.4841 - val_accuracy: 0.7548 - val_loss: 0.8042\n",
      "Epoch 22/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8325 - loss: 0.4639 - val_accuracy: 0.7552 - val_loss: 0.8129\n",
      "Epoch 23/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8353 - loss: 0.4551 - val_accuracy: 0.7497 - val_loss: 0.8606\n",
      "Epoch 24/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8413 - loss: 0.4428 - val_accuracy: 0.7495 - val_loss: 0.8667\n",
      "Epoch 25/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8491 - loss: 0.4223 - val_accuracy: 0.7489 - val_loss: 0.8899\n",
      "Epoch 26/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8484 - loss: 0.4179 - val_accuracy: 0.7574 - val_loss: 0.8766\n",
      "Epoch 27/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8497 - loss: 0.4105 - val_accuracy: 0.7599 - val_loss: 0.8598\n",
      "Epoch 28/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8567 - loss: 0.3979 - val_accuracy: 0.7523 - val_loss: 0.9295\n",
      "Epoch 29/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8631 - loss: 0.3757 - val_accuracy: 0.7556 - val_loss: 0.9133\n",
      "Epoch 30/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8698 - loss: 0.3628 - val_accuracy: 0.7443 - val_loss: 1.0035\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.7490 - loss: 0.9825\n",
      "Epoch 1/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.2718 - loss: 1.9434 - val_accuracy: 0.5118 - val_loss: 1.3553\n",
      "Epoch 2/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4905 - loss: 1.4147 - val_accuracy: 0.5958 - val_loss: 1.1380\n",
      "Epoch 3/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5605 - loss: 1.2248 - val_accuracy: 0.6259 - val_loss: 1.0569\n",
      "Epoch 4/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6096 - loss: 1.1161 - val_accuracy: 0.6664 - val_loss: 0.9452\n",
      "Epoch 5/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6408 - loss: 1.0081 - val_accuracy: 0.6772 - val_loss: 0.9064\n",
      "Epoch 6/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6609 - loss: 0.9605 - val_accuracy: 0.7010 - val_loss: 0.8506\n",
      "Epoch 7/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6859 - loss: 0.8955 - val_accuracy: 0.7117 - val_loss: 0.8254\n",
      "Epoch 8/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7019 - loss: 0.8603 - val_accuracy: 0.7088 - val_loss: 0.8363\n",
      "Epoch 9/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7141 - loss: 0.8179 - val_accuracy: 0.7197 - val_loss: 0.8223\n",
      "Epoch 10/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7267 - loss: 0.7802 - val_accuracy: 0.7317 - val_loss: 0.7749\n",
      "Epoch 11/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7397 - loss: 0.7436 - val_accuracy: 0.7260 - val_loss: 0.7973\n",
      "Epoch 12/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7460 - loss: 0.7279 - val_accuracy: 0.7317 - val_loss: 0.7789\n",
      "Epoch 13/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7620 - loss: 0.6862 - val_accuracy: 0.7412 - val_loss: 0.7690\n",
      "Epoch 14/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7634 - loss: 0.6665 - val_accuracy: 0.7338 - val_loss: 0.7849\n",
      "Epoch 15/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7699 - loss: 0.6561 - val_accuracy: 0.7405 - val_loss: 0.7758\n",
      "Epoch 16/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7777 - loss: 0.6223 - val_accuracy: 0.7385 - val_loss: 0.8091\n",
      "Epoch 17/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7862 - loss: 0.6024 - val_accuracy: 0.7405 - val_loss: 0.7930\n",
      "Epoch 18/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7937 - loss: 0.5821 - val_accuracy: 0.7429 - val_loss: 0.7998\n",
      "Epoch 19/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8018 - loss: 0.5568 - val_accuracy: 0.7404 - val_loss: 0.8038\n",
      "Epoch 20/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8079 - loss: 0.5433 - val_accuracy: 0.7466 - val_loss: 0.8049\n",
      "Epoch 21/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8069 - loss: 0.5409 - val_accuracy: 0.7493 - val_loss: 0.7771\n",
      "Epoch 22/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8118 - loss: 0.5204 - val_accuracy: 0.7426 - val_loss: 0.8274\n",
      "Epoch 23/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8134 - loss: 0.5212 - val_accuracy: 0.7439 - val_loss: 0.8393\n",
      "Epoch 24/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8211 - loss: 0.4895 - val_accuracy: 0.7459 - val_loss: 0.8454\n",
      "Epoch 25/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8259 - loss: 0.4852 - val_accuracy: 0.7503 - val_loss: 0.8585\n",
      "Epoch 26/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8280 - loss: 0.4738 - val_accuracy: 0.7440 - val_loss: 0.8364\n",
      "Epoch 27/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8379 - loss: 0.4490 - val_accuracy: 0.7406 - val_loss: 0.8884\n",
      "Epoch 28/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8353 - loss: 0.4439 - val_accuracy: 0.7468 - val_loss: 0.8648\n",
      "Epoch 29/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8395 - loss: 0.4426 - val_accuracy: 0.7426 - val_loss: 0.9428\n",
      "Epoch 30/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8449 - loss: 0.4267 - val_accuracy: 0.7432 - val_loss: 0.9152\n",
      "Epoch 31/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8448 - loss: 0.4198 - val_accuracy: 0.7448 - val_loss: 0.9234\n",
      "Epoch 32/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8493 - loss: 0.4063 - val_accuracy: 0.7409 - val_loss: 0.9751\n",
      "Epoch 33/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8568 - loss: 0.3846 - val_accuracy: 0.7459 - val_loss: 0.9451\n",
      "Epoch 34/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8587 - loss: 0.3830 - val_accuracy: 0.7455 - val_loss: 0.9553\n",
      "Epoch 35/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8558 - loss: 0.3823 - val_accuracy: 0.7470 - val_loss: 0.9876\n",
      "Epoch 36/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8647 - loss: 0.3651 - val_accuracy: 0.7443 - val_loss: 1.0483\n",
      "Epoch 37/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8619 - loss: 0.3664 - val_accuracy: 0.7312 - val_loss: 1.1517\n",
      "Epoch 38/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8638 - loss: 0.3705 - val_accuracy: 0.7427 - val_loss: 1.0559\n",
      "Epoch 39/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8711 - loss: 0.3423 - val_accuracy: 0.7384 - val_loss: 1.0897\n",
      "Epoch 40/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8718 - loss: 0.3470 - val_accuracy: 0.7455 - val_loss: 1.0870\n",
      "Epoch 41/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8706 - loss: 0.3391 - val_accuracy: 0.7427 - val_loss: 1.1023\n",
      "Epoch 42/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8772 - loss: 0.3238 - val_accuracy: 0.7426 - val_loss: 1.1323\n",
      "Epoch 43/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8813 - loss: 0.3223 - val_accuracy: 0.7403 - val_loss: 1.1387\n",
      "Epoch 44/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8777 - loss: 0.3306 - val_accuracy: 0.7450 - val_loss: 1.1275\n",
      "Epoch 45/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8803 - loss: 0.3232 - val_accuracy: 0.7451 - val_loss: 1.1379\n",
      "Epoch 46/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8847 - loss: 0.3049 - val_accuracy: 0.7435 - val_loss: 1.1963\n",
      "Epoch 47/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8837 - loss: 0.3098 - val_accuracy: 0.7420 - val_loss: 1.1438\n",
      "Epoch 48/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8889 - loss: 0.2985 - val_accuracy: 0.7452 - val_loss: 1.1663\n",
      "Epoch 49/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8919 - loss: 0.2886 - val_accuracy: 0.7389 - val_loss: 1.2773\n",
      "Epoch 50/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8869 - loss: 0.2966 - val_accuracy: 0.7482 - val_loss: 1.1979\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.7546 - loss: 1.1405\n",
      "Epoch 1/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.2455 - loss: 2.0052 - val_accuracy: 0.4796 - val_loss: 1.4135\n",
      "Epoch 2/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4594 - loss: 1.4857 - val_accuracy: 0.5666 - val_loss: 1.1995\n",
      "Epoch 3/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5372 - loss: 1.2834 - val_accuracy: 0.6276 - val_loss: 1.0574\n",
      "Epoch 4/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5992 - loss: 1.1479 - val_accuracy: 0.6536 - val_loss: 0.9876\n",
      "Epoch 5/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6317 - loss: 1.0588 - val_accuracy: 0.6698 - val_loss: 0.9258\n",
      "Epoch 6/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6587 - loss: 0.9833 - val_accuracy: 0.6898 - val_loss: 0.8911\n",
      "Epoch 7/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6812 - loss: 0.9221 - val_accuracy: 0.7142 - val_loss: 0.8139\n",
      "Epoch 8/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6981 - loss: 0.8756 - val_accuracy: 0.7241 - val_loss: 0.7961\n",
      "Epoch 9/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7152 - loss: 0.8248 - val_accuracy: 0.7221 - val_loss: 0.8060\n",
      "Epoch 10/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7252 - loss: 0.7935 - val_accuracy: 0.7376 - val_loss: 0.7538\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 980us/step - accuracy: 0.7376 - loss: 0.7481\n",
      "Epoch 1/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.2213 - loss: 2.0496 - val_accuracy: 0.4751 - val_loss: 1.4269\n",
      "Epoch 2/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4591 - loss: 1.4905 - val_accuracy: 0.5598 - val_loss: 1.2538\n",
      "Epoch 3/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5384 - loss: 1.2906 - val_accuracy: 0.6125 - val_loss: 1.0797\n",
      "Epoch 4/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5969 - loss: 1.1501 - val_accuracy: 0.6276 - val_loss: 1.0435\n",
      "Epoch 5/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6196 - loss: 1.0827 - val_accuracy: 0.6604 - val_loss: 0.9473\n",
      "Epoch 6/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6463 - loss: 1.0118 - val_accuracy: 0.6809 - val_loss: 0.9108\n",
      "Epoch 7/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6705 - loss: 0.9479 - val_accuracy: 0.7001 - val_loss: 0.8620\n",
      "Epoch 8/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6838 - loss: 0.9025 - val_accuracy: 0.7048 - val_loss: 0.8567\n",
      "Epoch 9/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7052 - loss: 0.8554 - val_accuracy: 0.7210 - val_loss: 0.7997\n",
      "Epoch 10/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7206 - loss: 0.8170 - val_accuracy: 0.7274 - val_loss: 0.7885\n",
      "Epoch 11/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7256 - loss: 0.7900 - val_accuracy: 0.7241 - val_loss: 0.7972\n",
      "Epoch 12/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7385 - loss: 0.7549 - val_accuracy: 0.7372 - val_loss: 0.7600\n",
      "Epoch 13/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7517 - loss: 0.7168 - val_accuracy: 0.7399 - val_loss: 0.7658\n",
      "Epoch 14/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7593 - loss: 0.6961 - val_accuracy: 0.7429 - val_loss: 0.7602\n",
      "Epoch 15/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7622 - loss: 0.6877 - val_accuracy: 0.7465 - val_loss: 0.7570\n",
      "Epoch 16/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7715 - loss: 0.6560 - val_accuracy: 0.7500 - val_loss: 0.7347\n",
      "Epoch 17/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7815 - loss: 0.6364 - val_accuracy: 0.7568 - val_loss: 0.7169\n",
      "Epoch 18/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7836 - loss: 0.6189 - val_accuracy: 0.7516 - val_loss: 0.7499\n",
      "Epoch 19/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7917 - loss: 0.6041 - val_accuracy: 0.7489 - val_loss: 0.7702\n",
      "Epoch 20/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7957 - loss: 0.5876 - val_accuracy: 0.7497 - val_loss: 0.7838\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.7564 - loss: 0.7646\n",
      "Epoch 1/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.2575 - loss: 1.9752 - val_accuracy: 0.4606 - val_loss: 1.4638\n",
      "Epoch 2/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4673 - loss: 1.4739 - val_accuracy: 0.5718 - val_loss: 1.1888\n",
      "Epoch 3/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5492 - loss: 1.2738 - val_accuracy: 0.6245 - val_loss: 1.0613\n",
      "Epoch 4/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6062 - loss: 1.1305 - val_accuracy: 0.6716 - val_loss: 0.9425\n",
      "Epoch 5/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6394 - loss: 1.0301 - val_accuracy: 0.6800 - val_loss: 0.9126\n",
      "Epoch 6/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6647 - loss: 0.9632 - val_accuracy: 0.7026 - val_loss: 0.8429\n",
      "Epoch 7/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6846 - loss: 0.9039 - val_accuracy: 0.7037 - val_loss: 0.8428\n",
      "Epoch 8/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7076 - loss: 0.8491 - val_accuracy: 0.7241 - val_loss: 0.7835\n",
      "Epoch 9/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7175 - loss: 0.8103 - val_accuracy: 0.7179 - val_loss: 0.8002\n",
      "Epoch 10/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7352 - loss: 0.7664 - val_accuracy: 0.7342 - val_loss: 0.7731\n",
      "Epoch 11/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7439 - loss: 0.7443 - val_accuracy: 0.7352 - val_loss: 0.7696\n",
      "Epoch 12/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7531 - loss: 0.7062 - val_accuracy: 0.7441 - val_loss: 0.7547\n",
      "Epoch 13/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7667 - loss: 0.6811 - val_accuracy: 0.7370 - val_loss: 0.7614\n",
      "Epoch 14/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7705 - loss: 0.6572 - val_accuracy: 0.7423 - val_loss: 0.7440\n",
      "Epoch 15/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7829 - loss: 0.6246 - val_accuracy: 0.7528 - val_loss: 0.7296\n",
      "Epoch 16/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7903 - loss: 0.6046 - val_accuracy: 0.7590 - val_loss: 0.7195\n",
      "Epoch 17/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8001 - loss: 0.5778 - val_accuracy: 0.7542 - val_loss: 0.7311\n",
      "Epoch 18/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8036 - loss: 0.5569 - val_accuracy: 0.7526 - val_loss: 0.7445\n",
      "Epoch 19/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8053 - loss: 0.5555 - val_accuracy: 0.7609 - val_loss: 0.7283\n",
      "Epoch 20/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8153 - loss: 0.5260 - val_accuracy: 0.7622 - val_loss: 0.7225\n",
      "Epoch 21/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8226 - loss: 0.5053 - val_accuracy: 0.7553 - val_loss: 0.7569\n",
      "Epoch 22/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8249 - loss: 0.4950 - val_accuracy: 0.7682 - val_loss: 0.7519\n",
      "Epoch 23/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8309 - loss: 0.4784 - val_accuracy: 0.7682 - val_loss: 0.7273\n",
      "Epoch 24/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8368 - loss: 0.4513 - val_accuracy: 0.7632 - val_loss: 0.7535\n",
      "Epoch 25/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8465 - loss: 0.4354 - val_accuracy: 0.7687 - val_loss: 0.7736\n",
      "Epoch 26/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8471 - loss: 0.4322 - val_accuracy: 0.7655 - val_loss: 0.7845\n",
      "Epoch 27/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8485 - loss: 0.4254 - val_accuracy: 0.7665 - val_loss: 0.8084\n",
      "Epoch 28/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8532 - loss: 0.4058 - val_accuracy: 0.7595 - val_loss: 0.8173\n",
      "Epoch 29/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8550 - loss: 0.4003 - val_accuracy: 0.7649 - val_loss: 0.8378\n",
      "Epoch 30/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8652 - loss: 0.3679 - val_accuracy: 0.7649 - val_loss: 0.8084\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.7701 - loss: 0.8044\n",
      "Epoch 1/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.2486 - loss: 1.9963 - val_accuracy: 0.5126 - val_loss: 1.3546\n",
      "Epoch 2/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4810 - loss: 1.4350 - val_accuracy: 0.5839 - val_loss: 1.1697\n",
      "Epoch 3/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5638 - loss: 1.2175 - val_accuracy: 0.6285 - val_loss: 1.0349\n",
      "Epoch 4/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6111 - loss: 1.0894 - val_accuracy: 0.6716 - val_loss: 0.9297\n",
      "Epoch 5/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6460 - loss: 1.0106 - val_accuracy: 0.6711 - val_loss: 0.9357\n",
      "Epoch 6/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6616 - loss: 0.9595 - val_accuracy: 0.7084 - val_loss: 0.8298\n",
      "Epoch 7/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6945 - loss: 0.8842 - val_accuracy: 0.7117 - val_loss: 0.8299\n",
      "Epoch 8/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7060 - loss: 0.8448 - val_accuracy: 0.7149 - val_loss: 0.8074\n",
      "Epoch 9/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7108 - loss: 0.8163 - val_accuracy: 0.7320 - val_loss: 0.7655\n",
      "Epoch 10/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7296 - loss: 0.7715 - val_accuracy: 0.7481 - val_loss: 0.7409\n",
      "Epoch 11/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7459 - loss: 0.7381 - val_accuracy: 0.7364 - val_loss: 0.7583\n",
      "Epoch 12/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7497 - loss: 0.7100 - val_accuracy: 0.7406 - val_loss: 0.7626\n",
      "Epoch 13/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7673 - loss: 0.6738 - val_accuracy: 0.7500 - val_loss: 0.7348\n",
      "Epoch 14/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7716 - loss: 0.6474 - val_accuracy: 0.7498 - val_loss: 0.7314\n",
      "Epoch 15/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7777 - loss: 0.6338 - val_accuracy: 0.7486 - val_loss: 0.7355\n",
      "Epoch 16/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7879 - loss: 0.6060 - val_accuracy: 0.7541 - val_loss: 0.7512\n",
      "Epoch 17/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7951 - loss: 0.5847 - val_accuracy: 0.7596 - val_loss: 0.7345\n",
      "Epoch 18/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8033 - loss: 0.5584 - val_accuracy: 0.7555 - val_loss: 0.7427\n",
      "Epoch 19/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8098 - loss: 0.5389 - val_accuracy: 0.7572 - val_loss: 0.7618\n",
      "Epoch 20/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8182 - loss: 0.5289 - val_accuracy: 0.7670 - val_loss: 0.7602\n",
      "Epoch 21/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8195 - loss: 0.5171 - val_accuracy: 0.7653 - val_loss: 0.7466\n",
      "Epoch 22/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8258 - loss: 0.4848 - val_accuracy: 0.7547 - val_loss: 0.7576\n",
      "Epoch 23/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8322 - loss: 0.4728 - val_accuracy: 0.7659 - val_loss: 0.7583\n",
      "Epoch 24/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8396 - loss: 0.4570 - val_accuracy: 0.7619 - val_loss: 0.7785\n",
      "Epoch 25/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8411 - loss: 0.4444 - val_accuracy: 0.7658 - val_loss: 0.7897\n",
      "Epoch 26/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8471 - loss: 0.4283 - val_accuracy: 0.7587 - val_loss: 0.8359\n",
      "Epoch 27/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8519 - loss: 0.4137 - val_accuracy: 0.7671 - val_loss: 0.7911\n",
      "Epoch 28/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8582 - loss: 0.3976 - val_accuracy: 0.7641 - val_loss: 0.8240\n",
      "Epoch 29/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8615 - loss: 0.3847 - val_accuracy: 0.7550 - val_loss: 0.8445\n",
      "Epoch 30/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8636 - loss: 0.3781 - val_accuracy: 0.7646 - val_loss: 0.8011\n",
      "Epoch 31/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8663 - loss: 0.3695 - val_accuracy: 0.7632 - val_loss: 0.8800\n",
      "Epoch 32/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8703 - loss: 0.3582 - val_accuracy: 0.7653 - val_loss: 0.8641\n",
      "Epoch 33/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8744 - loss: 0.3478 - val_accuracy: 0.7664 - val_loss: 0.8979\n",
      "Epoch 34/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8790 - loss: 0.3284 - val_accuracy: 0.7630 - val_loss: 0.9119\n",
      "Epoch 35/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8802 - loss: 0.3293 - val_accuracy: 0.7678 - val_loss: 0.9075\n",
      "Epoch 36/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8874 - loss: 0.3144 - val_accuracy: 0.7580 - val_loss: 0.9340\n",
      "Epoch 37/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8820 - loss: 0.3214 - val_accuracy: 0.7636 - val_loss: 0.9477\n",
      "Epoch 38/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8899 - loss: 0.2994 - val_accuracy: 0.7661 - val_loss: 0.9603\n",
      "Epoch 39/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8893 - loss: 0.3019 - val_accuracy: 0.7574 - val_loss: 0.9715\n",
      "Epoch 40/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8896 - loss: 0.2960 - val_accuracy: 0.7622 - val_loss: 1.0185\n",
      "Epoch 41/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8948 - loss: 0.2874 - val_accuracy: 0.7631 - val_loss: 1.0590\n",
      "Epoch 42/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8955 - loss: 0.2858 - val_accuracy: 0.7648 - val_loss: 1.0379\n",
      "Epoch 43/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9003 - loss: 0.2733 - val_accuracy: 0.7565 - val_loss: 1.0681\n",
      "Epoch 44/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8955 - loss: 0.2803 - val_accuracy: 0.7672 - val_loss: 1.1240\n",
      "Epoch 45/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9049 - loss: 0.2593 - val_accuracy: 0.7650 - val_loss: 1.1309\n",
      "Epoch 46/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9048 - loss: 0.2561 - val_accuracy: 0.7667 - val_loss: 1.1026\n",
      "Epoch 47/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9064 - loss: 0.2540 - val_accuracy: 0.7599 - val_loss: 1.1758\n",
      "Epoch 48/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9119 - loss: 0.2406 - val_accuracy: 0.7647 - val_loss: 1.1496\n",
      "Epoch 49/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9075 - loss: 0.2491 - val_accuracy: 0.7535 - val_loss: 1.1671\n",
      "Epoch 50/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9100 - loss: 0.2403 - val_accuracy: 0.7599 - val_loss: 1.2187\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.7706 - loss: 1.1871\n",
      "Epoch 1/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.2200 - loss: 2.0824 - val_accuracy: 0.4373 - val_loss: 1.5688\n",
      "Epoch 2/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4227 - loss: 1.5805 - val_accuracy: 0.5314 - val_loss: 1.3086\n",
      "Epoch 3/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5016 - loss: 1.3937 - val_accuracy: 0.5614 - val_loss: 1.2235\n",
      "Epoch 4/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5445 - loss: 1.2897 - val_accuracy: 0.5986 - val_loss: 1.1342\n",
      "Epoch 5/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5851 - loss: 1.1842 - val_accuracy: 0.6295 - val_loss: 1.0431\n",
      "Epoch 6/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6096 - loss: 1.1181 - val_accuracy: 0.6493 - val_loss: 0.9980\n",
      "Epoch 7/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6361 - loss: 1.0471 - val_accuracy: 0.6640 - val_loss: 0.9485\n",
      "Epoch 8/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6519 - loss: 0.9984 - val_accuracy: 0.6794 - val_loss: 0.9124\n",
      "Epoch 9/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6646 - loss: 0.9650 - val_accuracy: 0.6781 - val_loss: 0.9074\n",
      "Epoch 10/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6793 - loss: 0.9195 - val_accuracy: 0.7051 - val_loss: 0.8461\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.7107 - loss: 0.8290\n",
      "Epoch 1/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.2185 - loss: 2.0736 - val_accuracy: 0.4343 - val_loss: 1.5310\n",
      "Epoch 2/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4167 - loss: 1.5964 - val_accuracy: 0.5210 - val_loss: 1.3364\n",
      "Epoch 3/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5054 - loss: 1.3879 - val_accuracy: 0.5768 - val_loss: 1.1832\n",
      "Epoch 4/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5437 - loss: 1.2829 - val_accuracy: 0.6112 - val_loss: 1.0792\n",
      "Epoch 5/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5911 - loss: 1.1723 - val_accuracy: 0.6315 - val_loss: 1.0281\n",
      "Epoch 6/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6112 - loss: 1.0987 - val_accuracy: 0.6561 - val_loss: 0.9733\n",
      "Epoch 7/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6332 - loss: 1.0451 - val_accuracy: 0.6664 - val_loss: 0.9468\n",
      "Epoch 8/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6564 - loss: 0.9867 - val_accuracy: 0.6854 - val_loss: 0.8935\n",
      "Epoch 9/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6721 - loss: 0.9426 - val_accuracy: 0.6928 - val_loss: 0.8757\n",
      "Epoch 10/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6861 - loss: 0.9039 - val_accuracy: 0.7106 - val_loss: 0.8249\n",
      "Epoch 11/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6962 - loss: 0.8716 - val_accuracy: 0.7161 - val_loss: 0.8129\n",
      "Epoch 12/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7090 - loss: 0.8387 - val_accuracy: 0.7278 - val_loss: 0.7929\n",
      "Epoch 13/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7263 - loss: 0.7932 - val_accuracy: 0.7306 - val_loss: 0.7725\n",
      "Epoch 14/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7309 - loss: 0.7668 - val_accuracy: 0.7429 - val_loss: 0.7585\n",
      "Epoch 15/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7372 - loss: 0.7504 - val_accuracy: 0.7271 - val_loss: 0.7846\n",
      "Epoch 16/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7376 - loss: 0.7534 - val_accuracy: 0.7277 - val_loss: 0.8022\n",
      "Epoch 17/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7514 - loss: 0.7099 - val_accuracy: 0.7477 - val_loss: 0.7424\n",
      "Epoch 18/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7605 - loss: 0.6870 - val_accuracy: 0.7524 - val_loss: 0.7338\n",
      "Epoch 19/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7655 - loss: 0.6753 - val_accuracy: 0.7482 - val_loss: 0.7371\n",
      "Epoch 20/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7768 - loss: 0.6429 - val_accuracy: 0.7552 - val_loss: 0.7303\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.7605 - loss: 0.7182\n",
      "Epoch 1/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.2257 - loss: 2.0509 - val_accuracy: 0.4206 - val_loss: 1.5791\n",
      "Epoch 2/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4107 - loss: 1.6120 - val_accuracy: 0.5123 - val_loss: 1.3487\n",
      "Epoch 3/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4854 - loss: 1.4366 - val_accuracy: 0.5648 - val_loss: 1.2305\n",
      "Epoch 4/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5299 - loss: 1.3178 - val_accuracy: 0.5861 - val_loss: 1.1502\n",
      "Epoch 5/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5686 - loss: 1.2193 - val_accuracy: 0.5977 - val_loss: 1.1088\n",
      "Epoch 6/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5939 - loss: 1.1501 - val_accuracy: 0.6467 - val_loss: 1.0000\n",
      "Epoch 7/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6190 - loss: 1.0808 - val_accuracy: 0.6523 - val_loss: 0.9857\n",
      "Epoch 8/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6367 - loss: 1.0365 - val_accuracy: 0.6671 - val_loss: 0.9414\n",
      "Epoch 9/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6489 - loss: 0.9990 - val_accuracy: 0.6842 - val_loss: 0.8902\n",
      "Epoch 10/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6686 - loss: 0.9499 - val_accuracy: 0.6949 - val_loss: 0.8679\n",
      "Epoch 11/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6786 - loss: 0.9173 - val_accuracy: 0.7060 - val_loss: 0.8450\n",
      "Epoch 12/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6921 - loss: 0.8878 - val_accuracy: 0.7067 - val_loss: 0.8246\n",
      "Epoch 13/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6988 - loss: 0.8665 - val_accuracy: 0.7183 - val_loss: 0.8135\n",
      "Epoch 14/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7042 - loss: 0.8486 - val_accuracy: 0.7251 - val_loss: 0.7837\n",
      "Epoch 15/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7166 - loss: 0.8117 - val_accuracy: 0.7194 - val_loss: 0.7955\n",
      "Epoch 16/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7251 - loss: 0.7879 - val_accuracy: 0.7381 - val_loss: 0.7588\n",
      "Epoch 17/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7296 - loss: 0.7754 - val_accuracy: 0.7370 - val_loss: 0.7580\n",
      "Epoch 18/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7376 - loss: 0.7502 - val_accuracy: 0.7342 - val_loss: 0.7567\n",
      "Epoch 19/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7409 - loss: 0.7488 - val_accuracy: 0.7372 - val_loss: 0.7608\n",
      "Epoch 20/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7490 - loss: 0.7190 - val_accuracy: 0.7410 - val_loss: 0.7477\n",
      "Epoch 21/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7542 - loss: 0.6999 - val_accuracy: 0.7412 - val_loss: 0.7585\n",
      "Epoch 22/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7615 - loss: 0.6813 - val_accuracy: 0.7429 - val_loss: 0.7556\n",
      "Epoch 23/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7620 - loss: 0.6794 - val_accuracy: 0.7550 - val_loss: 0.7283\n",
      "Epoch 24/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7733 - loss: 0.6528 - val_accuracy: 0.7521 - val_loss: 0.7430\n",
      "Epoch 25/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7767 - loss: 0.6354 - val_accuracy: 0.7501 - val_loss: 0.7380\n",
      "Epoch 26/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7777 - loss: 0.6283 - val_accuracy: 0.7543 - val_loss: 0.7313\n",
      "Epoch 27/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7852 - loss: 0.6049 - val_accuracy: 0.7494 - val_loss: 0.7438\n",
      "Epoch 28/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7879 - loss: 0.5954 - val_accuracy: 0.7558 - val_loss: 0.7411\n",
      "Epoch 29/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7992 - loss: 0.5671 - val_accuracy: 0.7506 - val_loss: 0.7641\n",
      "Epoch 30/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7974 - loss: 0.5740 - val_accuracy: 0.7517 - val_loss: 0.7538\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.7512 - loss: 0.7460\n",
      "Epoch 1/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.2335 - loss: 2.0536 - val_accuracy: 0.4637 - val_loss: 1.4898\n",
      "Epoch 2/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4278 - loss: 1.5701 - val_accuracy: 0.5427 - val_loss: 1.2878\n",
      "Epoch 3/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5091 - loss: 1.3797 - val_accuracy: 0.5800 - val_loss: 1.1788\n",
      "Epoch 4/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5499 - loss: 1.2797 - val_accuracy: 0.6158 - val_loss: 1.0925\n",
      "Epoch 5/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5833 - loss: 1.1763 - val_accuracy: 0.6335 - val_loss: 1.0525\n",
      "Epoch 6/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6071 - loss: 1.1171 - val_accuracy: 0.6568 - val_loss: 0.9787\n",
      "Epoch 7/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6272 - loss: 1.0435 - val_accuracy: 0.6725 - val_loss: 0.9228\n",
      "Epoch 8/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6502 - loss: 0.9948 - val_accuracy: 0.6932 - val_loss: 0.8765\n",
      "Epoch 9/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6646 - loss: 0.9596 - val_accuracy: 0.6986 - val_loss: 0.8616\n",
      "Epoch 10/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6774 - loss: 0.9083 - val_accuracy: 0.7024 - val_loss: 0.8520\n",
      "Epoch 11/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6845 - loss: 0.9006 - val_accuracy: 0.7068 - val_loss: 0.8446\n",
      "Epoch 12/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6963 - loss: 0.8624 - val_accuracy: 0.7223 - val_loss: 0.7893\n",
      "Epoch 13/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7098 - loss: 0.8253 - val_accuracy: 0.7214 - val_loss: 0.8062\n",
      "Epoch 14/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7188 - loss: 0.8023 - val_accuracy: 0.7295 - val_loss: 0.7751\n",
      "Epoch 15/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7268 - loss: 0.7671 - val_accuracy: 0.7185 - val_loss: 0.8099\n",
      "Epoch 16/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7288 - loss: 0.7623 - val_accuracy: 0.7346 - val_loss: 0.7722\n",
      "Epoch 17/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7422 - loss: 0.7305 - val_accuracy: 0.7397 - val_loss: 0.7494\n",
      "Epoch 18/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7514 - loss: 0.7077 - val_accuracy: 0.7438 - val_loss: 0.7370\n",
      "Epoch 19/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7571 - loss: 0.6770 - val_accuracy: 0.7450 - val_loss: 0.7398\n",
      "Epoch 20/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7628 - loss: 0.6758 - val_accuracy: 0.7428 - val_loss: 0.7354\n",
      "Epoch 21/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7681 - loss: 0.6488 - val_accuracy: 0.7433 - val_loss: 0.7472\n",
      "Epoch 22/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7728 - loss: 0.6389 - val_accuracy: 0.7517 - val_loss: 0.7415\n",
      "Epoch 23/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7822 - loss: 0.6182 - val_accuracy: 0.7407 - val_loss: 0.7724\n",
      "Epoch 24/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7830 - loss: 0.6091 - val_accuracy: 0.7503 - val_loss: 0.7623\n",
      "Epoch 25/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7889 - loss: 0.5935 - val_accuracy: 0.7533 - val_loss: 0.7580\n",
      "Epoch 26/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7921 - loss: 0.5844 - val_accuracy: 0.7610 - val_loss: 0.7385\n",
      "Epoch 27/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7978 - loss: 0.5642 - val_accuracy: 0.7605 - val_loss: 0.7343\n",
      "Epoch 28/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8050 - loss: 0.5438 - val_accuracy: 0.7463 - val_loss: 0.7867\n",
      "Epoch 29/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8055 - loss: 0.5442 - val_accuracy: 0.7571 - val_loss: 0.7478\n",
      "Epoch 30/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8103 - loss: 0.5286 - val_accuracy: 0.7550 - val_loss: 0.7676\n",
      "Epoch 31/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8173 - loss: 0.5152 - val_accuracy: 0.7654 - val_loss: 0.7488\n",
      "Epoch 32/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8149 - loss: 0.5098 - val_accuracy: 0.7617 - val_loss: 0.7518\n",
      "Epoch 33/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8187 - loss: 0.4979 - val_accuracy: 0.7504 - val_loss: 0.8009\n",
      "Epoch 34/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8223 - loss: 0.4968 - val_accuracy: 0.7614 - val_loss: 0.7567\n",
      "Epoch 35/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8265 - loss: 0.4738 - val_accuracy: 0.7663 - val_loss: 0.7844\n",
      "Epoch 36/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8313 - loss: 0.4628 - val_accuracy: 0.7623 - val_loss: 0.7812\n",
      "Epoch 37/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8341 - loss: 0.4562 - val_accuracy: 0.7642 - val_loss: 0.7814\n",
      "Epoch 38/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8428 - loss: 0.4403 - val_accuracy: 0.7552 - val_loss: 0.7912\n",
      "Epoch 39/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8457 - loss: 0.4303 - val_accuracy: 0.7622 - val_loss: 0.8255\n",
      "Epoch 40/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8480 - loss: 0.4160 - val_accuracy: 0.7638 - val_loss: 0.7969\n",
      "Epoch 41/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8475 - loss: 0.4125 - val_accuracy: 0.7651 - val_loss: 0.8402\n",
      "Epoch 42/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8529 - loss: 0.3954 - val_accuracy: 0.7610 - val_loss: 0.8375\n",
      "Epoch 43/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8564 - loss: 0.3865 - val_accuracy: 0.7606 - val_loss: 0.8598\n",
      "Epoch 44/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8562 - loss: 0.3869 - val_accuracy: 0.7584 - val_loss: 0.8487\n",
      "Epoch 45/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8572 - loss: 0.3811 - val_accuracy: 0.7606 - val_loss: 0.8751\n",
      "Epoch 46/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8564 - loss: 0.3874 - val_accuracy: 0.7606 - val_loss: 0.9153\n",
      "Epoch 47/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8610 - loss: 0.3765 - val_accuracy: 0.7568 - val_loss: 0.9532\n",
      "Epoch 48/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8688 - loss: 0.3498 - val_accuracy: 0.7594 - val_loss: 0.9319\n",
      "Epoch 49/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8708 - loss: 0.3437 - val_accuracy: 0.7554 - val_loss: 0.9588\n",
      "Epoch 50/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8665 - loss: 0.3610 - val_accuracy: 0.7621 - val_loss: 0.9267\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - accuracy: 0.7691 - loss: 0.8934\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.1009 - loss: 2.3186 - val_accuracy: 0.1000 - val_loss: 2.3035\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0998 - loss: 2.3040 - val_accuracy: 0.1000 - val_loss: 2.3041\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0986 - loss: 2.3039 - val_accuracy: 0.1000 - val_loss: 2.3037\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1002 - loss: 2.3040 - val_accuracy: 0.1000 - val_loss: 2.3036\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0991 - loss: 2.3038 - val_accuracy: 0.1000 - val_loss: 2.3034\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1029 - loss: 2.3038 - val_accuracy: 0.1000 - val_loss: 2.3039\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1010 - loss: 2.3040 - val_accuracy: 0.1000 - val_loss: 2.3045\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1006 - loss: 2.3037 - val_accuracy: 0.1000 - val_loss: 2.3038\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1016 - loss: 2.3039 - val_accuracy: 0.1000 - val_loss: 2.3043\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0989 - loss: 2.3040 - val_accuracy: 0.1000 - val_loss: 2.3035\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.0987 - loss: 2.3037\n",
      "Epoch 1/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.0979 - loss: 2.3323 - val_accuracy: 0.1000 - val_loss: 2.3042\n",
      "Epoch 2/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0986 - loss: 2.3040 - val_accuracy: 0.1000 - val_loss: 2.3039\n",
      "Epoch 3/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0996 - loss: 2.3042 - val_accuracy: 0.1000 - val_loss: 2.3038\n",
      "Epoch 4/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0993 - loss: 2.3036 - val_accuracy: 0.1000 - val_loss: 2.3041\n",
      "Epoch 5/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1017 - loss: 2.3039 - val_accuracy: 0.1000 - val_loss: 2.3036\n",
      "Epoch 6/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0983 - loss: 2.3039 - val_accuracy: 0.1000 - val_loss: 2.3050\n",
      "Epoch 7/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0984 - loss: 2.3040 - val_accuracy: 0.1000 - val_loss: 2.3038\n",
      "Epoch 8/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1009 - loss: 2.3041 - val_accuracy: 0.1000 - val_loss: 2.3034\n",
      "Epoch 9/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0985 - loss: 2.3040 - val_accuracy: 0.1000 - val_loss: 2.3033\n",
      "Epoch 10/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1000 - loss: 2.3040 - val_accuracy: 0.1000 - val_loss: 2.3033\n",
      "Epoch 11/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1000 - loss: 2.3038 - val_accuracy: 0.1000 - val_loss: 2.3032\n",
      "Epoch 12/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0969 - loss: 2.3041 - val_accuracy: 0.1000 - val_loss: 2.3039\n",
      "Epoch 13/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0989 - loss: 2.3041 - val_accuracy: 0.1000 - val_loss: 2.3036\n",
      "Epoch 14/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0988 - loss: 2.3040 - val_accuracy: 0.1000 - val_loss: 2.3039\n",
      "Epoch 15/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1014 - loss: 2.3038 - val_accuracy: 0.1000 - val_loss: 2.3037\n",
      "Epoch 16/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0978 - loss: 2.3042 - val_accuracy: 0.1000 - val_loss: 2.3031\n",
      "Epoch 17/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0993 - loss: 2.3039 - val_accuracy: 0.1000 - val_loss: 2.3044\n",
      "Epoch 18/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0978 - loss: 2.3042 - val_accuracy: 0.1000 - val_loss: 2.3046\n",
      "Epoch 19/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1007 - loss: 2.3041 - val_accuracy: 0.1000 - val_loss: 2.3038\n",
      "Epoch 20/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1002 - loss: 2.3038 - val_accuracy: 0.1000 - val_loss: 2.3035\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.0975 - loss: 2.3038\n",
      "Epoch 1/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.0994 - loss: 2.3088 - val_accuracy: 0.1000 - val_loss: 2.3037\n",
      "Epoch 2/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0986 - loss: 2.3039 - val_accuracy: 0.1000 - val_loss: 2.3033\n",
      "Epoch 3/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1027 - loss: 2.3038 - val_accuracy: 0.1000 - val_loss: 2.3033\n",
      "Epoch 4/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1033 - loss: 2.3038 - val_accuracy: 0.1000 - val_loss: 2.3036\n",
      "Epoch 5/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0984 - loss: 2.3039 - val_accuracy: 0.1000 - val_loss: 2.3039\n",
      "Epoch 6/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1009 - loss: 2.3041 - val_accuracy: 0.1000 - val_loss: 2.3033\n",
      "Epoch 7/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0993 - loss: 2.3039 - val_accuracy: 0.1000 - val_loss: 2.3038\n",
      "Epoch 8/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0978 - loss: 2.3042 - val_accuracy: 0.1000 - val_loss: 2.3041\n",
      "Epoch 9/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1012 - loss: 2.3041 - val_accuracy: 0.1000 - val_loss: 2.3041\n",
      "Epoch 10/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0978 - loss: 2.3040 - val_accuracy: 0.1000 - val_loss: 2.3034\n",
      "Epoch 11/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0956 - loss: 2.3041 - val_accuracy: 0.1000 - val_loss: 2.3041\n",
      "Epoch 12/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0986 - loss: 2.3040 - val_accuracy: 0.1000 - val_loss: 2.3036\n",
      "Epoch 13/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1011 - loss: 2.3040 - val_accuracy: 0.1000 - val_loss: 2.3036\n",
      "Epoch 14/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1012 - loss: 2.3039 - val_accuracy: 0.1000 - val_loss: 2.3042\n",
      "Epoch 15/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0974 - loss: 2.3037 - val_accuracy: 0.1000 - val_loss: 2.3059\n",
      "Epoch 16/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0978 - loss: 2.3044 - val_accuracy: 0.1000 - val_loss: 2.3037\n",
      "Epoch 17/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1010 - loss: 2.3038 - val_accuracy: 0.1000 - val_loss: 2.3031\n",
      "Epoch 18/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1004 - loss: 2.3041 - val_accuracy: 0.1000 - val_loss: 2.3031\n",
      "Epoch 19/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0966 - loss: 2.3041 - val_accuracy: 0.1000 - val_loss: 2.3032\n",
      "Epoch 20/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0990 - loss: 2.3041 - val_accuracy: 0.1000 - val_loss: 2.3042\n",
      "Epoch 21/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0993 - loss: 2.3038 - val_accuracy: 0.1000 - val_loss: 2.3042\n",
      "Epoch 22/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0979 - loss: 2.3043 - val_accuracy: 0.1000 - val_loss: 2.3044\n",
      "Epoch 23/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1018 - loss: 2.3037 - val_accuracy: 0.1000 - val_loss: 2.3036\n",
      "Epoch 24/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1038 - loss: 2.3038 - val_accuracy: 0.1000 - val_loss: 2.3039\n",
      "Epoch 25/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0985 - loss: 2.3039 - val_accuracy: 0.1000 - val_loss: 2.3030\n",
      "Epoch 26/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0982 - loss: 2.3040 - val_accuracy: 0.1000 - val_loss: 2.3034\n",
      "Epoch 27/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0977 - loss: 2.3043 - val_accuracy: 0.1000 - val_loss: 2.3040\n",
      "Epoch 28/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1000 - loss: 2.3039 - val_accuracy: 0.1000 - val_loss: 2.3037\n",
      "Epoch 29/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0993 - loss: 2.3038 - val_accuracy: 0.1000 - val_loss: 2.3039\n",
      "Epoch 30/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0983 - loss: 2.3041 - val_accuracy: 0.1000 - val_loss: 2.3037\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.0987 - loss: 2.3040\n",
      "Epoch 1/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.1024 - loss: 2.3183 - val_accuracy: 0.1000 - val_loss: 2.3033\n",
      "Epoch 2/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0973 - loss: 2.3040 - val_accuracy: 0.1000 - val_loss: 2.3034\n",
      "Epoch 3/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1016 - loss: 2.3037 - val_accuracy: 0.1000 - val_loss: 2.3030\n",
      "Epoch 4/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1008 - loss: 2.3038 - val_accuracy: 0.1000 - val_loss: 2.3035\n",
      "Epoch 5/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0970 - loss: 2.3040 - val_accuracy: 0.1000 - val_loss: 2.3037\n",
      "Epoch 6/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0964 - loss: 2.3038 - val_accuracy: 0.1000 - val_loss: 2.3038\n",
      "Epoch 7/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0981 - loss: 2.3040 - val_accuracy: 0.1000 - val_loss: 2.3034\n",
      "Epoch 8/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1003 - loss: 2.3041 - val_accuracy: 0.1000 - val_loss: 2.3040\n",
      "Epoch 9/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0992 - loss: 2.3040 - val_accuracy: 0.1000 - val_loss: 2.3052\n",
      "Epoch 10/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0983 - loss: 2.3046 - val_accuracy: 0.1000 - val_loss: 2.3031\n",
      "Epoch 11/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0994 - loss: 2.3040 - val_accuracy: 0.1000 - val_loss: 2.3035\n",
      "Epoch 12/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0990 - loss: 2.3039 - val_accuracy: 0.1000 - val_loss: 2.3041\n",
      "Epoch 13/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0961 - loss: 2.3042 - val_accuracy: 0.1000 - val_loss: 2.3042\n",
      "Epoch 14/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0972 - loss: 2.3041 - val_accuracy: 0.1000 - val_loss: 2.3031\n",
      "Epoch 15/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0984 - loss: 2.3040 - val_accuracy: 0.1000 - val_loss: 2.3039\n",
      "Epoch 16/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0990 - loss: 2.3040 - val_accuracy: 0.1000 - val_loss: 2.3034\n",
      "Epoch 17/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0985 - loss: 2.3040 - val_accuracy: 0.1000 - val_loss: 2.3034\n",
      "Epoch 18/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1021 - loss: 2.3035 - val_accuracy: 0.1000 - val_loss: 2.3041\n",
      "Epoch 19/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0997 - loss: 2.3040 - val_accuracy: 0.1000 - val_loss: 2.3030\n",
      "Epoch 20/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0971 - loss: 2.3042 - val_accuracy: 0.1000 - val_loss: 2.3035\n",
      "Epoch 21/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0996 - loss: 2.3042 - val_accuracy: 0.1000 - val_loss: 2.3033\n",
      "Epoch 22/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1006 - loss: 2.3038 - val_accuracy: 0.1000 - val_loss: 2.3033\n",
      "Epoch 23/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0983 - loss: 2.3039 - val_accuracy: 0.1000 - val_loss: 2.3030\n",
      "Epoch 24/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1025 - loss: 2.3038 - val_accuracy: 0.1000 - val_loss: 2.3036\n",
      "Epoch 25/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0990 - loss: 2.3041 - val_accuracy: 0.1000 - val_loss: 2.3037\n",
      "Epoch 26/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0961 - loss: 2.3042 - val_accuracy: 0.1000 - val_loss: 2.3039\n",
      "Epoch 27/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0961 - loss: 2.3042 - val_accuracy: 0.1000 - val_loss: 2.3035\n",
      "Epoch 28/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1018 - loss: 2.3039 - val_accuracy: 0.1000 - val_loss: 2.3034\n",
      "Epoch 29/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1000 - loss: 2.3038 - val_accuracy: 0.1000 - val_loss: 2.3035\n",
      "Epoch 30/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1010 - loss: 2.3041 - val_accuracy: 0.1000 - val_loss: 2.3039\n",
      "Epoch 31/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1033 - loss: 2.3037 - val_accuracy: 0.1000 - val_loss: 2.3037\n",
      "Epoch 32/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1017 - loss: 2.3038 - val_accuracy: 0.1000 - val_loss: 2.3032\n",
      "Epoch 33/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0998 - loss: 2.3039 - val_accuracy: 0.1000 - val_loss: 2.3034\n",
      "Epoch 34/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0970 - loss: 2.3040 - val_accuracy: 0.1000 - val_loss: 2.3036\n",
      "Epoch 35/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0978 - loss: 2.3039 - val_accuracy: 0.1000 - val_loss: 2.3039\n",
      "Epoch 36/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1031 - loss: 2.3037 - val_accuracy: 0.1000 - val_loss: 2.3035\n",
      "Epoch 37/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1022 - loss: 2.3039 - val_accuracy: 0.1000 - val_loss: 2.3038\n",
      "Epoch 38/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1009 - loss: 2.3043 - val_accuracy: 0.1000 - val_loss: 2.3044\n",
      "Epoch 39/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1017 - loss: 2.3038 - val_accuracy: 0.1000 - val_loss: 2.3057\n",
      "Epoch 40/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0959 - loss: 2.3045 - val_accuracy: 0.1000 - val_loss: 2.3031\n",
      "Epoch 41/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1024 - loss: 2.3038 - val_accuracy: 0.1000 - val_loss: 2.3039\n",
      "Epoch 42/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0982 - loss: 2.3041 - val_accuracy: 0.1000 - val_loss: 2.3037\n",
      "Epoch 43/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0985 - loss: 2.3041 - val_accuracy: 0.1000 - val_loss: 2.3042\n",
      "Epoch 44/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0984 - loss: 2.3041 - val_accuracy: 0.1000 - val_loss: 2.3036\n",
      "Epoch 45/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0986 - loss: 2.3041 - val_accuracy: 0.1000 - val_loss: 2.3039\n",
      "Epoch 46/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0999 - loss: 2.3041 - val_accuracy: 0.1000 - val_loss: 2.3037\n",
      "Epoch 47/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0947 - loss: 2.3040 - val_accuracy: 0.1000 - val_loss: 2.3036\n",
      "Epoch 48/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0991 - loss: 2.3041 - val_accuracy: 0.1000 - val_loss: 2.3035\n",
      "Epoch 49/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0997 - loss: 2.3041 - val_accuracy: 0.1000 - val_loss: 2.3035\n",
      "Epoch 50/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0992 - loss: 2.3038 - val_accuracy: 0.1000 - val_loss: 2.3034\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.1036 - loss: 2.3030\n",
      "Epoch 1/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.0994 - loss: 2.3147 - val_accuracy: 0.1000 - val_loss: 2.3037\n",
      "Epoch 2/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0991 - loss: 2.3036 - val_accuracy: 0.1000 - val_loss: 2.3034\n",
      "Epoch 3/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1000 - loss: 2.3035 - val_accuracy: 0.1000 - val_loss: 2.3037\n",
      "Epoch 4/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0961 - loss: 2.3039 - val_accuracy: 0.1000 - val_loss: 2.3035\n",
      "Epoch 5/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0989 - loss: 2.3037 - val_accuracy: 0.1000 - val_loss: 2.3043\n",
      "Epoch 6/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0977 - loss: 2.3034 - val_accuracy: 0.1000 - val_loss: 2.3046\n",
      "Epoch 7/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1008 - loss: 2.3033 - val_accuracy: 0.1000 - val_loss: 2.3035\n",
      "Epoch 8/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0973 - loss: 2.3037 - val_accuracy: 0.1000 - val_loss: 2.3029\n",
      "Epoch 9/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0989 - loss: 2.3036 - val_accuracy: 0.1000 - val_loss: 2.3032\n",
      "Epoch 10/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.1005 - loss: 2.3034 - val_accuracy: 0.1000 - val_loss: 2.3035\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 994us/step - accuracy: 0.0968 - loss: 2.3039\n",
      "Epoch 1/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1017 - loss: 2.3122 - val_accuracy: 0.1000 - val_loss: 2.3040\n",
      "Epoch 2/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0994 - loss: 2.3037 - val_accuracy: 0.1000 - val_loss: 2.3040\n",
      "Epoch 3/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1052 - loss: 2.3035 - val_accuracy: 0.1000 - val_loss: 2.3029\n",
      "Epoch 4/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0983 - loss: 2.3035 - val_accuracy: 0.1000 - val_loss: 2.3035\n",
      "Epoch 5/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1005 - loss: 2.3035 - val_accuracy: 0.1000 - val_loss: 2.3034\n",
      "Epoch 6/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1001 - loss: 2.3037 - val_accuracy: 0.1000 - val_loss: 2.3032\n",
      "Epoch 7/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0991 - loss: 2.3035 - val_accuracy: 0.1000 - val_loss: 2.3034\n",
      "Epoch 8/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0999 - loss: 2.3035 - val_accuracy: 0.1000 - val_loss: 2.3033\n",
      "Epoch 9/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0979 - loss: 2.3038 - val_accuracy: 0.1000 - val_loss: 2.3036\n",
      "Epoch 10/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0986 - loss: 2.3038 - val_accuracy: 0.1000 - val_loss: 2.3048\n",
      "Epoch 11/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0997 - loss: 2.3039 - val_accuracy: 0.1000 - val_loss: 2.3032\n",
      "Epoch 12/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1006 - loss: 2.3034 - val_accuracy: 0.1000 - val_loss: 2.3036\n",
      "Epoch 13/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0976 - loss: 2.3037 - val_accuracy: 0.1000 - val_loss: 2.3041\n",
      "Epoch 14/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0994 - loss: 2.3038 - val_accuracy: 0.1000 - val_loss: 2.3034\n",
      "Epoch 15/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1017 - loss: 2.3035 - val_accuracy: 0.1000 - val_loss: 2.3029\n",
      "Epoch 16/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0997 - loss: 2.3036 - val_accuracy: 0.1000 - val_loss: 2.3033\n",
      "Epoch 17/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0966 - loss: 2.3036 - val_accuracy: 0.1000 - val_loss: 2.3043\n",
      "Epoch 18/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0991 - loss: 2.3038 - val_accuracy: 0.1000 - val_loss: 2.3038\n",
      "Epoch 19/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0994 - loss: 2.3035 - val_accuracy: 0.1000 - val_loss: 2.3035\n",
      "Epoch 20/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0987 - loss: 2.3037 - val_accuracy: 0.1000 - val_loss: 2.3037\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.0995 - loss: 2.3040\n",
      "Epoch 1/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.0976 - loss: 2.3606 - val_accuracy: 0.1000 - val_loss: 2.3034\n",
      "Epoch 2/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0974 - loss: 2.3035 - val_accuracy: 0.1000 - val_loss: 2.3034\n",
      "Epoch 3/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1009 - loss: 2.3036 - val_accuracy: 0.1000 - val_loss: 2.3043\n",
      "Epoch 4/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0988 - loss: 2.3039 - val_accuracy: 0.1000 - val_loss: 2.3036\n",
      "Epoch 5/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1012 - loss: 2.3038 - val_accuracy: 0.1000 - val_loss: 2.3031\n",
      "Epoch 6/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1027 - loss: 2.3033 - val_accuracy: 0.1000 - val_loss: 2.3039\n",
      "Epoch 7/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0974 - loss: 2.3036 - val_accuracy: 0.1000 - val_loss: 2.3036\n",
      "Epoch 8/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0975 - loss: 2.3038 - val_accuracy: 0.1000 - val_loss: 2.3036\n",
      "Epoch 9/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1010 - loss: 2.3038 - val_accuracy: 0.1000 - val_loss: 2.3039\n",
      "Epoch 10/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0984 - loss: 2.3036 - val_accuracy: 0.1000 - val_loss: 2.3040\n",
      "Epoch 11/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0991 - loss: 2.3036 - val_accuracy: 0.1000 - val_loss: 2.3036\n",
      "Epoch 12/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0967 - loss: 2.3037 - val_accuracy: 0.1000 - val_loss: 2.3040\n",
      "Epoch 13/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1019 - loss: 2.3035 - val_accuracy: 0.1000 - val_loss: 2.3033\n",
      "Epoch 14/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1026 - loss: 2.3037 - val_accuracy: 0.1000 - val_loss: 2.3039\n",
      "Epoch 15/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0985 - loss: 2.3037 - val_accuracy: 0.1000 - val_loss: 2.3030\n",
      "Epoch 16/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0960 - loss: 2.3036 - val_accuracy: 0.1000 - val_loss: 2.3031\n",
      "Epoch 17/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0960 - loss: 2.3037 - val_accuracy: 0.1000 - val_loss: 2.3032\n",
      "Epoch 18/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0998 - loss: 2.3032 - val_accuracy: 0.1000 - val_loss: 2.3032\n",
      "Epoch 19/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0980 - loss: 2.3035 - val_accuracy: 0.1000 - val_loss: 2.3030\n",
      "Epoch 20/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0962 - loss: 2.3036 - val_accuracy: 0.1000 - val_loss: 2.3038\n",
      "Epoch 21/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1001 - loss: 2.3033 - val_accuracy: 0.1000 - val_loss: 2.3027\n",
      "Epoch 22/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1000 - loss: 2.3034 - val_accuracy: 0.1000 - val_loss: 2.3045\n",
      "Epoch 23/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1021 - loss: 2.3035 - val_accuracy: 0.1000 - val_loss: 2.3036\n",
      "Epoch 24/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1011 - loss: 2.3033 - val_accuracy: 0.1000 - val_loss: 2.3038\n",
      "Epoch 25/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1024 - loss: 2.3036 - val_accuracy: 0.1000 - val_loss: 2.3036\n",
      "Epoch 26/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1011 - loss: 2.3035 - val_accuracy: 0.1000 - val_loss: 2.3033\n",
      "Epoch 27/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0976 - loss: 2.3034 - val_accuracy: 0.1000 - val_loss: 2.3047\n",
      "Epoch 28/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0982 - loss: 2.3036 - val_accuracy: 0.1000 - val_loss: 2.3043\n",
      "Epoch 29/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0988 - loss: 2.3036 - val_accuracy: 0.1000 - val_loss: 2.3035\n",
      "Epoch 30/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0988 - loss: 2.3037 - val_accuracy: 0.1000 - val_loss: 2.3032\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0987 - loss: 2.3032\n",
      "Epoch 1/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.1002 - loss: 2.3138 - val_accuracy: 0.1000 - val_loss: 2.3029\n",
      "Epoch 2/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0972 - loss: 2.3036 - val_accuracy: 0.1000 - val_loss: 2.3029\n",
      "Epoch 3/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0994 - loss: 2.3035 - val_accuracy: 0.1000 - val_loss: 2.3032\n",
      "Epoch 4/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0978 - loss: 2.3037 - val_accuracy: 0.1000 - val_loss: 2.3035\n",
      "Epoch 5/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0988 - loss: 2.3037 - val_accuracy: 0.1000 - val_loss: 2.3043\n",
      "Epoch 6/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0997 - loss: 2.3036 - val_accuracy: 0.1000 - val_loss: 2.3031\n",
      "Epoch 7/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1001 - loss: 2.3036 - val_accuracy: 0.1000 - val_loss: 2.3030\n",
      "Epoch 8/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1037 - loss: 2.3034 - val_accuracy: 0.1000 - val_loss: 2.3034\n",
      "Epoch 9/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0941 - loss: 2.3039 - val_accuracy: 0.1000 - val_loss: 2.3030\n",
      "Epoch 10/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1012 - loss: 2.3035 - val_accuracy: 0.1000 - val_loss: 2.3034\n",
      "Epoch 11/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1021 - loss: 2.3035 - val_accuracy: 0.1000 - val_loss: 2.3036\n",
      "Epoch 12/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0990 - loss: 2.3037 - val_accuracy: 0.1000 - val_loss: 2.3030\n",
      "Epoch 13/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1005 - loss: 2.3036 - val_accuracy: 0.1000 - val_loss: 2.3039\n",
      "Epoch 14/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1001 - loss: 2.3037 - val_accuracy: 0.1000 - val_loss: 2.3031\n",
      "Epoch 15/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0989 - loss: 2.3037 - val_accuracy: 0.1000 - val_loss: 2.3033\n",
      "Epoch 16/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0992 - loss: 2.3034 - val_accuracy: 0.1000 - val_loss: 2.3032\n",
      "Epoch 17/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1011 - loss: 2.3034 - val_accuracy: 0.1000 - val_loss: 2.3034\n",
      "Epoch 18/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1030 - loss: 2.3033 - val_accuracy: 0.1000 - val_loss: 2.3037\n",
      "Epoch 19/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0965 - loss: 2.3038 - val_accuracy: 0.1000 - val_loss: 2.3034\n",
      "Epoch 20/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0976 - loss: 2.3037 - val_accuracy: 0.1000 - val_loss: 2.3032\n",
      "Epoch 21/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0964 - loss: 2.3036 - val_accuracy: 0.1000 - val_loss: 2.3037\n",
      "Epoch 22/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1024 - loss: 2.3036 - val_accuracy: 0.1000 - val_loss: 2.3031\n",
      "Epoch 23/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1000 - loss: 2.3033 - val_accuracy: 0.1000 - val_loss: 2.3033\n",
      "Epoch 24/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0983 - loss: 2.3033 - val_accuracy: 0.1000 - val_loss: 2.3032\n",
      "Epoch 25/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1026 - loss: 2.3034 - val_accuracy: 0.1000 - val_loss: 2.3035\n",
      "Epoch 26/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1007 - loss: 2.3038 - val_accuracy: 0.1000 - val_loss: 2.3037\n",
      "Epoch 27/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1009 - loss: 2.3038 - val_accuracy: 0.1000 - val_loss: 2.3036\n",
      "Epoch 28/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1023 - loss: 2.3035 - val_accuracy: 0.1000 - val_loss: 2.3030\n",
      "Epoch 29/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1012 - loss: 2.3034 - val_accuracy: 0.1000 - val_loss: 2.3031\n",
      "Epoch 30/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0985 - loss: 2.3035 - val_accuracy: 0.1000 - val_loss: 2.3030\n",
      "Epoch 31/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0982 - loss: 2.3037 - val_accuracy: 0.1000 - val_loss: 2.3029\n",
      "Epoch 32/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0975 - loss: 2.3035 - val_accuracy: 0.1000 - val_loss: 2.3029\n",
      "Epoch 33/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1018 - loss: 2.3034 - val_accuracy: 0.1000 - val_loss: 2.3046\n",
      "Epoch 34/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1007 - loss: 2.3034 - val_accuracy: 0.1000 - val_loss: 2.3044\n",
      "Epoch 35/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1013 - loss: 2.3039 - val_accuracy: 0.1000 - val_loss: 2.3034\n",
      "Epoch 36/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0985 - loss: 2.3034 - val_accuracy: 0.1000 - val_loss: 2.3032\n",
      "Epoch 37/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1018 - loss: 2.3037 - val_accuracy: 0.1000 - val_loss: 2.3036\n",
      "Epoch 38/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0981 - loss: 2.3038 - val_accuracy: 0.1000 - val_loss: 2.3032\n",
      "Epoch 39/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0994 - loss: 2.3036 - val_accuracy: 0.1000 - val_loss: 2.3030\n",
      "Epoch 40/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0985 - loss: 2.3036 - val_accuracy: 0.1000 - val_loss: 2.3038\n",
      "Epoch 41/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0988 - loss: 2.3037 - val_accuracy: 0.1000 - val_loss: 2.3030\n",
      "Epoch 42/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1005 - loss: 2.3036 - val_accuracy: 0.1000 - val_loss: 2.3033\n",
      "Epoch 43/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1006 - loss: 2.3037 - val_accuracy: 0.1000 - val_loss: 2.3037\n",
      "Epoch 44/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0990 - loss: 2.3037 - val_accuracy: 0.1000 - val_loss: 2.3034\n",
      "Epoch 45/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0976 - loss: 2.3034 - val_accuracy: 0.1000 - val_loss: 2.3034\n",
      "Epoch 46/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0960 - loss: 2.3037 - val_accuracy: 0.1000 - val_loss: 2.3033\n",
      "Epoch 47/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0985 - loss: 2.3037 - val_accuracy: 0.1000 - val_loss: 2.3041\n",
      "Epoch 48/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0978 - loss: 2.3037 - val_accuracy: 0.1000 - val_loss: 2.3036\n",
      "Epoch 49/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1008 - loss: 2.3036 - val_accuracy: 0.1000 - val_loss: 2.3036\n",
      "Epoch 50/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.1004 - loss: 2.3038 - val_accuracy: 0.1000 - val_loss: 2.3037\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.0987 - loss: 2.3036\n",
      "Epoch 1/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.1715 - loss: 2.1946 - val_accuracy: 0.2732 - val_loss: 1.9345\n",
      "Epoch 2/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2490 - loss: 1.9990 - val_accuracy: 0.3219 - val_loss: 1.8581\n",
      "Epoch 3/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2712 - loss: 1.9396 - val_accuracy: 0.3291 - val_loss: 1.8063\n",
      "Epoch 4/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2819 - loss: 1.8970 - val_accuracy: 0.3468 - val_loss: 1.8020\n",
      "Epoch 5/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2911 - loss: 1.8943 - val_accuracy: 0.3555 - val_loss: 1.7546\n",
      "Epoch 6/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3136 - loss: 1.8434 - val_accuracy: 0.3595 - val_loss: 1.7307\n",
      "Epoch 7/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3143 - loss: 1.8403 - val_accuracy: 0.3685 - val_loss: 1.7389\n",
      "Epoch 8/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3311 - loss: 1.8175 - val_accuracy: 0.3540 - val_loss: 1.7566\n",
      "Epoch 9/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3312 - loss: 1.7963 - val_accuracy: 0.3942 - val_loss: 1.6562\n",
      "Epoch 10/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3461 - loss: 1.7725 - val_accuracy: 0.3820 - val_loss: 1.6447\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.3898 - loss: 1.6450\n",
      "Epoch 1/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.0990 - loss: 2.3347 - val_accuracy: 0.1000 - val_loss: 2.3031\n",
      "Epoch 2/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0985 - loss: 2.3033 - val_accuracy: 0.1000 - val_loss: 2.3029\n",
      "Epoch 3/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1002 - loss: 2.3032 - val_accuracy: 0.1000 - val_loss: 2.3030\n",
      "Epoch 4/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0988 - loss: 2.3032 - val_accuracy: 0.1000 - val_loss: 2.3033\n",
      "Epoch 5/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1006 - loss: 2.3033 - val_accuracy: 0.1000 - val_loss: 2.3033\n",
      "Epoch 6/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.0995 - loss: 2.3031 - val_accuracy: 0.1000 - val_loss: 2.3038\n",
      "Epoch 7/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0974 - loss: 2.3036 - val_accuracy: 0.1000 - val_loss: 2.3034\n",
      "Epoch 8/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1033 - loss: 2.3031 - val_accuracy: 0.1000 - val_loss: 2.3028\n",
      "Epoch 9/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1010 - loss: 2.3032 - val_accuracy: 0.1000 - val_loss: 2.3029\n",
      "Epoch 10/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1016 - loss: 2.3032 - val_accuracy: 0.1000 - val_loss: 2.3038\n",
      "Epoch 11/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0975 - loss: 2.3039 - val_accuracy: 0.1000 - val_loss: 2.3030\n",
      "Epoch 12/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0996 - loss: 2.3033 - val_accuracy: 0.1000 - val_loss: 2.3029\n",
      "Epoch 13/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1009 - loss: 2.3032 - val_accuracy: 0.1000 - val_loss: 2.3029\n",
      "Epoch 14/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0982 - loss: 2.3031 - val_accuracy: 0.1000 - val_loss: 2.3038\n",
      "Epoch 15/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1002 - loss: 2.3036 - val_accuracy: 0.1000 - val_loss: 2.3037\n",
      "Epoch 16/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1019 - loss: 2.3030 - val_accuracy: 0.1000 - val_loss: 2.3039\n",
      "Epoch 17/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0984 - loss: 2.3035 - val_accuracy: 0.1000 - val_loss: 2.3029\n",
      "Epoch 18/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0982 - loss: 2.3032 - val_accuracy: 0.1000 - val_loss: 2.3029\n",
      "Epoch 19/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1000 - loss: 2.3032 - val_accuracy: 0.1000 - val_loss: 2.3031\n",
      "Epoch 20/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0992 - loss: 2.3033 - val_accuracy: 0.1000 - val_loss: 2.3029\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.0975 - loss: 2.3032\n",
      "Epoch 1/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.1006 - loss: 2.3417 - val_accuracy: 0.1000 - val_loss: 2.3033\n",
      "Epoch 2/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1017 - loss: 2.3033 - val_accuracy: 0.1000 - val_loss: 2.3030\n",
      "Epoch 3/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.1022 - loss: 2.3032 - val_accuracy: 0.1000 - val_loss: 2.3031\n",
      "Epoch 4/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1017 - loss: 2.3032 - val_accuracy: 0.1000 - val_loss: 2.3028\n",
      "Epoch 5/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0972 - loss: 2.3033 - val_accuracy: 0.1000 - val_loss: 2.3032\n",
      "Epoch 6/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0978 - loss: 2.3033 - val_accuracy: 0.1000 - val_loss: 2.3029\n",
      "Epoch 7/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0999 - loss: 2.3032 - val_accuracy: 0.1000 - val_loss: 2.3031\n",
      "Epoch 8/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1003 - loss: 2.3034 - val_accuracy: 0.1000 - val_loss: 2.3036\n",
      "Epoch 9/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0992 - loss: 2.3036 - val_accuracy: 0.1000 - val_loss: 2.3032\n",
      "Epoch 10/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1011 - loss: 2.3032 - val_accuracy: 0.1000 - val_loss: 2.3036\n",
      "Epoch 11/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0983 - loss: 2.3033 - val_accuracy: 0.1000 - val_loss: 2.3034\n",
      "Epoch 12/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0980 - loss: 2.3032 - val_accuracy: 0.1000 - val_loss: 2.3028\n",
      "Epoch 13/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0993 - loss: 2.3033 - val_accuracy: 0.1000 - val_loss: 2.3031\n",
      "Epoch 14/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0992 - loss: 2.3034 - val_accuracy: 0.1000 - val_loss: 2.3028\n",
      "Epoch 15/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1002 - loss: 2.3033 - val_accuracy: 0.1000 - val_loss: 2.3031\n",
      "Epoch 16/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0978 - loss: 2.3031 - val_accuracy: 0.1000 - val_loss: 2.3037\n",
      "Epoch 17/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0981 - loss: 2.3036 - val_accuracy: 0.1000 - val_loss: 2.3034\n",
      "Epoch 18/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0978 - loss: 2.3035 - val_accuracy: 0.1000 - val_loss: 2.3033\n",
      "Epoch 19/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1035 - loss: 2.3031 - val_accuracy: 0.1000 - val_loss: 2.3029\n",
      "Epoch 20/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1019 - loss: 2.3031 - val_accuracy: 0.1000 - val_loss: 2.3027\n",
      "Epoch 21/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1003 - loss: 2.3032 - val_accuracy: 0.1000 - val_loss: 2.3033\n",
      "Epoch 22/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0991 - loss: 2.3035 - val_accuracy: 0.1000 - val_loss: 2.3029\n",
      "Epoch 23/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1015 - loss: 2.3031 - val_accuracy: 0.1000 - val_loss: 2.3030\n",
      "Epoch 24/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0999 - loss: 2.3033 - val_accuracy: 0.1000 - val_loss: 2.3031\n",
      "Epoch 25/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0987 - loss: 2.3033 - val_accuracy: 0.1000 - val_loss: 2.3030\n",
      "Epoch 26/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1002 - loss: 2.3035 - val_accuracy: 0.1000 - val_loss: 2.3032\n",
      "Epoch 27/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0986 - loss: 2.3034 - val_accuracy: 0.1000 - val_loss: 2.3030\n",
      "Epoch 28/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0995 - loss: 2.3033 - val_accuracy: 0.1000 - val_loss: 2.3031\n",
      "Epoch 29/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0968 - loss: 2.3034 - val_accuracy: 0.1000 - val_loss: 2.3031\n",
      "Epoch 30/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1018 - loss: 2.3033 - val_accuracy: 0.1000 - val_loss: 2.3036\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.1019 - loss: 2.3037\n",
      "Epoch 1/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.1814 - loss: 2.1574 - val_accuracy: 0.3118 - val_loss: 1.8676\n",
      "Epoch 2/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2839 - loss: 1.9029 - val_accuracy: 0.3844 - val_loss: 1.6844\n",
      "Epoch 3/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3315 - loss: 1.7854 - val_accuracy: 0.3887 - val_loss: 1.6471\n",
      "Epoch 4/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3518 - loss: 1.7411 - val_accuracy: 0.3959 - val_loss: 1.6102\n",
      "Epoch 5/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3643 - loss: 1.7194 - val_accuracy: 0.3910 - val_loss: 1.6495\n",
      "Epoch 6/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3696 - loss: 1.6939 - val_accuracy: 0.4143 - val_loss: 1.5802\n",
      "Epoch 7/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3775 - loss: 1.6878 - val_accuracy: 0.4205 - val_loss: 1.5589\n",
      "Epoch 8/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3848 - loss: 1.6639 - val_accuracy: 0.4104 - val_loss: 1.6062\n",
      "Epoch 9/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3800 - loss: 1.6899 - val_accuracy: 0.4159 - val_loss: 1.5603\n",
      "Epoch 10/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3835 - loss: 1.6651 - val_accuracy: 0.4069 - val_loss: 1.6123\n",
      "Epoch 11/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3854 - loss: 1.6579 - val_accuracy: 0.4111 - val_loss: 1.5934\n",
      "Epoch 12/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3893 - loss: 1.6481 - val_accuracy: 0.4445 - val_loss: 1.5166\n",
      "Epoch 13/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3906 - loss: 1.6468 - val_accuracy: 0.4052 - val_loss: 1.6501\n",
      "Epoch 14/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3955 - loss: 1.6412 - val_accuracy: 0.4390 - val_loss: 1.5256\n",
      "Epoch 15/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3952 - loss: 1.6386 - val_accuracy: 0.4303 - val_loss: 1.5267\n",
      "Epoch 16/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4017 - loss: 1.6271 - val_accuracy: 0.4403 - val_loss: 1.4965\n",
      "Epoch 17/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4005 - loss: 1.6224 - val_accuracy: 0.4472 - val_loss: 1.5106\n",
      "Epoch 18/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4041 - loss: 1.6278 - val_accuracy: 0.4471 - val_loss: 1.5131\n",
      "Epoch 19/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4098 - loss: 1.6062 - val_accuracy: 0.4515 - val_loss: 1.5292\n",
      "Epoch 20/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4030 - loss: 1.6216 - val_accuracy: 0.4467 - val_loss: 1.4957\n",
      "Epoch 21/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4065 - loss: 1.6063 - val_accuracy: 0.4355 - val_loss: 1.5300\n",
      "Epoch 22/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4041 - loss: 1.6225 - val_accuracy: 0.4558 - val_loss: 1.4947\n",
      "Epoch 23/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4089 - loss: 1.6023 - val_accuracy: 0.4534 - val_loss: 1.5028\n",
      "Epoch 24/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4103 - loss: 1.5937 - val_accuracy: 0.4566 - val_loss: 1.4855\n",
      "Epoch 25/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4050 - loss: 1.6140 - val_accuracy: 0.4396 - val_loss: 1.5068\n",
      "Epoch 26/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4100 - loss: 1.5969 - val_accuracy: 0.4596 - val_loss: 1.4655\n",
      "Epoch 27/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4166 - loss: 1.5884 - val_accuracy: 0.4311 - val_loss: 1.5163\n",
      "Epoch 28/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4122 - loss: 1.5981 - val_accuracy: 0.4440 - val_loss: 1.5003\n",
      "Epoch 29/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4172 - loss: 1.5845 - val_accuracy: 0.4485 - val_loss: 1.5012\n",
      "Epoch 30/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4074 - loss: 1.5967 - val_accuracy: 0.4612 - val_loss: 1.4740\n",
      "Epoch 31/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4155 - loss: 1.5850 - val_accuracy: 0.4646 - val_loss: 1.4570\n",
      "Epoch 32/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4150 - loss: 1.5977 - val_accuracy: 0.4503 - val_loss: 1.4880\n",
      "Epoch 33/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4177 - loss: 1.5868 - val_accuracy: 0.4511 - val_loss: 1.4983\n",
      "Epoch 34/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4173 - loss: 1.5766 - val_accuracy: 0.4718 - val_loss: 1.4598\n",
      "Epoch 35/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4221 - loss: 1.5832 - val_accuracy: 0.4535 - val_loss: 1.4896\n",
      "Epoch 36/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4194 - loss: 1.5931 - val_accuracy: 0.4294 - val_loss: 1.5632\n",
      "Epoch 37/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4179 - loss: 1.5890 - val_accuracy: 0.4681 - val_loss: 1.4874\n",
      "Epoch 38/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4233 - loss: 1.5685 - val_accuracy: 0.4596 - val_loss: 1.4726\n",
      "Epoch 39/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4271 - loss: 1.5756 - val_accuracy: 0.4621 - val_loss: 1.4927\n",
      "Epoch 40/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4193 - loss: 1.5753 - val_accuracy: 0.4711 - val_loss: 1.4692\n",
      "Epoch 41/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4280 - loss: 1.5725 - val_accuracy: 0.4577 - val_loss: 1.4869\n",
      "Epoch 42/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4268 - loss: 1.5810 - val_accuracy: 0.4442 - val_loss: 1.5305\n",
      "Epoch 43/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4282 - loss: 1.5675 - val_accuracy: 0.4846 - val_loss: 1.4320\n",
      "Epoch 44/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4169 - loss: 1.5971 - val_accuracy: 0.4428 - val_loss: 1.5135\n",
      "Epoch 45/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4254 - loss: 1.5712 - val_accuracy: 0.4527 - val_loss: 1.5147\n",
      "Epoch 46/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4242 - loss: 1.5771 - val_accuracy: 0.4630 - val_loss: 1.5037\n",
      "Epoch 47/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4279 - loss: 1.5624 - val_accuracy: 0.4578 - val_loss: 1.4892\n",
      "Epoch 48/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4316 - loss: 1.5597 - val_accuracy: 0.4660 - val_loss: 1.4573\n",
      "Epoch 49/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4273 - loss: 1.5606 - val_accuracy: 0.4537 - val_loss: 1.4727\n",
      "Epoch 50/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4293 - loss: 1.5671 - val_accuracy: 0.4747 - val_loss: 1.4402\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.4740 - loss: 1.4414\n",
      "Epoch 1/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.1594 - loss: 2.4679 - val_accuracy: 0.3207 - val_loss: 1.8701\n",
      "Epoch 2/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3035 - loss: 1.8896 - val_accuracy: 0.3430 - val_loss: 1.7486\n",
      "Epoch 3/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3330 - loss: 1.8009 - val_accuracy: 0.3788 - val_loss: 1.6878\n",
      "Epoch 4/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3523 - loss: 1.7367 - val_accuracy: 0.3972 - val_loss: 1.6093\n",
      "Epoch 5/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3622 - loss: 1.7175 - val_accuracy: 0.4034 - val_loss: 1.5990\n",
      "Epoch 6/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3675 - loss: 1.6871 - val_accuracy: 0.4313 - val_loss: 1.5544\n",
      "Epoch 7/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3789 - loss: 1.6704 - val_accuracy: 0.4168 - val_loss: 1.5593\n",
      "Epoch 8/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3917 - loss: 1.6376 - val_accuracy: 0.4454 - val_loss: 1.4970\n",
      "Epoch 9/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4005 - loss: 1.6211 - val_accuracy: 0.4652 - val_loss: 1.4601\n",
      "Epoch 10/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4083 - loss: 1.5983 - val_accuracy: 0.4547 - val_loss: 1.4649\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4604 - loss: 1.4637\n",
      "Epoch 1/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.1082 - loss: 2.3472 - val_accuracy: 0.1000 - val_loss: 2.3029\n",
      "Epoch 2/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0985 - loss: 2.3032 - val_accuracy: 0.1000 - val_loss: 2.3029\n",
      "Epoch 3/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0988 - loss: 2.3030 - val_accuracy: 0.1000 - val_loss: 2.3029\n",
      "Epoch 4/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0996 - loss: 2.3031 - val_accuracy: 0.1000 - val_loss: 2.3031\n",
      "Epoch 5/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1009 - loss: 2.3030 - val_accuracy: 0.1000 - val_loss: 2.3028\n",
      "Epoch 6/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0970 - loss: 2.3032 - val_accuracy: 0.1000 - val_loss: 2.3030\n",
      "Epoch 7/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0993 - loss: 2.3031 - val_accuracy: 0.1000 - val_loss: 2.3029\n",
      "Epoch 8/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1028 - loss: 2.3030 - val_accuracy: 0.1000 - val_loss: 2.3032\n",
      "Epoch 9/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1021 - loss: 2.3031 - val_accuracy: 0.1000 - val_loss: 2.3032\n",
      "Epoch 10/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0972 - loss: 2.3034 - val_accuracy: 0.1000 - val_loss: 2.3030\n",
      "Epoch 11/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0973 - loss: 2.3032 - val_accuracy: 0.1000 - val_loss: 2.3028\n",
      "Epoch 12/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1011 - loss: 2.3029 - val_accuracy: 0.1000 - val_loss: 2.3027\n",
      "Epoch 13/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0964 - loss: 2.3032 - val_accuracy: 0.1000 - val_loss: 2.3031\n",
      "Epoch 14/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0970 - loss: 2.3032 - val_accuracy: 0.1000 - val_loss: 2.3030\n",
      "Epoch 15/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1005 - loss: 2.3033 - val_accuracy: 0.1000 - val_loss: 2.3031\n",
      "Epoch 16/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0990 - loss: 2.3032 - val_accuracy: 0.1000 - val_loss: 2.3030\n",
      "Epoch 17/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1015 - loss: 2.3030 - val_accuracy: 0.1000 - val_loss: 2.3037\n",
      "Epoch 18/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0994 - loss: 2.3031 - val_accuracy: 0.1000 - val_loss: 2.3030\n",
      "Epoch 19/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0997 - loss: 2.3031 - val_accuracy: 0.1000 - val_loss: 2.3029\n",
      "Epoch 20/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0998 - loss: 2.3031 - val_accuracy: 0.1000 - val_loss: 2.3026\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.0975 - loss: 2.3028\n",
      "Epoch 1/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.0988 - loss: 2.3404 - val_accuracy: 0.1000 - val_loss: 2.3030\n",
      "Epoch 2/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1002 - loss: 2.3031 - val_accuracy: 0.1000 - val_loss: 2.3029\n",
      "Epoch 3/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1017 - loss: 2.3031 - val_accuracy: 0.1000 - val_loss: 2.3033\n",
      "Epoch 4/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1005 - loss: 2.3033 - val_accuracy: 0.1000 - val_loss: 2.3029\n",
      "Epoch 5/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0977 - loss: 2.3031 - val_accuracy: 0.1000 - val_loss: 2.3029\n",
      "Epoch 6/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0979 - loss: 2.3032 - val_accuracy: 0.1000 - val_loss: 2.3027\n",
      "Epoch 7/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1002 - loss: 2.3031 - val_accuracy: 0.1000 - val_loss: 2.3031\n",
      "Epoch 8/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0991 - loss: 2.3030 - val_accuracy: 0.1000 - val_loss: 2.3031\n",
      "Epoch 9/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0990 - loss: 2.3031 - val_accuracy: 0.1000 - val_loss: 2.3030\n",
      "Epoch 10/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1028 - loss: 2.3029 - val_accuracy: 0.1000 - val_loss: 2.3031\n",
      "Epoch 11/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0978 - loss: 2.3033 - val_accuracy: 0.1000 - val_loss: 2.3032\n",
      "Epoch 12/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0986 - loss: 2.3031 - val_accuracy: 0.1000 - val_loss: 2.3029\n",
      "Epoch 13/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1003 - loss: 2.3032 - val_accuracy: 0.1000 - val_loss: 2.3028\n",
      "Epoch 14/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1016 - loss: 2.3031 - val_accuracy: 0.1000 - val_loss: 2.3027\n",
      "Epoch 15/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0979 - loss: 2.3031 - val_accuracy: 0.1000 - val_loss: 2.3029\n",
      "Epoch 16/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0989 - loss: 2.3032 - val_accuracy: 0.1000 - val_loss: 2.3030\n",
      "Epoch 17/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0994 - loss: 2.3031 - val_accuracy: 0.1000 - val_loss: 2.3031\n",
      "Epoch 18/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1016 - loss: 2.3029 - val_accuracy: 0.1000 - val_loss: 2.3028\n",
      "Epoch 19/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0994 - loss: 2.3031 - val_accuracy: 0.1000 - val_loss: 2.3030\n",
      "Epoch 20/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1019 - loss: 2.3031 - val_accuracy: 0.1000 - val_loss: 2.3030\n",
      "Epoch 21/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1001 - loss: 2.3031 - val_accuracy: 0.1000 - val_loss: 2.3027\n",
      "Epoch 22/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0991 - loss: 2.3029 - val_accuracy: 0.1000 - val_loss: 2.3030\n",
      "Epoch 23/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1020 - loss: 2.3031 - val_accuracy: 0.1000 - val_loss: 2.3030\n",
      "Epoch 24/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0960 - loss: 2.3031 - val_accuracy: 0.1000 - val_loss: 2.3030\n",
      "Epoch 25/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0970 - loss: 2.3032 - val_accuracy: 0.1000 - val_loss: 2.3030\n",
      "Epoch 26/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1000 - loss: 2.3031 - val_accuracy: 0.1000 - val_loss: 2.3029\n",
      "Epoch 27/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0999 - loss: 2.3033 - val_accuracy: 0.1000 - val_loss: 2.3028\n",
      "Epoch 28/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0999 - loss: 2.3030 - val_accuracy: 0.1000 - val_loss: 2.3028\n",
      "Epoch 29/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.0985 - loss: 2.3031 - val_accuracy: 0.1000 - val_loss: 2.3028\n",
      "Epoch 30/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0971 - loss: 2.3032 - val_accuracy: 0.1000 - val_loss: 2.3028\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - accuracy: 0.1036 - loss: 2.3026\n",
      "Epoch 1/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.1322 - loss: 2.2973 - val_accuracy: 0.2751 - val_loss: 1.9801\n",
      "Epoch 2/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2403 - loss: 2.0246 - val_accuracy: 0.2923 - val_loss: 1.8900\n",
      "Epoch 3/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2723 - loss: 1.9093 - val_accuracy: 0.3504 - val_loss: 1.7283\n",
      "Epoch 4/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3059 - loss: 1.8159 - val_accuracy: 0.3576 - val_loss: 1.6963\n",
      "Epoch 5/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3233 - loss: 1.7798 - val_accuracy: 0.3812 - val_loss: 1.6414\n",
      "Epoch 6/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3423 - loss: 1.7303 - val_accuracy: 0.3988 - val_loss: 1.6020\n",
      "Epoch 7/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3528 - loss: 1.7125 - val_accuracy: 0.4069 - val_loss: 1.5801\n",
      "Epoch 8/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3522 - loss: 1.7087 - val_accuracy: 0.3795 - val_loss: 1.6645\n",
      "Epoch 9/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3585 - loss: 1.6924 - val_accuracy: 0.4041 - val_loss: 1.6114\n",
      "Epoch 10/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3604 - loss: 1.6968 - val_accuracy: 0.3960 - val_loss: 1.6052\n",
      "Epoch 11/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3743 - loss: 1.6732 - val_accuracy: 0.4147 - val_loss: 1.5879\n",
      "Epoch 12/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3754 - loss: 1.6590 - val_accuracy: 0.4215 - val_loss: 1.5627\n",
      "Epoch 13/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3788 - loss: 1.6679 - val_accuracy: 0.4201 - val_loss: 1.5506\n",
      "Epoch 14/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3889 - loss: 1.6333 - val_accuracy: 0.4322 - val_loss: 1.5247\n",
      "Epoch 15/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3909 - loss: 1.6368 - val_accuracy: 0.4364 - val_loss: 1.5249\n",
      "Epoch 16/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3944 - loss: 1.6267 - val_accuracy: 0.4225 - val_loss: 1.5294\n",
      "Epoch 17/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3951 - loss: 1.6309 - val_accuracy: 0.4252 - val_loss: 1.5948\n",
      "Epoch 18/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4039 - loss: 1.6130 - val_accuracy: 0.4539 - val_loss: 1.4795\n",
      "Epoch 19/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4107 - loss: 1.5923 - val_accuracy: 0.4461 - val_loss: 1.5214\n",
      "Epoch 20/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4126 - loss: 1.6042 - val_accuracy: 0.4357 - val_loss: 1.4974\n",
      "Epoch 21/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4105 - loss: 1.5947 - val_accuracy: 0.4541 - val_loss: 1.4750\n",
      "Epoch 22/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4151 - loss: 1.5846 - val_accuracy: 0.4484 - val_loss: 1.4630\n",
      "Epoch 23/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4164 - loss: 1.5878 - val_accuracy: 0.4607 - val_loss: 1.4826\n",
      "Epoch 24/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4192 - loss: 1.5805 - val_accuracy: 0.4640 - val_loss: 1.4610\n",
      "Epoch 25/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4120 - loss: 1.5757 - val_accuracy: 0.4420 - val_loss: 1.5427\n",
      "Epoch 26/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4216 - loss: 1.5750 - val_accuracy: 0.4735 - val_loss: 1.4484\n",
      "Epoch 27/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4210 - loss: 1.5619 - val_accuracy: 0.4553 - val_loss: 1.4714\n",
      "Epoch 28/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4217 - loss: 1.5747 - val_accuracy: 0.4710 - val_loss: 1.4494\n",
      "Epoch 29/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4314 - loss: 1.5548 - val_accuracy: 0.4525 - val_loss: 1.4848\n",
      "Epoch 30/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4233 - loss: 1.5687 - val_accuracy: 0.4516 - val_loss: 1.4936\n",
      "Epoch 31/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4245 - loss: 1.5583 - val_accuracy: 0.4656 - val_loss: 1.4576\n",
      "Epoch 32/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4245 - loss: 1.5586 - val_accuracy: 0.4692 - val_loss: 1.4488\n",
      "Epoch 33/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4275 - loss: 1.5576 - val_accuracy: 0.4782 - val_loss: 1.4249\n",
      "Epoch 34/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4369 - loss: 1.5356 - val_accuracy: 0.4756 - val_loss: 1.4417\n",
      "Epoch 35/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4279 - loss: 1.5553 - val_accuracy: 0.4528 - val_loss: 1.5069\n",
      "Epoch 36/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4270 - loss: 1.5731 - val_accuracy: 0.4693 - val_loss: 1.4759\n",
      "Epoch 37/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4250 - loss: 1.5559 - val_accuracy: 0.4789 - val_loss: 1.4289\n",
      "Epoch 38/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4333 - loss: 1.5460 - val_accuracy: 0.4666 - val_loss: 1.4448\n",
      "Epoch 39/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4283 - loss: 1.5527 - val_accuracy: 0.4835 - val_loss: 1.4214\n",
      "Epoch 40/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4338 - loss: 1.5284 - val_accuracy: 0.4706 - val_loss: 1.4507\n",
      "Epoch 41/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4422 - loss: 1.5201 - val_accuracy: 0.4767 - val_loss: 1.4327\n",
      "Epoch 42/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4319 - loss: 1.5516 - val_accuracy: 0.4774 - val_loss: 1.4230\n",
      "Epoch 43/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4368 - loss: 1.5249 - val_accuracy: 0.4870 - val_loss: 1.4034\n",
      "Epoch 44/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4369 - loss: 1.5287 - val_accuracy: 0.4964 - val_loss: 1.3887\n",
      "Epoch 45/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4440 - loss: 1.5190 - val_accuracy: 0.4742 - val_loss: 1.4390\n",
      "Epoch 46/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4424 - loss: 1.5353 - val_accuracy: 0.4933 - val_loss: 1.3940\n",
      "Epoch 47/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4404 - loss: 1.5231 - val_accuracy: 0.4907 - val_loss: 1.4083\n",
      "Epoch 48/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4362 - loss: 1.5306 - val_accuracy: 0.4845 - val_loss: 1.4176\n",
      "Epoch 49/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4430 - loss: 1.5263 - val_accuracy: 0.4861 - val_loss: 1.3922\n",
      "Epoch 50/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4450 - loss: 1.5178 - val_accuracy: 0.4948 - val_loss: 1.3833\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.4995 - loss: 1.3723\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.0992 - loss: 295.9457 - val_accuracy: 0.1000 - val_loss: 2.3134\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1040 - loss: 2.3149 - val_accuracy: 0.1000 - val_loss: 2.3150\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1000 - loss: 2.3155 - val_accuracy: 0.1000 - val_loss: 2.3089\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1003 - loss: 2.3155 - val_accuracy: 0.1000 - val_loss: 2.3066\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0962 - loss: 2.3151 - val_accuracy: 0.1000 - val_loss: 2.3150\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0991 - loss: 2.3155 - val_accuracy: 0.1000 - val_loss: 2.3251\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0971 - loss: 2.3154 - val_accuracy: 0.1000 - val_loss: 2.3127\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0998 - loss: 2.3155 - val_accuracy: 0.1000 - val_loss: 2.3203\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0997 - loss: 2.3156 - val_accuracy: 0.1000 - val_loss: 2.3238\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1008 - loss: 2.3162 - val_accuracy: 0.1000 - val_loss: 2.3194\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.1027 - loss: 2.3202\n",
      "Epoch 1/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.1016 - loss: 118.2493 - val_accuracy: 0.1000 - val_loss: 2.3141\n",
      "Epoch 2/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1041 - loss: 2.3144 - val_accuracy: 0.1000 - val_loss: 2.3172\n",
      "Epoch 3/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0957 - loss: 2.3157 - val_accuracy: 0.1000 - val_loss: 2.3177\n",
      "Epoch 4/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0984 - loss: 2.3164 - val_accuracy: 0.1000 - val_loss: 2.3134\n",
      "Epoch 5/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0972 - loss: 2.3170 - val_accuracy: 0.1000 - val_loss: 2.3161\n",
      "Epoch 6/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1031 - loss: 2.3148 - val_accuracy: 0.1000 - val_loss: 2.3205\n",
      "Epoch 7/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0983 - loss: 2.3166 - val_accuracy: 0.1000 - val_loss: 2.3248\n",
      "Epoch 8/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0970 - loss: 2.3157 - val_accuracy: 0.1000 - val_loss: 2.3214\n",
      "Epoch 9/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1020 - loss: 2.3152 - val_accuracy: 0.1000 - val_loss: 2.3176\n",
      "Epoch 10/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1003 - loss: 2.3159 - val_accuracy: 0.1000 - val_loss: 2.3054\n",
      "Epoch 11/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1010 - loss: 2.3145 - val_accuracy: 0.1000 - val_loss: 2.3215\n",
      "Epoch 12/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1021 - loss: 2.3145 - val_accuracy: 0.1000 - val_loss: 2.3216\n",
      "Epoch 13/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1019 - loss: 2.3154 - val_accuracy: 0.1000 - val_loss: 2.3143\n",
      "Epoch 14/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0980 - loss: 2.3151 - val_accuracy: 0.1000 - val_loss: 2.3114\n",
      "Epoch 15/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0984 - loss: 2.3156 - val_accuracy: 0.1000 - val_loss: 2.3099\n",
      "Epoch 16/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1019 - loss: 2.3148 - val_accuracy: 0.1000 - val_loss: 2.3249\n",
      "Epoch 17/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0995 - loss: 2.3163 - val_accuracy: 0.1000 - val_loss: 2.3353\n",
      "Epoch 18/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1043 - loss: 2.3160 - val_accuracy: 0.1000 - val_loss: 2.3203\n",
      "Epoch 19/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0994 - loss: 2.3159 - val_accuracy: 0.1000 - val_loss: 2.3178\n",
      "Epoch 20/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0994 - loss: 2.3150 - val_accuracy: 0.1000 - val_loss: 2.3116\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.1027 - loss: 2.3102\n",
      "Epoch 1/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.0994 - loss: 494.5653 - val_accuracy: 0.1000 - val_loss: 2.3133\n",
      "Epoch 2/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1008 - loss: 2.3154 - val_accuracy: 0.1000 - val_loss: 2.3153\n",
      "Epoch 3/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0966 - loss: 2.3155 - val_accuracy: 0.1000 - val_loss: 2.3104\n",
      "Epoch 4/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1004 - loss: 2.3154 - val_accuracy: 0.1000 - val_loss: 2.3117\n",
      "Epoch 5/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1014 - loss: 2.3146 - val_accuracy: 0.1000 - val_loss: 2.3065\n",
      "Epoch 6/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0985 - loss: 2.3157 - val_accuracy: 0.1000 - val_loss: 2.3106\n",
      "Epoch 7/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0990 - loss: 2.3150 - val_accuracy: 0.1000 - val_loss: 2.3180\n",
      "Epoch 8/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1010 - loss: 2.3132 - val_accuracy: 0.1000 - val_loss: 2.3097\n",
      "Epoch 9/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0959 - loss: 2.3163 - val_accuracy: 0.1000 - val_loss: 2.3217\n",
      "Epoch 10/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0996 - loss: 2.3166 - val_accuracy: 0.1000 - val_loss: 2.3089\n",
      "Epoch 11/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1010 - loss: 2.3155 - val_accuracy: 0.1000 - val_loss: 2.3101\n",
      "Epoch 12/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1020 - loss: 2.3152 - val_accuracy: 0.1000 - val_loss: 2.3214\n",
      "Epoch 13/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1017 - loss: 2.3157 - val_accuracy: 0.1000 - val_loss: 2.3063\n",
      "Epoch 14/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1005 - loss: 2.3154 - val_accuracy: 0.1000 - val_loss: 2.3182\n",
      "Epoch 15/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1031 - loss: 2.3151 - val_accuracy: 0.1000 - val_loss: 2.3164\n",
      "Epoch 16/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1002 - loss: 2.3164 - val_accuracy: 0.1000 - val_loss: 2.3137\n",
      "Epoch 17/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0993 - loss: 2.3159 - val_accuracy: 0.1000 - val_loss: 2.3128\n",
      "Epoch 18/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0994 - loss: 2.3153 - val_accuracy: 0.1000 - val_loss: 2.3118\n",
      "Epoch 19/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1013 - loss: 2.3144 - val_accuracy: 0.1000 - val_loss: 2.3233\n",
      "Epoch 20/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1021 - loss: 2.3162 - val_accuracy: 0.1000 - val_loss: 2.3150\n",
      "Epoch 21/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0994 - loss: 2.3163 - val_accuracy: 0.1000 - val_loss: 2.3111\n",
      "Epoch 22/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1003 - loss: 2.3147 - val_accuracy: 0.1000 - val_loss: 2.3162\n",
      "Epoch 23/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1006 - loss: 2.3152 - val_accuracy: 0.1000 - val_loss: 2.3158\n",
      "Epoch 24/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1017 - loss: 2.3149 - val_accuracy: 0.1000 - val_loss: 2.3093\n",
      "Epoch 25/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0999 - loss: 2.3156 - val_accuracy: 0.1000 - val_loss: 2.3118\n",
      "Epoch 26/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0998 - loss: 2.3152 - val_accuracy: 0.1000 - val_loss: 2.3198\n",
      "Epoch 27/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0995 - loss: 2.3152 - val_accuracy: 0.1000 - val_loss: 2.3146\n",
      "Epoch 28/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1029 - loss: 2.3149 - val_accuracy: 0.1000 - val_loss: 2.3265\n",
      "Epoch 29/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0998 - loss: 2.3167 - val_accuracy: 0.1000 - val_loss: 2.3256\n",
      "Epoch 30/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0972 - loss: 2.3151 - val_accuracy: 0.1000 - val_loss: 2.3151\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.1001 - loss: 2.3144\n",
      "Epoch 1/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.0970 - loss: 153.9405 - val_accuracy: 0.1000 - val_loss: 2.3054\n",
      "Epoch 2/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1008 - loss: 2.3149 - val_accuracy: 0.1000 - val_loss: 2.3119\n",
      "Epoch 3/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1004 - loss: 2.3151 - val_accuracy: 0.1000 - val_loss: 2.3183\n",
      "Epoch 4/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1003 - loss: 2.3157 - val_accuracy: 0.1000 - val_loss: 2.3138\n",
      "Epoch 5/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0996 - loss: 2.3145 - val_accuracy: 0.1000 - val_loss: 2.3156\n",
      "Epoch 6/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0977 - loss: 2.3154 - val_accuracy: 0.1000 - val_loss: 2.3102\n",
      "Epoch 7/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1007 - loss: 2.3152 - val_accuracy: 0.1000 - val_loss: 2.3123\n",
      "Epoch 8/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0963 - loss: 2.3159 - val_accuracy: 0.1000 - val_loss: 2.3088\n",
      "Epoch 9/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1000 - loss: 2.3154 - val_accuracy: 0.1000 - val_loss: 2.3131\n",
      "Epoch 10/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0988 - loss: 2.3159 - val_accuracy: 0.1000 - val_loss: 2.3143\n",
      "Epoch 11/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1013 - loss: 2.3143 - val_accuracy: 0.1000 - val_loss: 2.3186\n",
      "Epoch 12/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0984 - loss: 2.3158 - val_accuracy: 0.1000 - val_loss: 2.3229\n",
      "Epoch 13/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0989 - loss: 2.3160 - val_accuracy: 0.1000 - val_loss: 2.3137\n",
      "Epoch 14/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0990 - loss: 2.3159 - val_accuracy: 0.1000 - val_loss: 2.3133\n",
      "Epoch 15/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1007 - loss: 2.3161 - val_accuracy: 0.1000 - val_loss: 2.3153\n",
      "Epoch 16/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0971 - loss: 2.3166 - val_accuracy: 0.1000 - val_loss: 2.3134\n",
      "Epoch 17/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0996 - loss: 2.3149 - val_accuracy: 0.1000 - val_loss: 2.3224\n",
      "Epoch 18/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1000 - loss: 2.3146 - val_accuracy: 0.1000 - val_loss: 2.3074\n",
      "Epoch 19/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0975 - loss: 2.3147 - val_accuracy: 0.1000 - val_loss: 2.3096\n",
      "Epoch 20/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0997 - loss: 2.3153 - val_accuracy: 0.1000 - val_loss: 2.3091\n",
      "Epoch 21/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0985 - loss: 2.3149 - val_accuracy: 0.1000 - val_loss: 2.3168\n",
      "Epoch 22/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1018 - loss: 2.3138 - val_accuracy: 0.1000 - val_loss: 2.3223\n",
      "Epoch 23/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1007 - loss: 2.3153 - val_accuracy: 0.1000 - val_loss: 2.3171\n",
      "Epoch 24/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0999 - loss: 2.3148 - val_accuracy: 0.1000 - val_loss: 2.3135\n",
      "Epoch 25/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0989 - loss: 2.3158 - val_accuracy: 0.1000 - val_loss: 2.3171\n",
      "Epoch 26/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0969 - loss: 2.3165 - val_accuracy: 0.1000 - val_loss: 2.3154\n",
      "Epoch 27/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0967 - loss: 2.3153 - val_accuracy: 0.1000 - val_loss: 2.3095\n",
      "Epoch 28/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0956 - loss: 2.3166 - val_accuracy: 0.1000 - val_loss: 2.3202\n",
      "Epoch 29/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1012 - loss: 2.3160 - val_accuracy: 0.1000 - val_loss: 2.3106\n",
      "Epoch 30/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0959 - loss: 2.3160 - val_accuracy: 0.1000 - val_loss: 2.3158\n",
      "Epoch 31/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0990 - loss: 2.3166 - val_accuracy: 0.1000 - val_loss: 2.3108\n",
      "Epoch 32/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1008 - loss: 2.3154 - val_accuracy: 0.1000 - val_loss: 2.3237\n",
      "Epoch 33/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0975 - loss: 2.3154 - val_accuracy: 0.1000 - val_loss: 2.3106\n",
      "Epoch 34/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1002 - loss: 2.3152 - val_accuracy: 0.1000 - val_loss: 2.3116\n",
      "Epoch 35/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0982 - loss: 2.3156 - val_accuracy: 0.1000 - val_loss: 2.3171\n",
      "Epoch 36/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0989 - loss: 2.3168 - val_accuracy: 0.1000 - val_loss: 2.3153\n",
      "Epoch 37/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0993 - loss: 2.3148 - val_accuracy: 0.1000 - val_loss: 2.3167\n",
      "Epoch 38/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1002 - loss: 2.3157 - val_accuracy: 0.1000 - val_loss: 2.3089\n",
      "Epoch 39/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1016 - loss: 2.3159 - val_accuracy: 0.1000 - val_loss: 2.3063\n",
      "Epoch 40/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1025 - loss: 2.3142 - val_accuracy: 0.1000 - val_loss: 2.3091\n",
      "Epoch 41/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0996 - loss: 2.3158 - val_accuracy: 0.1000 - val_loss: 2.3141\n",
      "Epoch 42/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1022 - loss: 2.3139 - val_accuracy: 0.1000 - val_loss: 2.3103\n",
      "Epoch 43/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0992 - loss: 2.3164 - val_accuracy: 0.1000 - val_loss: 2.3142\n",
      "Epoch 44/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1013 - loss: 2.3145 - val_accuracy: 0.1000 - val_loss: 2.3137\n",
      "Epoch 45/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0963 - loss: 2.3170 - val_accuracy: 0.1000 - val_loss: 2.3097\n",
      "Epoch 46/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1010 - loss: 2.3142 - val_accuracy: 0.1000 - val_loss: 2.3139\n",
      "Epoch 47/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1000 - loss: 2.3154 - val_accuracy: 0.1000 - val_loss: 2.3170\n",
      "Epoch 48/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1006 - loss: 2.3162 - val_accuracy: 0.1000 - val_loss: 2.3152\n",
      "Epoch 49/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1029 - loss: 2.3154 - val_accuracy: 0.1000 - val_loss: 2.3081\n",
      "Epoch 50/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1033 - loss: 2.3145 - val_accuracy: 0.1000 - val_loss: 2.3121\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.0987 - loss: 2.3113\n",
      "Epoch 1/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.1031 - loss: 330.9852 - val_accuracy: 0.1000 - val_loss: 2.3074\n",
      "Epoch 2/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0981 - loss: 2.3121 - val_accuracy: 0.1000 - val_loss: 2.3084\n",
      "Epoch 3/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0985 - loss: 2.3133 - val_accuracy: 0.1000 - val_loss: 2.3230\n",
      "Epoch 4/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1008 - loss: 2.3113 - val_accuracy: 0.1000 - val_loss: 2.3116\n",
      "Epoch 5/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0999 - loss: 2.3119 - val_accuracy: 0.1000 - val_loss: 2.3156\n",
      "Epoch 6/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1027 - loss: 2.3119 - val_accuracy: 0.1000 - val_loss: 2.3129\n",
      "Epoch 7/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1012 - loss: 2.3122 - val_accuracy: 0.1000 - val_loss: 2.3128\n",
      "Epoch 8/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1008 - loss: 2.3106 - val_accuracy: 0.1000 - val_loss: 2.3127\n",
      "Epoch 9/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1016 - loss: 2.3107 - val_accuracy: 0.1000 - val_loss: 2.3068\n",
      "Epoch 10/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1007 - loss: 2.3113 - val_accuracy: 0.1000 - val_loss: 2.3126\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.0995 - loss: 2.3136\n",
      "Epoch 1/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.0992 - loss: 1156.2837 - val_accuracy: 0.1000 - val_loss: 2.3138\n",
      "Epoch 2/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1017 - loss: 2.3127 - val_accuracy: 0.1000 - val_loss: 2.3199\n",
      "Epoch 3/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0992 - loss: 2.3106 - val_accuracy: 0.1000 - val_loss: 2.3043\n",
      "Epoch 4/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1035 - loss: 2.3093 - val_accuracy: 0.1000 - val_loss: 2.3095\n",
      "Epoch 5/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1030 - loss: 2.3115 - val_accuracy: 0.1000 - val_loss: 2.3100\n",
      "Epoch 6/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1018 - loss: 2.3113 - val_accuracy: 0.1000 - val_loss: 2.3102\n",
      "Epoch 7/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0992 - loss: 2.3115 - val_accuracy: 0.1000 - val_loss: 2.3140\n",
      "Epoch 8/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1027 - loss: 2.3111 - val_accuracy: 0.1000 - val_loss: 2.3082\n",
      "Epoch 9/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1000 - loss: 2.3114 - val_accuracy: 0.1000 - val_loss: 2.3143\n",
      "Epoch 10/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1018 - loss: 2.3112 - val_accuracy: 0.1000 - val_loss: 2.3177\n",
      "Epoch 11/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1042 - loss: 2.3119 - val_accuracy: 0.1000 - val_loss: 2.3075\n",
      "Epoch 12/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0979 - loss: 2.3115 - val_accuracy: 0.1000 - val_loss: 2.3116\n",
      "Epoch 13/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0983 - loss: 2.3115 - val_accuracy: 0.1000 - val_loss: 2.3115\n",
      "Epoch 14/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0989 - loss: 2.3102 - val_accuracy: 0.1000 - val_loss: 2.3073\n",
      "Epoch 15/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0992 - loss: 2.3117 - val_accuracy: 0.1000 - val_loss: 2.3134\n",
      "Epoch 16/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1038 - loss: 2.3107 - val_accuracy: 0.1000 - val_loss: 2.3144\n",
      "Epoch 17/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0972 - loss: 2.3132 - val_accuracy: 0.1000 - val_loss: 2.3167\n",
      "Epoch 18/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1032 - loss: 2.3121 - val_accuracy: 0.1000 - val_loss: 2.3072\n",
      "Epoch 19/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0982 - loss: 2.3116 - val_accuracy: 0.1000 - val_loss: 2.3140\n",
      "Epoch 20/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0960 - loss: 2.3109 - val_accuracy: 0.1000 - val_loss: 2.3161\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.0988 - loss: 2.3178\n",
      "Epoch 1/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.0990 - loss: 1950.2820 - val_accuracy: 0.1000 - val_loss: 2.3190\n",
      "Epoch 2/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0978 - loss: 2.3119 - val_accuracy: 0.1000 - val_loss: 2.3095\n",
      "Epoch 3/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1028 - loss: 2.3111 - val_accuracy: 0.1000 - val_loss: 2.3085\n",
      "Epoch 4/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0982 - loss: 2.3115 - val_accuracy: 0.1000 - val_loss: 2.3105\n",
      "Epoch 5/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1005 - loss: 2.3127 - val_accuracy: 0.1000 - val_loss: 2.3081\n",
      "Epoch 6/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1005 - loss: 2.3113 - val_accuracy: 0.1000 - val_loss: 2.3130\n",
      "Epoch 7/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1009 - loss: 2.3124 - val_accuracy: 0.1000 - val_loss: 2.3080\n",
      "Epoch 8/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1020 - loss: 2.3108 - val_accuracy: 0.1000 - val_loss: 2.3078\n",
      "Epoch 9/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0959 - loss: 2.3113 - val_accuracy: 0.1000 - val_loss: 2.3174\n",
      "Epoch 10/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0998 - loss: 2.3136 - val_accuracy: 0.1000 - val_loss: 2.3169\n",
      "Epoch 11/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1029 - loss: 2.3115 - val_accuracy: 0.1000 - val_loss: 2.3062\n",
      "Epoch 12/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1001 - loss: 2.3105 - val_accuracy: 0.1000 - val_loss: 2.3091\n",
      "Epoch 13/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0987 - loss: 2.3112 - val_accuracy: 0.1000 - val_loss: 2.3123\n",
      "Epoch 14/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1000 - loss: 2.3124 - val_accuracy: 0.1000 - val_loss: 2.3137\n",
      "Epoch 15/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1006 - loss: 2.3125 - val_accuracy: 0.1000 - val_loss: 2.3147\n",
      "Epoch 16/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0997 - loss: 2.3107 - val_accuracy: 0.1000 - val_loss: 2.3077\n",
      "Epoch 17/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1031 - loss: 2.3117 - val_accuracy: 0.1000 - val_loss: 2.3091\n",
      "Epoch 18/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0983 - loss: 2.3120 - val_accuracy: 0.1000 - val_loss: 2.3099\n",
      "Epoch 19/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0989 - loss: 2.3126 - val_accuracy: 0.1000 - val_loss: 2.3078\n",
      "Epoch 20/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0974 - loss: 2.3122 - val_accuracy: 0.1000 - val_loss: 2.3111\n",
      "Epoch 21/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0976 - loss: 2.3107 - val_accuracy: 0.1000 - val_loss: 2.3117\n",
      "Epoch 22/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0963 - loss: 2.3120 - val_accuracy: 0.1000 - val_loss: 2.3089\n",
      "Epoch 23/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1032 - loss: 2.3109 - val_accuracy: 0.1000 - val_loss: 2.3152\n",
      "Epoch 24/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0989 - loss: 2.3121 - val_accuracy: 0.1000 - val_loss: 2.3074\n",
      "Epoch 25/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0989 - loss: 2.3112 - val_accuracy: 0.1000 - val_loss: 2.3086\n",
      "Epoch 26/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1010 - loss: 2.3111 - val_accuracy: 0.1000 - val_loss: 2.3070\n",
      "Epoch 27/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0970 - loss: 2.3121 - val_accuracy: 0.1000 - val_loss: 2.3182\n",
      "Epoch 28/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0978 - loss: 2.3122 - val_accuracy: 0.1000 - val_loss: 2.3101\n",
      "Epoch 29/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0954 - loss: 2.3121 - val_accuracy: 0.1000 - val_loss: 2.3111\n",
      "Epoch 30/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0984 - loss: 2.3121 - val_accuracy: 0.1000 - val_loss: 2.3076\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 0.1001 - loss: 2.3085\n",
      "Epoch 1/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.1001 - loss: 442.0569 - val_accuracy: 0.1000 - val_loss: 2.3172\n",
      "Epoch 2/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0998 - loss: 2.3117 - val_accuracy: 0.1000 - val_loss: 2.3129\n",
      "Epoch 3/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1008 - loss: 2.3107 - val_accuracy: 0.1000 - val_loss: 2.3062\n",
      "Epoch 4/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0961 - loss: 2.3115 - val_accuracy: 0.1000 - val_loss: 2.3055\n",
      "Epoch 5/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1009 - loss: 2.3109 - val_accuracy: 0.1000 - val_loss: 2.3122\n",
      "Epoch 6/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1007 - loss: 2.3110 - val_accuracy: 0.1000 - val_loss: 2.3107\n",
      "Epoch 7/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0988 - loss: 2.3121 - val_accuracy: 0.1000 - val_loss: 2.3082\n",
      "Epoch 8/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0993 - loss: 2.3121 - val_accuracy: 0.1000 - val_loss: 2.3120\n",
      "Epoch 9/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0992 - loss: 2.3126 - val_accuracy: 0.1000 - val_loss: 2.3079\n",
      "Epoch 10/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0987 - loss: 2.3122 - val_accuracy: 0.1000 - val_loss: 2.3106\n",
      "Epoch 11/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0998 - loss: 2.3112 - val_accuracy: 0.1000 - val_loss: 2.3074\n",
      "Epoch 12/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1017 - loss: 2.3108 - val_accuracy: 0.1000 - val_loss: 2.3137\n",
      "Epoch 13/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1018 - loss: 2.3112 - val_accuracy: 0.1000 - val_loss: 2.3077\n",
      "Epoch 14/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1009 - loss: 2.3129 - val_accuracy: 0.1000 - val_loss: 2.3113\n",
      "Epoch 15/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1011 - loss: 2.3108 - val_accuracy: 0.1000 - val_loss: 2.3162\n",
      "Epoch 16/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0998 - loss: 2.3122 - val_accuracy: 0.1000 - val_loss: 2.3071\n",
      "Epoch 17/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0967 - loss: 2.3123 - val_accuracy: 0.1000 - val_loss: 2.3164\n",
      "Epoch 18/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0972 - loss: 2.3118 - val_accuracy: 0.1000 - val_loss: 2.3061\n",
      "Epoch 19/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0982 - loss: 2.3124 - val_accuracy: 0.1000 - val_loss: 2.3140\n",
      "Epoch 20/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0988 - loss: 2.3129 - val_accuracy: 0.1000 - val_loss: 2.3101\n",
      "Epoch 21/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1018 - loss: 2.3112 - val_accuracy: 0.1000 - val_loss: 2.3119\n",
      "Epoch 22/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0996 - loss: 2.3116 - val_accuracy: 0.1000 - val_loss: 2.3150\n",
      "Epoch 23/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0962 - loss: 2.3133 - val_accuracy: 0.1000 - val_loss: 2.3154\n",
      "Epoch 24/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1027 - loss: 2.3115 - val_accuracy: 0.1000 - val_loss: 2.3096\n",
      "Epoch 25/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0981 - loss: 2.3115 - val_accuracy: 0.1000 - val_loss: 2.3101\n",
      "Epoch 26/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0996 - loss: 2.3113 - val_accuracy: 0.1000 - val_loss: 2.3063\n",
      "Epoch 27/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1014 - loss: 2.3114 - val_accuracy: 0.1000 - val_loss: 2.3072\n",
      "Epoch 28/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1010 - loss: 2.3124 - val_accuracy: 0.1000 - val_loss: 2.3064\n",
      "Epoch 29/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0975 - loss: 2.3121 - val_accuracy: 0.1000 - val_loss: 2.3172\n",
      "Epoch 30/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0987 - loss: 2.3112 - val_accuracy: 0.1000 - val_loss: 2.3168\n",
      "Epoch 31/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1003 - loss: 2.3124 - val_accuracy: 0.1000 - val_loss: 2.3142\n",
      "Epoch 32/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0994 - loss: 2.3126 - val_accuracy: 0.1000 - val_loss: 2.3176\n",
      "Epoch 33/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1007 - loss: 2.3124 - val_accuracy: 0.1000 - val_loss: 2.3105\n",
      "Epoch 34/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1004 - loss: 2.3112 - val_accuracy: 0.1000 - val_loss: 2.3100\n",
      "Epoch 35/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0985 - loss: 2.3125 - val_accuracy: 0.1000 - val_loss: 2.3152\n",
      "Epoch 36/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0962 - loss: 2.3131 - val_accuracy: 0.1000 - val_loss: 2.3062\n",
      "Epoch 37/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0967 - loss: 2.3104 - val_accuracy: 0.1000 - val_loss: 2.3066\n",
      "Epoch 38/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1030 - loss: 2.3116 - val_accuracy: 0.1000 - val_loss: 2.3089\n",
      "Epoch 39/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.1004 - loss: 2.3115 - val_accuracy: 0.1000 - val_loss: 2.3103\n",
      "Epoch 40/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0997 - loss: 2.3113 - val_accuracy: 0.1000 - val_loss: 2.3095\n",
      "Epoch 41/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1014 - loss: 2.3108 - val_accuracy: 0.1000 - val_loss: 2.3088\n",
      "Epoch 42/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1050 - loss: 2.3102 - val_accuracy: 0.1000 - val_loss: 2.3155\n",
      "Epoch 43/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0985 - loss: 2.3124 - val_accuracy: 0.1000 - val_loss: 2.3058\n",
      "Epoch 44/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0961 - loss: 2.3109 - val_accuracy: 0.1000 - val_loss: 2.3089\n",
      "Epoch 45/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0974 - loss: 2.3112 - val_accuracy: 0.1000 - val_loss: 2.3162\n",
      "Epoch 46/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0976 - loss: 2.3128 - val_accuracy: 0.1000 - val_loss: 2.3114\n",
      "Epoch 47/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0979 - loss: 2.3112 - val_accuracy: 0.1000 - val_loss: 2.3081\n",
      "Epoch 48/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1004 - loss: 2.3122 - val_accuracy: 0.1000 - val_loss: 2.3082\n",
      "Epoch 49/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0988 - loss: 2.3113 - val_accuracy: 0.1000 - val_loss: 2.3145\n",
      "Epoch 50/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0966 - loss: 2.3124 - val_accuracy: 0.1000 - val_loss: 2.3074\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0988 - loss: 2.3084\n",
      "Epoch 1/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.1004 - loss: 651.2679 - val_accuracy: 0.1000 - val_loss: 2.3054\n",
      "Epoch 2/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0974 - loss: 2.3078 - val_accuracy: 0.1000 - val_loss: 2.3046\n",
      "Epoch 3/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1014 - loss: 2.3083 - val_accuracy: 0.1000 - val_loss: 2.3084\n",
      "Epoch 4/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0978 - loss: 2.3085 - val_accuracy: 0.1000 - val_loss: 2.3090\n",
      "Epoch 5/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1024 - loss: 2.3085 - val_accuracy: 0.1000 - val_loss: 2.3088\n",
      "Epoch 6/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1007 - loss: 2.3081 - val_accuracy: 0.1000 - val_loss: 2.3129\n",
      "Epoch 7/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0980 - loss: 2.3100 - val_accuracy: 0.1000 - val_loss: 2.3096\n",
      "Epoch 8/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0970 - loss: 2.3086 - val_accuracy: 0.1000 - val_loss: 2.3125\n",
      "Epoch 9/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0971 - loss: 2.3110 - val_accuracy: 0.1000 - val_loss: 2.3075\n",
      "Epoch 10/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0997 - loss: 2.3099 - val_accuracy: 0.1000 - val_loss: 2.3080\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.0975 - loss: 2.3077\n",
      "Epoch 1/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.0993 - loss: 476.9967 - val_accuracy: 0.1000 - val_loss: 2.3041\n",
      "Epoch 2/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0995 - loss: 2.3081 - val_accuracy: 0.1000 - val_loss: 2.3083\n",
      "Epoch 3/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0993 - loss: 2.3088 - val_accuracy: 0.1000 - val_loss: 2.3059\n",
      "Epoch 4/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0987 - loss: 2.3093 - val_accuracy: 0.1000 - val_loss: 2.3089\n",
      "Epoch 5/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0984 - loss: 2.3076 - val_accuracy: 0.1000 - val_loss: 2.3102\n",
      "Epoch 6/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0981 - loss: 2.3092 - val_accuracy: 0.1000 - val_loss: 2.3101\n",
      "Epoch 7/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1006 - loss: 2.3088 - val_accuracy: 0.1000 - val_loss: 2.3105\n",
      "Epoch 8/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0985 - loss: 2.3099 - val_accuracy: 0.1000 - val_loss: 2.3079\n",
      "Epoch 9/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0976 - loss: 2.3093 - val_accuracy: 0.1000 - val_loss: 2.3059\n",
      "Epoch 10/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1002 - loss: 2.3080 - val_accuracy: 0.1000 - val_loss: 2.3097\n",
      "Epoch 11/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1002 - loss: 2.3107 - val_accuracy: 0.1000 - val_loss: 2.3062\n",
      "Epoch 12/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1015 - loss: 2.3079 - val_accuracy: 0.1000 - val_loss: 2.3121\n",
      "Epoch 13/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0989 - loss: 2.3099 - val_accuracy: 0.1000 - val_loss: 2.3106\n",
      "Epoch 14/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1019 - loss: 2.3092 - val_accuracy: 0.1000 - val_loss: 2.3056\n",
      "Epoch 15/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0995 - loss: 2.3083 - val_accuracy: 0.1000 - val_loss: 2.3069\n",
      "Epoch 16/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0965 - loss: 2.3096 - val_accuracy: 0.1000 - val_loss: 2.3078\n",
      "Epoch 17/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1020 - loss: 2.3080 - val_accuracy: 0.1000 - val_loss: 2.3093\n",
      "Epoch 18/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1005 - loss: 2.3088 - val_accuracy: 0.1000 - val_loss: 2.3084\n",
      "Epoch 19/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1011 - loss: 2.3092 - val_accuracy: 0.1000 - val_loss: 2.3081\n",
      "Epoch 20/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1020 - loss: 2.3077 - val_accuracy: 0.1000 - val_loss: 2.3098\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 916us/step - accuracy: 0.1036 - loss: 2.3082\n",
      "Epoch 1/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.0983 - loss: 705.9652 - val_accuracy: 0.1000 - val_loss: 2.3054\n",
      "Epoch 2/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1004 - loss: 2.3076 - val_accuracy: 0.1000 - val_loss: 2.3073\n",
      "Epoch 3/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1003 - loss: 2.3087 - val_accuracy: 0.1000 - val_loss: 2.3116\n",
      "Epoch 4/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0981 - loss: 2.3085 - val_accuracy: 0.1000 - val_loss: 2.3071\n",
      "Epoch 5/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0982 - loss: 2.3091 - val_accuracy: 0.1000 - val_loss: 2.3073\n",
      "Epoch 6/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0987 - loss: 2.3088 - val_accuracy: 0.1000 - val_loss: 2.3169\n",
      "Epoch 7/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0982 - loss: 2.3097 - val_accuracy: 0.1000 - val_loss: 2.3053\n",
      "Epoch 8/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0994 - loss: 2.3090 - val_accuracy: 0.1000 - val_loss: 2.3080\n",
      "Epoch 9/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0986 - loss: 2.3085 - val_accuracy: 0.1000 - val_loss: 2.3101\n",
      "Epoch 10/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.1005 - loss: 2.3080 - val_accuracy: 0.1000 - val_loss: 2.3109\n",
      "Epoch 11/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0991 - loss: 2.3101 - val_accuracy: 0.1000 - val_loss: 2.3085\n",
      "Epoch 12/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0990 - loss: 2.3086 - val_accuracy: 0.1000 - val_loss: 2.3078\n",
      "Epoch 13/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0990 - loss: 2.3088 - val_accuracy: 0.1000 - val_loss: 2.3126\n",
      "Epoch 14/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0990 - loss: 2.3085 - val_accuracy: 0.1000 - val_loss: 2.3039\n",
      "Epoch 15/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0993 - loss: 2.3076 - val_accuracy: 0.1000 - val_loss: 2.3122\n",
      "Epoch 16/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1004 - loss: 2.3097 - val_accuracy: 0.1000 - val_loss: 2.3079\n",
      "Epoch 17/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1000 - loss: 2.3093 - val_accuracy: 0.1000 - val_loss: 2.3043\n",
      "Epoch 18/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1018 - loss: 2.3091 - val_accuracy: 0.1000 - val_loss: 2.3085\n",
      "Epoch 19/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0994 - loss: 2.3080 - val_accuracy: 0.1000 - val_loss: 2.3064\n",
      "Epoch 20/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1008 - loss: 2.3092 - val_accuracy: 0.1000 - val_loss: 2.3132\n",
      "Epoch 21/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1004 - loss: 2.3100 - val_accuracy: 0.1000 - val_loss: 2.3070\n",
      "Epoch 22/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1002 - loss: 2.3084 - val_accuracy: 0.1000 - val_loss: 2.3126\n",
      "Epoch 23/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1013 - loss: 2.3100 - val_accuracy: 0.1000 - val_loss: 2.3132\n",
      "Epoch 24/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1005 - loss: 2.3093 - val_accuracy: 0.1000 - val_loss: 2.3082\n",
      "Epoch 25/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1015 - loss: 2.3080 - val_accuracy: 0.1000 - val_loss: 2.3072\n",
      "Epoch 26/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0970 - loss: 2.3092 - val_accuracy: 0.1000 - val_loss: 2.3071\n",
      "Epoch 27/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0989 - loss: 2.3088 - val_accuracy: 0.1000 - val_loss: 2.3102\n",
      "Epoch 28/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1017 - loss: 2.3093 - val_accuracy: 0.1000 - val_loss: 2.3079\n",
      "Epoch 29/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1031 - loss: 2.3095 - val_accuracy: 0.1000 - val_loss: 2.3084\n",
      "Epoch 30/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0979 - loss: 2.3095 - val_accuracy: 0.1000 - val_loss: 2.3086\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 0.1027 - loss: 2.3070\n",
      "Epoch 1/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.0978 - loss: 618.7703 - val_accuracy: 0.1000 - val_loss: 2.3067\n",
      "Epoch 2/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0968 - loss: 2.3087 - val_accuracy: 0.1000 - val_loss: 2.3055\n",
      "Epoch 3/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0984 - loss: 2.3079 - val_accuracy: 0.1000 - val_loss: 2.3120\n",
      "Epoch 4/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.0979 - loss: 2.3103 - val_accuracy: 0.1000 - val_loss: 2.3086\n",
      "Epoch 5/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0972 - loss: 2.3084 - val_accuracy: 0.1000 - val_loss: 2.3104\n",
      "Epoch 6/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0986 - loss: 2.3092 - val_accuracy: 0.1000 - val_loss: 2.3157\n",
      "Epoch 7/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1004 - loss: 2.3094 - val_accuracy: 0.1000 - val_loss: 2.3065\n",
      "Epoch 8/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1010 - loss: 2.3088 - val_accuracy: 0.1000 - val_loss: 2.3062\n",
      "Epoch 9/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1012 - loss: 2.3094 - val_accuracy: 0.1000 - val_loss: 2.3132\n",
      "Epoch 10/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0997 - loss: 2.3082 - val_accuracy: 0.1000 - val_loss: 2.3063\n",
      "Epoch 11/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1031 - loss: 2.3083 - val_accuracy: 0.1000 - val_loss: 2.3088\n",
      "Epoch 12/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0997 - loss: 2.3087 - val_accuracy: 0.1000 - val_loss: 2.3121\n",
      "Epoch 13/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0994 - loss: 2.3079 - val_accuracy: 0.1000 - val_loss: 2.3098\n",
      "Epoch 14/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0978 - loss: 2.3091 - val_accuracy: 0.1000 - val_loss: 2.3115\n",
      "Epoch 15/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0992 - loss: 2.3099 - val_accuracy: 0.1000 - val_loss: 2.3095\n",
      "Epoch 16/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1011 - loss: 2.3086 - val_accuracy: 0.1000 - val_loss: 2.3064\n",
      "Epoch 17/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0977 - loss: 2.3087 - val_accuracy: 0.1000 - val_loss: 2.3066\n",
      "Epoch 18/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0989 - loss: 2.3094 - val_accuracy: 0.1000 - val_loss: 2.3112\n",
      "Epoch 19/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0980 - loss: 2.3092 - val_accuracy: 0.1000 - val_loss: 2.3092\n",
      "Epoch 20/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0973 - loss: 2.3085 - val_accuracy: 0.1000 - val_loss: 2.3091\n",
      "Epoch 21/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0988 - loss: 2.3093 - val_accuracy: 0.1000 - val_loss: 2.3124\n",
      "Epoch 22/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.0976 - loss: 2.3092 - val_accuracy: 0.1000 - val_loss: 2.3113\n",
      "Epoch 23/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0975 - loss: 2.3104 - val_accuracy: 0.1000 - val_loss: 2.3133\n",
      "Epoch 24/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0964 - loss: 2.3102 - val_accuracy: 0.1000 - val_loss: 2.3045\n",
      "Epoch 25/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1004 - loss: 2.3074 - val_accuracy: 0.1000 - val_loss: 2.3083\n",
      "Epoch 26/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0981 - loss: 2.3082 - val_accuracy: 0.1000 - val_loss: 2.3092\n",
      "Epoch 27/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0990 - loss: 2.3088 - val_accuracy: 0.1000 - val_loss: 2.3112\n",
      "Epoch 28/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0996 - loss: 2.3098 - val_accuracy: 0.1000 - val_loss: 2.3065\n",
      "Epoch 29/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0982 - loss: 2.3098 - val_accuracy: 0.1000 - val_loss: 2.3057\n",
      "Epoch 30/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1009 - loss: 2.3088 - val_accuracy: 0.1000 - val_loss: 2.3118\n",
      "Epoch 31/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0979 - loss: 2.3096 - val_accuracy: 0.1000 - val_loss: 2.3050\n",
      "Epoch 32/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0984 - loss: 2.3079 - val_accuracy: 0.1000 - val_loss: 2.3096\n",
      "Epoch 33/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0983 - loss: 2.3090 - val_accuracy: 0.1000 - val_loss: 2.3053\n",
      "Epoch 34/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0972 - loss: 2.3089 - val_accuracy: 0.1000 - val_loss: 2.3089\n",
      "Epoch 35/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0981 - loss: 2.3093 - val_accuracy: 0.1000 - val_loss: 2.3095\n",
      "Epoch 36/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0987 - loss: 2.3113 - val_accuracy: 0.1000 - val_loss: 2.3072\n",
      "Epoch 37/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1012 - loss: 2.3083 - val_accuracy: 0.1000 - val_loss: 2.3082\n",
      "Epoch 38/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1003 - loss: 2.3084 - val_accuracy: 0.1000 - val_loss: 2.3053\n",
      "Epoch 39/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0987 - loss: 2.3081 - val_accuracy: 0.1000 - val_loss: 2.3081\n",
      "Epoch 40/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1004 - loss: 2.3097 - val_accuracy: 0.1000 - val_loss: 2.3065\n",
      "Epoch 41/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0996 - loss: 2.3083 - val_accuracy: 0.1000 - val_loss: 2.3129\n",
      "Epoch 42/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0989 - loss: 2.3097 - val_accuracy: 0.1000 - val_loss: 2.3108\n",
      "Epoch 43/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0988 - loss: 2.3100 - val_accuracy: 0.1000 - val_loss: 2.3128\n",
      "Epoch 44/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0988 - loss: 2.3091 - val_accuracy: 0.1000 - val_loss: 2.3115\n",
      "Epoch 45/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1015 - loss: 2.3101 - val_accuracy: 0.1000 - val_loss: 2.3054\n",
      "Epoch 46/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1024 - loss: 2.3083 - val_accuracy: 0.1000 - val_loss: 2.3107\n",
      "Epoch 47/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1007 - loss: 2.3087 - val_accuracy: 0.1000 - val_loss: 2.3106\n",
      "Epoch 48/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1000 - loss: 2.3090 - val_accuracy: 0.1000 - val_loss: 2.3056\n",
      "Epoch 49/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0970 - loss: 2.3087 - val_accuracy: 0.1000 - val_loss: 2.3106\n",
      "Epoch 50/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1002 - loss: 2.3076 - val_accuracy: 0.1000 - val_loss: 2.3136\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.0995 - loss: 2.3133\n",
      "Epoch 1/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.1033 - loss: 707.1315 - val_accuracy: 0.1000 - val_loss: 2.3069\n",
      "Epoch 2/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0964 - loss: 2.3058 - val_accuracy: 0.1000 - val_loss: 2.3068\n",
      "Epoch 3/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.0973 - loss: 2.3070 - val_accuracy: 0.1000 - val_loss: 2.3085\n",
      "Epoch 4/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.0978 - loss: 2.3071 - val_accuracy: 0.1000 - val_loss: 2.3094\n",
      "Epoch 5/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.0996 - loss: 2.3064 - val_accuracy: 0.1000 - val_loss: 2.3063\n",
      "Epoch 6/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.0976 - loss: 2.3071 - val_accuracy: 0.1000 - val_loss: 2.3113\n",
      "Epoch 7/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.0998 - loss: 2.3068 - val_accuracy: 0.1000 - val_loss: 2.3086\n",
      "Epoch 8/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1000 - loss: 2.3068 - val_accuracy: 0.1000 - val_loss: 2.3061\n",
      "Epoch 9/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.1022 - loss: 2.3062 - val_accuracy: 0.1000 - val_loss: 2.3071\n",
      "Epoch 10/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0988 - loss: 2.3069 - val_accuracy: 0.1000 - val_loss: 2.3055\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 992us/step - accuracy: 0.0968 - loss: 2.3055\n",
      "Epoch 1/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.1015 - loss: 2370.5225 - val_accuracy: 0.1000 - val_loss: 2.3060\n",
      "Epoch 2/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1001 - loss: 2.3066 - val_accuracy: 0.1000 - val_loss: 2.3064\n",
      "Epoch 3/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1016 - loss: 2.3055 - val_accuracy: 0.1000 - val_loss: 2.3074\n",
      "Epoch 4/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1026 - loss: 2.3061 - val_accuracy: 0.1000 - val_loss: 2.3103\n",
      "Epoch 5/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0983 - loss: 2.3070 - val_accuracy: 0.1000 - val_loss: 2.3061\n",
      "Epoch 6/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0977 - loss: 2.3075 - val_accuracy: 0.1000 - val_loss: 2.3071\n",
      "Epoch 7/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0995 - loss: 2.3076 - val_accuracy: 0.1000 - val_loss: 2.3070\n",
      "Epoch 8/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0993 - loss: 2.3068 - val_accuracy: 0.1000 - val_loss: 2.3041\n",
      "Epoch 9/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0992 - loss: 2.3064 - val_accuracy: 0.1000 - val_loss: 2.3072\n",
      "Epoch 10/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1017 - loss: 2.3069 - val_accuracy: 0.1000 - val_loss: 2.3092\n",
      "Epoch 11/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0991 - loss: 2.3072 - val_accuracy: 0.1000 - val_loss: 2.3079\n",
      "Epoch 12/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0975 - loss: 2.3085 - val_accuracy: 0.1000 - val_loss: 2.3053\n",
      "Epoch 13/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0983 - loss: 2.3065 - val_accuracy: 0.1000 - val_loss: 2.3077\n",
      "Epoch 14/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1021 - loss: 2.3070 - val_accuracy: 0.1000 - val_loss: 2.3047\n",
      "Epoch 15/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1006 - loss: 2.3061 - val_accuracy: 0.1000 - val_loss: 2.3052\n",
      "Epoch 16/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1025 - loss: 2.3061 - val_accuracy: 0.1000 - val_loss: 2.3058\n",
      "Epoch 17/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0984 - loss: 2.3072 - val_accuracy: 0.1000 - val_loss: 2.3067\n",
      "Epoch 18/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1024 - loss: 2.3063 - val_accuracy: 0.1000 - val_loss: 2.3080\n",
      "Epoch 19/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1053 - loss: 2.3067 - val_accuracy: 0.1000 - val_loss: 2.3065\n",
      "Epoch 20/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0989 - loss: 2.3071 - val_accuracy: 0.1000 - val_loss: 2.3076\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 0.1019 - loss: 2.3071\n",
      "Epoch 1/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.1013 - loss: 912.4483 - val_accuracy: 0.1000 - val_loss: 2.3056\n",
      "Epoch 2/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0999 - loss: 2.3053 - val_accuracy: 0.1000 - val_loss: 2.3050\n",
      "Epoch 3/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1028 - loss: 2.3058 - val_accuracy: 0.1000 - val_loss: 2.3047\n",
      "Epoch 4/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0965 - loss: 2.3067 - val_accuracy: 0.1000 - val_loss: 2.3072\n",
      "Epoch 5/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0984 - loss: 2.3063 - val_accuracy: 0.1000 - val_loss: 2.3043\n",
      "Epoch 6/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0971 - loss: 2.3057 - val_accuracy: 0.1000 - val_loss: 2.3050\n",
      "Epoch 7/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0999 - loss: 2.3064 - val_accuracy: 0.1000 - val_loss: 2.3066\n",
      "Epoch 8/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0983 - loss: 2.3066 - val_accuracy: 0.1000 - val_loss: 2.3076\n",
      "Epoch 9/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0995 - loss: 2.3079 - val_accuracy: 0.1000 - val_loss: 2.3059\n",
      "Epoch 10/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1006 - loss: 2.3058 - val_accuracy: 0.1000 - val_loss: 2.3069\n",
      "Epoch 11/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1005 - loss: 2.3069 - val_accuracy: 0.1000 - val_loss: 2.3070\n",
      "Epoch 12/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0976 - loss: 2.3066 - val_accuracy: 0.1000 - val_loss: 2.3057\n",
      "Epoch 13/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1030 - loss: 2.3064 - val_accuracy: 0.1000 - val_loss: 2.3041\n",
      "Epoch 14/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0987 - loss: 2.3069 - val_accuracy: 0.1000 - val_loss: 2.3070\n",
      "Epoch 15/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0969 - loss: 2.3088 - val_accuracy: 0.1000 - val_loss: 2.3068\n",
      "Epoch 16/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1004 - loss: 2.3067 - val_accuracy: 0.1000 - val_loss: 2.3070\n",
      "Epoch 17/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1003 - loss: 2.3073 - val_accuracy: 0.1000 - val_loss: 2.3056\n",
      "Epoch 18/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0965 - loss: 2.3077 - val_accuracy: 0.1000 - val_loss: 2.3037\n",
      "Epoch 19/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0979 - loss: 2.3065 - val_accuracy: 0.1000 - val_loss: 2.3050\n",
      "Epoch 20/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1003 - loss: 2.3071 - val_accuracy: 0.1000 - val_loss: 2.3031\n",
      "Epoch 21/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1000 - loss: 2.3062 - val_accuracy: 0.1000 - val_loss: 2.3081\n",
      "Epoch 22/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0995 - loss: 2.3065 - val_accuracy: 0.1000 - val_loss: 2.3052\n",
      "Epoch 23/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0998 - loss: 2.3070 - val_accuracy: 0.1000 - val_loss: 2.3045\n",
      "Epoch 24/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1009 - loss: 2.3062 - val_accuracy: 0.1000 - val_loss: 2.3046\n",
      "Epoch 25/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1002 - loss: 2.3076 - val_accuracy: 0.1000 - val_loss: 2.3049\n",
      "Epoch 26/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1006 - loss: 2.3065 - val_accuracy: 0.1000 - val_loss: 2.3058\n",
      "Epoch 27/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1026 - loss: 2.3061 - val_accuracy: 0.1000 - val_loss: 2.3062\n",
      "Epoch 28/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.1015 - loss: 2.3070 - val_accuracy: 0.1000 - val_loss: 2.3035\n",
      "Epoch 29/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0992 - loss: 2.3072 - val_accuracy: 0.1000 - val_loss: 2.3054\n",
      "Epoch 30/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0961 - loss: 2.3076 - val_accuracy: 0.1000 - val_loss: 2.3059\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.1036 - loss: 2.3057\n",
      "Epoch 1/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.1004 - loss: 1922.2506 - val_accuracy: 0.1000 - val_loss: 2.3038\n",
      "Epoch 2/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0979 - loss: 2.3056 - val_accuracy: 0.1000 - val_loss: 2.3053\n",
      "Epoch 3/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1009 - loss: 2.3058 - val_accuracy: 0.1000 - val_loss: 2.3063\n",
      "Epoch 4/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1002 - loss: 2.3063 - val_accuracy: 0.1000 - val_loss: 2.3054\n",
      "Epoch 5/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0976 - loss: 2.3072 - val_accuracy: 0.1000 - val_loss: 2.3050\n",
      "Epoch 6/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0960 - loss: 2.3058 - val_accuracy: 0.1000 - val_loss: 2.3081\n",
      "Epoch 7/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0994 - loss: 2.3066 - val_accuracy: 0.1000 - val_loss: 2.3097\n",
      "Epoch 8/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.1009 - loss: 2.3050 - val_accuracy: 0.1000 - val_loss: 2.3089\n",
      "Epoch 9/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0980 - loss: 2.3075 - val_accuracy: 0.1000 - val_loss: 2.3078\n",
      "Epoch 10/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0997 - loss: 2.3066 - val_accuracy: 0.1000 - val_loss: 2.3073\n",
      "Epoch 11/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1011 - loss: 2.3065 - val_accuracy: 0.1000 - val_loss: 2.3061\n",
      "Epoch 12/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0977 - loss: 2.3079 - val_accuracy: 0.1000 - val_loss: 2.3054\n",
      "Epoch 13/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0982 - loss: 2.3070 - val_accuracy: 0.1000 - val_loss: 2.3064\n",
      "Epoch 14/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0971 - loss: 2.3069 - val_accuracy: 0.1000 - val_loss: 2.3077\n",
      "Epoch 15/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1018 - loss: 2.3080 - val_accuracy: 0.1000 - val_loss: 2.3078\n",
      "Epoch 16/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1020 - loss: 2.3067 - val_accuracy: 0.1000 - val_loss: 2.3051\n",
      "Epoch 17/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0982 - loss: 2.3069 - val_accuracy: 0.1000 - val_loss: 2.3069\n",
      "Epoch 18/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0995 - loss: 2.3082 - val_accuracy: 0.1000 - val_loss: 2.3092\n",
      "Epoch 19/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1014 - loss: 2.3061 - val_accuracy: 0.1000 - val_loss: 2.3048\n",
      "Epoch 20/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1020 - loss: 2.3063 - val_accuracy: 0.1000 - val_loss: 2.3087\n",
      "Epoch 21/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0997 - loss: 2.3078 - val_accuracy: 0.1000 - val_loss: 2.3049\n",
      "Epoch 22/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.1016 - loss: 2.3062 - val_accuracy: 0.1000 - val_loss: 2.3038\n",
      "Epoch 23/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.1007 - loss: 2.3063 - val_accuracy: 0.1000 - val_loss: 2.3047\n",
      "Epoch 24/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0999 - loss: 2.3073 - val_accuracy: 0.1000 - val_loss: 2.3076\n",
      "Epoch 25/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.0980 - loss: 2.3074 - val_accuracy: 0.1000 - val_loss: 2.3082\n",
      "Epoch 26/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0979 - loss: 2.3067 - val_accuracy: 0.1000 - val_loss: 2.3108\n",
      "Epoch 27/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0981 - loss: 2.3074 - val_accuracy: 0.1000 - val_loss: 2.3076\n",
      "Epoch 28/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1025 - loss: 2.3063 - val_accuracy: 0.1000 - val_loss: 2.3077\n",
      "Epoch 29/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1001 - loss: 2.3069 - val_accuracy: 0.1000 - val_loss: 2.3067\n",
      "Epoch 30/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0990 - loss: 2.3061 - val_accuracy: 0.1000 - val_loss: 2.3054\n",
      "Epoch 31/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0984 - loss: 2.3065 - val_accuracy: 0.1000 - val_loss: 2.3081\n",
      "Epoch 32/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1007 - loss: 2.3065 - val_accuracy: 0.1000 - val_loss: 2.3101\n",
      "Epoch 33/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0993 - loss: 2.3074 - val_accuracy: 0.1000 - val_loss: 2.3046\n",
      "Epoch 34/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0992 - loss: 2.3057 - val_accuracy: 0.1000 - val_loss: 2.3065\n",
      "Epoch 35/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.1019 - loss: 2.3066 - val_accuracy: 0.1000 - val_loss: 2.3097\n",
      "Epoch 36/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1010 - loss: 2.3078 - val_accuracy: 0.1000 - val_loss: 2.3060\n",
      "Epoch 37/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1011 - loss: 2.3071 - val_accuracy: 0.1000 - val_loss: 2.3040\n",
      "Epoch 38/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0983 - loss: 2.3064 - val_accuracy: 0.1000 - val_loss: 2.3070\n",
      "Epoch 39/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0988 - loss: 2.3080 - val_accuracy: 0.1000 - val_loss: 2.3068\n",
      "Epoch 40/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1019 - loss: 2.3062 - val_accuracy: 0.1000 - val_loss: 2.3079\n",
      "Epoch 41/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0996 - loss: 2.3061 - val_accuracy: 0.1000 - val_loss: 2.3054\n",
      "Epoch 42/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0988 - loss: 2.3069 - val_accuracy: 0.1000 - val_loss: 2.3056\n",
      "Epoch 43/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1004 - loss: 2.3088 - val_accuracy: 0.1000 - val_loss: 2.3056\n",
      "Epoch 44/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1013 - loss: 2.3066 - val_accuracy: 0.1000 - val_loss: 2.3064\n",
      "Epoch 45/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1011 - loss: 2.3070 - val_accuracy: 0.1000 - val_loss: 2.3065\n",
      "Epoch 46/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.1017 - loss: 2.3067 - val_accuracy: 0.1000 - val_loss: 2.3085\n",
      "Epoch 47/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.1015 - loss: 2.3069 - val_accuracy: 0.1000 - val_loss: 2.3096\n",
      "Epoch 48/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0983 - loss: 2.3082 - val_accuracy: 0.1000 - val_loss: 2.3059\n",
      "Epoch 49/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1008 - loss: 2.3067 - val_accuracy: 0.1000 - val_loss: 2.3069\n",
      "Epoch 50/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1004 - loss: 2.3078 - val_accuracy: 0.1000 - val_loss: 2.3054\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.1019 - loss: 2.3057\n"
     ]
    }
   ],
   "source": [
    "# Realizar una búsqueda en cuadrícula de hiperparámetros\n",
    "best_acc = 0\n",
    "best_params = None\n",
    "for lr in learning_rates:\n",
    "    for bs in batch_sizes:\n",
    "        for ep in epochs:\n",
    "            model = create_model(lr)\n",
    "            history = model.fit(x_train, y_train, \n",
    "                                batch_size=bs, epochs=ep, \n",
    "                                validation_data=(x_test, y_test))\n",
    "            _, test_acc = model.evaluate(x_test, y_test)\n",
    "            if test_acc > best_acc:\n",
    "                best_acc = test_acc\n",
    "                best_params = (lr, bs, ep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.7649000287055969\n",
      "Best parameters: (0.001, 128, 30)\n"
     ]
    }
   ],
   "source": [
    "print('Best accuracy:', best_acc)\n",
    "print('Best parameters:', best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los mejores resultados se obtienen con una tasa de aprendizaje de 0.001, tamaño de lote de 128 y 30 épocas de entrenamiento, alcanzando una precisión de 76.49% en el conjunto de prueba. Esto representa una mejora de casi 11 puntos porcentuales respecto al modelo base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento 4: Técnicas Avanzadas (Batch Normalization)\n",
    "En esta parte se decidio implementar la Normalización por Lotes o Batch Normalization la cual en teoria, ayudaría a mejorar el rendimiento del modelo al normalizar las activaciones en cada lote durante el entrenamiento, lo que permitiría que el modelo converja más rápido y sea más estable. Esto se traduce en una mayor capacidad de generalización y precisión en la tarea de clasificación de imágenes.\n",
    "\n",
    "Una vez explicado ello implementó la técnica de Batch Normalization en el modelo de CNN. La Normalización por Lotes es una técnica que ayuda a acelerar y estabilizar el entrenamiento de redes neuronales profundas al normalizar las activaciones de cada capa.\n",
    "Se modificó la arquitectura del modelo agregando capas de BatchNormalization en la primera y tercera capa, asi para encontrar un equilibrio entre los beneficios de la normalización y el costo computacional adicional que implica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define un modelo con Normalización por lotes (Batch Normalization)\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "model_bn = Sequential(\n",
    "    [\n",
    "        Conv2D(32, (3, 3), activation=\"relu\", input_shape=(32, 32, 3)),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        Flatten(),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo se compiló utilizando el optimizador Adam con una tasa de aprendizaje de 0.001, la función de pérdida categorical crossentropy y se midió la precisión como métrica. Se entrenó por 30 épocas con un tamaño de lote de 128, los cuales son los valores que en el experimento 3 dieron mejores resultados a la hora de entrenar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.3012 - loss: 1.9600 - val_accuracy: 0.1995 - val_loss: 2.7960\n",
      "Epoch 2/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5411 - loss: 1.3020 - val_accuracy: 0.5733 - val_loss: 1.2269\n",
      "Epoch 3/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6272 - loss: 1.0779 - val_accuracy: 0.6551 - val_loss: 1.0070\n",
      "Epoch 4/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6709 - loss: 0.9454 - val_accuracy: 0.6772 - val_loss: 0.9087\n",
      "Epoch 5/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7092 - loss: 0.8398 - val_accuracy: 0.7117 - val_loss: 0.8514\n",
      "Epoch 6/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7330 - loss: 0.7661 - val_accuracy: 0.5674 - val_loss: 1.4497\n",
      "Epoch 7/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7551 - loss: 0.7006 - val_accuracy: 0.7085 - val_loss: 0.8603\n",
      "Epoch 8/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7715 - loss: 0.6555 - val_accuracy: 0.7019 - val_loss: 0.9182\n",
      "Epoch 9/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7852 - loss: 0.6161 - val_accuracy: 0.7081 - val_loss: 0.8734\n",
      "Epoch 10/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8031 - loss: 0.5666 - val_accuracy: 0.7393 - val_loss: 0.8260\n",
      "Epoch 11/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8133 - loss: 0.5309 - val_accuracy: 0.7648 - val_loss: 0.7256\n",
      "Epoch 12/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8226 - loss: 0.5081 - val_accuracy: 0.7526 - val_loss: 0.7945\n",
      "Epoch 13/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8317 - loss: 0.4767 - val_accuracy: 0.7463 - val_loss: 0.8446\n",
      "Epoch 14/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8432 - loss: 0.4339 - val_accuracy: 0.7121 - val_loss: 0.9857\n",
      "Epoch 15/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8495 - loss: 0.4238 - val_accuracy: 0.7581 - val_loss: 0.8118\n",
      "Epoch 16/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8623 - loss: 0.3922 - val_accuracy: 0.7672 - val_loss: 0.7796\n",
      "Epoch 17/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8637 - loss: 0.3789 - val_accuracy: 0.7641 - val_loss: 0.8217\n",
      "Epoch 18/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8684 - loss: 0.3647 - val_accuracy: 0.7561 - val_loss: 0.8273\n",
      "Epoch 19/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8720 - loss: 0.3515 - val_accuracy: 0.7648 - val_loss: 0.8685\n",
      "Epoch 20/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8784 - loss: 0.3342 - val_accuracy: 0.7737 - val_loss: 0.8535\n",
      "Epoch 21/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8840 - loss: 0.3234 - val_accuracy: 0.7719 - val_loss: 0.8832\n",
      "Epoch 22/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8915 - loss: 0.3030 - val_accuracy: 0.7831 - val_loss: 0.8342\n",
      "Epoch 23/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8930 - loss: 0.2949 - val_accuracy: 0.7715 - val_loss: 0.8634\n",
      "Epoch 24/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8998 - loss: 0.2733 - val_accuracy: 0.7802 - val_loss: 0.8788\n",
      "Epoch 25/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9046 - loss: 0.2619 - val_accuracy: 0.7764 - val_loss: 0.9229\n",
      "Epoch 26/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9076 - loss: 0.2588 - val_accuracy: 0.7616 - val_loss: 1.0190\n",
      "Epoch 27/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9102 - loss: 0.2497 - val_accuracy: 0.7767 - val_loss: 0.9779\n",
      "Epoch 28/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9126 - loss: 0.2361 - val_accuracy: 0.7745 - val_loss: 0.9297\n",
      "Epoch 29/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9165 - loss: 0.2309 - val_accuracy: 0.7736 - val_loss: 1.0130\n",
      "Epoch 30/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9201 - loss: 0.2255 - val_accuracy: 0.7750 - val_loss: 0.9688\n"
     ]
    }
   ],
   "source": [
    "# Compilar y entrenar el modelo\n",
    "model_bn.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history_bn = model_bn.fit(\n",
    "    x_train, y_train, batch_size=128, epochs=30, validation_data=(x_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7812 - loss: 0.9185\n",
      "Test accuracy (modelo Batch Normalization): 0.7749999761581421\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo modificado en el conjunto de test\n",
    "test_loss_bn, test_acc_bn = model_bn.evaluate(x_test, y_test)\n",
    "print('Test accuracy (modelo Batch Normalization):', test_acc_bn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo tuvo una precisión de 77.50%, este comprueba que efectivamente, de ser aplicados de manera correcta las técnicas avanzadas pueden ayudar a mejorar la precisión de los modelos construidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados y Discusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los experimentos realizados demuestran que tanto la arquitectura como los hiperparámetros tienen un impacto significativo en el rendimiento de las CNNs para la clasificación de imágenes.\n",
    "\n",
    "Agregar más capas convolucionales, aumentar el número de filtros y aplicar ciertas técnicas permite al modelo aprender características más complejas y discriminativas. La capa de dropout ayuda a reducir el sobreajuste, mejorando la capacidad de generalización. Por otro lado, ajustar hiperparámetros como la tasa de aprendizaje, el tamaño de lote y el número de épocas es crucial para encontrar la configuración óptima que permita al modelo converger adecuadamente y obtener un buen desempeño.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se demostró que realizar cambios en la arquitectura, como agregar más capas convolucionales, aumentar el número de filtros e incluir dropout, así como ajustar hiperparámetros clave como la tasa de aprendizaje, el tamaño de lote y el número de épocas, permite mejorar significativamente la precisión del modelo base.\n",
    "\n",
    "Los resultados obtenidos resaltan la importancia de experimentar con diferentes configuraciones al construir modelos de CNNs para obtener un buen desempeño en tareas de visión por computadora. Como trabajo futuro, se podrían explorar técnicas adicionales y arquitecturas más avanzadas para seguir mejorando la capacidad de clasificación de imágenes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep learning. MIT press.\n",
    "\n",
    " Krizhevsky, A., & Hinton, G. (2009). Learning multiple layers of features from tiny images.\n",
    "\n",
    " Chollet, F. (2018). Deep learning with Python. Simon and Schuster.\n",
    " \n",
    " Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep learning. MIT press."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
