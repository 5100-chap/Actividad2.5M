{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad M2.5\n",
    "\n",
    "### Diego Alberto Baños Lopez A01275100\n",
    "\n",
    "## Resumen\n",
    "\n",
    "En este reporte, se exploran diferentes arquitecturas e hiperparámetros de Redes Neuronales Convolucionales (CNNs) para la clasificación de imágenes utilizando el conjunto de datos CIFAR-10. Se implementa un modelo CNN base y se realizan experimentos variando la arquitectura e hiperparámetros para analizar su impacto en el rendimiento. Los resultados muestran que agregar más capas convolucionales, aumentar el número de filtros y ajustar hiperparámetros como la tasa de aprendizaje, el tamaño de lote y el número de épocas, permite mejorar significativamente la precisión del modelo base. Este trabajo demuestra la importancia de explorar diferentes configuraciones en las CNNs para obtener un buen desempeño en tareas de clasificación de imágenes.\n",
    "\n",
    "\n",
    "## Introducción\n",
    "Las Redes Neuronales Convolucionales (CNNs) han demostrado ser muy efectivas en tareas de visión por computadora, especialmente en la clasificación de imágenes. Su capacidad para aprender características jerárquicas directamente de los datos las hace muy adecuadas para procesar imágenes.\n",
    "En este trabajo, se explora el impacto de diferentes arquitecturas e hiperparámetros en el rendimiento de las CNNs utilizando el conjunto de datos CIFAR-10 y usando el framework de Tensorflow. Se parte de un modelo CNN base y se realizan experimentos variando componentes como el número de capas convolucionales, número de filtros, capas de dropout, así como hiperparámetros como la tasa de aprendizaje, tamaño de lote y número de épocas. El objetivo es analizar cómo estos cambios afectan la capacidad del modelo para clasificar correctamente las imágenes.\n",
    "\n",
    "## Metodología\n",
    "\n",
    "### 1. Uso de la GPU\n",
    "Primeramente, el autor de este reporte descubrio que Tensorflow puede trabajar de forma más eficiente si puede hacer uso de la GPU, asi que verificamos si el framework anteriormente mencionado detecta el dispositivo, que en este caso es una RTX 3050 TI de laptop, cabe recalcar que este paso no es obligatorio y simplemente ayuda a realizar con mayor rapidez los modelos de este reporte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (23.3.1)\n",
      "Collecting pip\n",
      "  Using cached pip-24.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Using cached pip-24.0-py3-none-any.whl (2.1 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.3.1\n",
      "    Uninstalling pip-23.3.1:\n",
      "      Successfully uninstalled pip-23.3.1\n",
      "Successfully installed pip-24.0\n",
      "Requirement already satisfied: tensorflow[and-cuda] in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (1.26.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (4.23.4)\n",
      "Requirement already satisfied: setuptools in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (1.59.3)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (2.15.0)\n",
      "Collecting nvidia-cublas-cu12==12.2.5.6 (from tensorflow[and-cuda])\n",
      "  Downloading nvidia_cublas_cu12-12.2.5.6-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.2.142 (from tensorflow[and-cuda])\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.2.142-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cuda-nvcc-cu12==12.2.140 (from tensorflow[and-cuda])\n",
      "  Downloading nvidia_cuda_nvcc_cu12-12.2.140-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.2.140 (from tensorflow[and-cuda])\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.2.140-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.2.140 (from tensorflow[and-cuda])\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.2.140-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.4.25 (from tensorflow[and-cuda])\n",
      "  Downloading nvidia_cudnn_cu12-8.9.4.25-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.8.103 (from tensorflow[and-cuda])\n",
      "  Downloading nvidia_cufft_cu12-11.0.8.103-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.3.141 (from tensorflow[and-cuda])\n",
      "  Downloading nvidia_curand_cu12-10.3.3.141-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.5.2.141 (from tensorflow[and-cuda])\n",
      "  Downloading nvidia_cusolver_cu12-11.5.2.141-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.2.141 (from tensorflow[and-cuda])\n",
      "  Downloading nvidia_cusparse_cu12-12.1.2.141-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.16.5 (from tensorflow[and-cuda])\n",
      "  Downloading nvidia_nccl_cu12-2.16.5-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.2.140 (from tensorflow[and-cuda])\n",
      "  Downloading nvidia_nvjitlink_cu12-12.2.140-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting tensorrt==8.6.1.post1 (from tensorflow[and-cuda])\n",
      "  Downloading tensorrt-8.6.1.post1.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorrt-bindings==8.6.1 (from tensorflow[and-cuda])\n",
      "  Downloading tensorrt_bindings-8.6.1-cp311-none-manylinux_2_17_x86_64.whl.metadata (621 bytes)\n",
      "INFO: pip is looking at multiple versions of tensorflow[and-cuda] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Using cached tensorflow-2.16.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow[and-cuda])\n",
      "  Using cached ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (2.31.0)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow[and-cuda])\n",
      "  Using cached tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.0.0 (from tensorflow[and-cuda])\n",
      "  Using cached keras-3.3.3-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting nvidia-cublas-cu12==12.3.4.1 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cublas_cu12-12.3.4.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.3.101 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cuda-nvcc-cu12==12.3.107 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_nvcc_cu12-12.3.107-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.3.107 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.3.107-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.3.101 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.7.29 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cudnn_cu12-8.9.7.29-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.12.1 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cufft_cu12-11.0.12.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.4.107 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_curand_cu12-10.3.4.107-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.5.4.101 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cusolver_cu12-11.5.4.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.2.0.103 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cusparse_cu12-12.2.0.103-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.3.101 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (12.3.101)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow[and-cuda]) (0.41.3)\n",
      "Requirement already satisfied: rich in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow[and-cuda]) (13.7.0)\n",
      "Collecting namex (from keras>=3.0.0->tensorflow[and-cuda])\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.0.0->tensorflow[and-cuda])\n",
      "  Using cached optree-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (45 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (2023.11.17)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow[and-cuda]) (3.5.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow[and-cuda]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow[and-cuda]) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow[and-cuda]) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow[and-cuda]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow[and-cuda]) (2.17.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow[and-cuda]) (0.1.2)\n",
      "Using cached nvidia_cublas_cu12-12.3.4.1-py3-none-manylinux1_x86_64.whl (412.6 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (14.0 MB)\n",
      "Using cached nvidia_cuda_nvcc_cu12-12.3.107-py3-none-manylinux1_x86_64.whl (22.0 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.3.107-py3-none-manylinux1_x86_64.whl (24.9 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (867 kB)\n",
      "Using cached nvidia_cudnn_cu12-8.9.7.29-py3-none-manylinux1_x86_64.whl (704.7 MB)\n",
      "Using cached nvidia_cufft_cu12-11.0.12.1-py3-none-manylinux1_x86_64.whl (98.8 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.4.107-py3-none-manylinux1_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.5.4.101-py3-none-manylinux1_x86_64.whl (125.2 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.2.0.103-py3-none-manylinux1_x86_64.whl (197.5 MB)\n",
      "Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "Using cached keras-3.3.3-py3-none-any.whl (1.1 MB)\n",
      "Using cached ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "Using cached tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "Using cached tensorflow-2.16.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
      "Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Using cached optree-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (312 kB)\n",
      "Installing collected packages: namex, optree, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-nvcc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ml-dtypes, tensorboard, nvidia-cusolver-cu12, nvidia-cudnn-cu12, keras, tensorflow\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.18.1\n",
      "    Uninstalling nvidia-nccl-cu12-2.18.1:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.18.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.1.0.106\n",
      "    Uninstalling nvidia-cusparse-cu12-12.1.0.106:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.2.106\n",
      "    Uninstalling nvidia-curand-cu12-10.3.2.106:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.2.106\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.0.2.54\n",
      "    Uninstalling nvidia-cufft-cu12-11.0.2.54:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.1.3.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.1.3.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1\n",
      "  Attempting uninstall: ml-dtypes\n",
      "    Found existing installation: ml-dtypes 0.2.0\n",
      "    Uninstalling ml-dtypes-0.2.0:\n",
      "      Successfully uninstalled ml-dtypes-0.2.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.15.1\n",
      "    Uninstalling tensorboard-2.15.1:\n",
      "      Successfully uninstalled tensorboard-2.15.1\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.4.5.107\n",
      "    Uninstalling nvidia-cusolver-cu12-11.4.5.107:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 8.9.2.26\n",
      "    Uninstalling nvidia-cudnn-cu12-8.9.2.26:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-8.9.2.26\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.15.0\n",
      "    Uninstalling keras-2.15.0:\n",
      "      Successfully uninstalled keras-2.15.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.15.0\n",
      "    Uninstalling tensorflow-2.15.0:\n",
      "      Successfully uninstalled tensorflow-2.15.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torch 2.1.1 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.3.4.1 which is incompatible.\n",
      "torch 2.1.1 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.3.101 which is incompatible.\n",
      "torch 2.1.1 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.3.107 which is incompatible.\n",
      "torch 2.1.1 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.3.101 which is incompatible.\n",
      "torch 2.1.1 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 8.9.7.29 which is incompatible.\n",
      "torch 2.1.1 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.0.12.1 which is incompatible.\n",
      "torch 2.1.1 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.4.107 which is incompatible.\n",
      "torch 2.1.1 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.5.4.101 which is incompatible.\n",
      "torch 2.1.1 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.2.0.103 which is incompatible.\n",
      "torch 2.1.1 requires nvidia-nccl-cu12==2.18.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nccl-cu12 2.19.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed keras-3.3.3 ml-dtypes-0.3.2 namex-0.0.8 nvidia-cublas-cu12-12.3.4.1 nvidia-cuda-cupti-cu12-12.3.101 nvidia-cuda-nvcc-cu12-12.3.107 nvidia-cuda-nvrtc-cu12-12.3.107 nvidia-cuda-runtime-cu12-12.3.101 nvidia-cudnn-cu12-8.9.7.29 nvidia-cufft-cu12-11.0.12.1 nvidia-curand-cu12-10.3.4.107 nvidia-cusolver-cu12-11.5.4.101 nvidia-cusparse-cu12-12.2.0.103 nvidia-nccl-cu12-2.19.3 optree-0.11.0 tensorboard-2.16.2 tensorflow-2.16.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 18:00:04.044802: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 18:00:04.088817: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 18:00:04.684210: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "2.16.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 18:00:06.692486: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-13 18:00:06.709078: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "#Checamos si podemos usar la GPU\n",
    "!pip install --upgrade pip\n",
    "!pip install 'tensorflow[and-cuda]'\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "print(\"Num GPUs Available: \" , len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Conjunto de datos\n",
    "Se utiliza el conjunto de datos CIFAR-10, que consiste en 60 000 imágenes a color de 32x32 píxeles, divididas en 10 clases: avión, automóvil, pájaro, gato, ciervo, perro, rana, caballo, barco y camión. Hay 50 000 imágenes de entrenamiento y 10 000 imágenes de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide los datos en donde X son las imagenes del dataset y Y son las etiquetas de entrenamiento para las imagenes\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (3.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from matplotlib) (4.45.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from matplotlib) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Imprimir la imagen seleccionada\n",
    "plt.imshow(x_train[51])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de datos en x_train:  50000\n",
      "Numero de datos en y_train:  50000\n",
      "Numero de datos en x_test:  10000\n",
      "Numero de datos en y_test:  10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Numero de datos en x_train: \", len(x_train))\n",
    "print(\"Numero de datos en y_train: \", len(y_train))\n",
    "print(\"Numero de datos en x_test: \", len(x_test))\n",
    "print(\"Numero de datos en y_test: \", len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preprocesamiento\n",
    "\n",
    "Las imágenes se normalizan dividiendo los valores de píxeles entre 255 para escalarlos al rango. Además, las etiquetas se codifican en one-hot encoding para ser compatibles con la capa de salida softmax del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar los datos de entrada\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# Convertir las etiquetas a one-hot encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Modelo base\n",
    "El modelo base consiste en la siguiente arquitectura:\n",
    "- Capa convolucional con 32 filtros de 3x3 y activación ReLU\n",
    "- Capa de max pooling de 2x2\n",
    "- Capa flatten\n",
    "- Capa densa con 128 unidades y activación ReLU\n",
    "- Capa de salida densa con activación softmax\n",
    "\n",
    "El modelo se compila utilizando el optimizador Adam, la función de pérdida categorical crossentropy y se mide la precisión como métrica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/upijijis/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Definir el modelo base de CNN\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentos\n",
    "\n",
    "### Experimento 1: Modelo base\n",
    "El modelo base se entrena por 10 épocas con un tamaño de lote de 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - accuracy: 0.3705 - loss: 1.7733 - val_accuracy: 0.5394 - val_loss: 1.3061\n",
      "Epoch 2/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 29ms/step - accuracy: 0.5566 - loss: 1.2633 - val_accuracy: 0.5819 - val_loss: 1.1897\n",
      "Epoch 3/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 30ms/step - accuracy: 0.6065 - loss: 1.1363 - val_accuracy: 0.5856 - val_loss: 1.1636\n",
      "Epoch 4/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 29ms/step - accuracy: 0.6319 - loss: 1.0566 - val_accuracy: 0.6026 - val_loss: 1.1303\n",
      "Epoch 5/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 30ms/step - accuracy: 0.6601 - loss: 0.9810 - val_accuracy: 0.6104 - val_loss: 1.1047\n",
      "Epoch 6/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 34ms/step - accuracy: 0.6757 - loss: 0.9317 - val_accuracy: 0.6422 - val_loss: 1.0362\n",
      "Epoch 7/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 34ms/step - accuracy: 0.6959 - loss: 0.8796 - val_accuracy: 0.6392 - val_loss: 1.0253\n",
      "Epoch 8/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 34ms/step - accuracy: 0.7089 - loss: 0.8383 - val_accuracy: 0.6362 - val_loss: 1.0325\n",
      "Epoch 9/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 34ms/step - accuracy: 0.7229 - loss: 0.8020 - val_accuracy: 0.6551 - val_loss: 0.9909\n",
      "Epoch 10/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 34ms/step - accuracy: 0.7403 - loss: 0.7566 - val_accuracy: 0.6560 - val_loss: 1.0026\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "history = model.fit(x_train, y_train, \n",
    "                    batch_size=128, epochs=10, \n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6602 - loss: 0.9878\n",
      "Test accuracy: 0.656000018119812\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en el conjunto de test\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez completado la evaluación se obtiene una precisión de 65.6% en el conjunto de prueba, indicando que el modelo base puede predecir mas de la mitad de los datos de prueba de manera correcta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento 2: Cambio de arquitectura\n",
    "Se modifica la arquitectura base agregando más capas convolucionales, aumentando el número de filtros y agregando una capa de dropout:\n",
    "- Conv2D con 32 filtros de 3x3 y activación ReLU\n",
    "- Conv2D con 64 filtros de 3x3 y activación ReLU\n",
    "- MaxPooling de 2x2\n",
    "- Conv2D con 64 filtros de 3x3 y activación ReLU\n",
    "- MaxPooling de 2x2\n",
    "- Conv2D con 64 filtros de 3x3 y activación ReLU\n",
    "- Flatten\n",
    "- Dense con 64 unidades y activación ReLU\n",
    "- Dropout con tasa de 0.5\n",
    "- Dense de salida con activación softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir un modelo modificado de CNN\n",
    "model_v2 = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 77ms/step - accuracy: 0.2504 - loss: 1.9905 - val_accuracy: 0.4889 - val_loss: 1.4144\n",
      "Epoch 2/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 78ms/step - accuracy: 0.4646 - loss: 1.4698 - val_accuracy: 0.5717 - val_loss: 1.2104\n",
      "Epoch 3/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.5472 - loss: 1.2784 - val_accuracy: 0.6165 - val_loss: 1.0719\n",
      "Epoch 4/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.5980 - loss: 1.1450 - val_accuracy: 0.6605 - val_loss: 0.9632\n",
      "Epoch 5/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.6384 - loss: 1.0455 - val_accuracy: 0.6783 - val_loss: 0.9232\n",
      "Epoch 6/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 72ms/step - accuracy: 0.6640 - loss: 0.9666 - val_accuracy: 0.7049 - val_loss: 0.8515\n",
      "Epoch 7/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.6874 - loss: 0.9059 - val_accuracy: 0.7130 - val_loss: 0.8460\n",
      "Epoch 8/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 76ms/step - accuracy: 0.7042 - loss: 0.8572 - val_accuracy: 0.7211 - val_loss: 0.8071\n",
      "Epoch 9/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 73ms/step - accuracy: 0.7110 - loss: 0.8284 - val_accuracy: 0.7300 - val_loss: 0.7840\n",
      "Epoch 10/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.7301 - loss: 0.7784 - val_accuracy: 0.7332 - val_loss: 0.7784\n"
     ]
    }
   ],
   "source": [
    "# Compilar y entrenar el modelo modificado\n",
    "model_v2.compile(optimizer='adam',\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "history_v2 = model_v2.fit(x_train, y_train, \n",
    "                          batch_size=128, epochs=10, \n",
    "                          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7367 - loss: 0.7679\n",
      "Test accuracy (modelo modificado): 0.7332000136375427\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo modificado en el conjunto de test\n",
    "test_loss_v2, test_acc_v2 = model_v2.evaluate(x_test, y_test)\n",
    "print('Test accuracy (modelo modificado):', test_acc_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con las modificaciones al modelo se logra una precisión de 73.32% en el conjunto de prueba, mejorando en más de 8 puntos porcentuales al modelo base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento 3: Ajuste de hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando las bases del modelo modificado se exploran diferentes valores para la tasa de aprendizaje (0.1, 0.01, 0.001, 0.0001), tamaño de lote (32, 64, 128, 256) y número de épocas (10, 20, 30, 50). Se evalua cada uno para asi determinar cual es la mejor configuración de hiperparametros para entrenar el modelo anteriormente mencionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el modelo con hiperparámetros variables\n",
    "def create_model(learning_rate):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los valores de los hiperparámetros a explorar\n",
    "learning_rates = [0.0001,0.001, 0.01, 0.1]\n",
    "batch_sizes = [32, 64, 128, 256]\n",
    "epochs = [10, 20, 30, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 18ms/step - accuracy: 0.2183 - loss: 2.0901 - val_accuracy: 0.4285 - val_loss: 1.6154\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - accuracy: 0.3846 - loss: 1.6732 - val_accuracy: 0.4903 - val_loss: 1.4615\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.4440 - loss: 1.5352 - val_accuracy: 0.5275 - val_loss: 1.3285\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 18ms/step - accuracy: 0.4778 - loss: 1.4440 - val_accuracy: 0.5495 - val_loss: 1.2785\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.5119 - loss: 1.3615 - val_accuracy: 0.5864 - val_loss: 1.1807\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.5374 - loss: 1.3049 - val_accuracy: 0.5879 - val_loss: 1.1574\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.5603 - loss: 1.2500 - val_accuracy: 0.6130 - val_loss: 1.1001\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 18ms/step - accuracy: 0.5790 - loss: 1.1955 - val_accuracy: 0.6336 - val_loss: 1.0751\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - accuracy: 0.5939 - loss: 1.1558 - val_accuracy: 0.6419 - val_loss: 1.0334\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - accuracy: 0.6083 - loss: 1.1218 - val_accuracy: 0.6490 - val_loss: 1.0005\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6592 - loss: 0.9863\n",
      "Epoch 1/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - accuracy: 0.2159 - loss: 2.0813 - val_accuracy: 0.4306 - val_loss: 1.5836\n",
      "Epoch 2/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 20ms/step - accuracy: 0.3848 - loss: 1.6680 - val_accuracy: 0.4896 - val_loss: 1.4145\n",
      "Epoch 3/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 17ms/step - accuracy: 0.4464 - loss: 1.5132 - val_accuracy: 0.5336 - val_loss: 1.3255\n",
      "Epoch 4/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.4870 - loss: 1.4238 - val_accuracy: 0.5593 - val_loss: 1.2445\n",
      "Epoch 5/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.5181 - loss: 1.3542 - val_accuracy: 0.5684 - val_loss: 1.2006\n",
      "Epoch 6/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - accuracy: 0.5400 - loss: 1.3017 - val_accuracy: 0.5879 - val_loss: 1.1504\n",
      "Epoch 7/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.5629 - loss: 1.2437 - val_accuracy: 0.5976 - val_loss: 1.1306\n",
      "Epoch 8/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 17ms/step - accuracy: 0.5763 - loss: 1.2054 - val_accuracy: 0.6234 - val_loss: 1.0577\n",
      "Epoch 9/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - accuracy: 0.5927 - loss: 1.1532 - val_accuracy: 0.6340 - val_loss: 1.0314\n",
      "Epoch 10/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - accuracy: 0.6018 - loss: 1.1390 - val_accuracy: 0.6405 - val_loss: 1.0084\n",
      "Epoch 11/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.6106 - loss: 1.1111 - val_accuracy: 0.6437 - val_loss: 0.9904\n",
      "Epoch 12/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.6296 - loss: 1.0582 - val_accuracy: 0.6546 - val_loss: 0.9667\n",
      "Epoch 13/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.6356 - loss: 1.0537 - val_accuracy: 0.6619 - val_loss: 0.9557\n",
      "Epoch 14/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 19ms/step - accuracy: 0.6405 - loss: 1.0247 - val_accuracy: 0.6710 - val_loss: 0.9158\n",
      "Epoch 15/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.6533 - loss: 1.0018 - val_accuracy: 0.6754 - val_loss: 0.9086\n",
      "Epoch 16/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.6597 - loss: 0.9789 - val_accuracy: 0.6758 - val_loss: 0.9104\n",
      "Epoch 17/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.6648 - loss: 0.9653 - val_accuracy: 0.6872 - val_loss: 0.8799\n",
      "Epoch 18/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.6710 - loss: 0.9409 - val_accuracy: 0.6920 - val_loss: 0.8745\n",
      "Epoch 19/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.6809 - loss: 0.9228 - val_accuracy: 0.6928 - val_loss: 0.8521\n",
      "Epoch 20/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.6853 - loss: 0.9033 - val_accuracy: 0.6940 - val_loss: 0.8431\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6993 - loss: 0.8277\n",
      "Epoch 1/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - accuracy: 0.2249 - loss: 2.0810 - val_accuracy: 0.4426 - val_loss: 1.5832\n",
      "Epoch 2/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.3947 - loss: 1.6591 - val_accuracy: 0.5014 - val_loss: 1.4116\n",
      "Epoch 3/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.4527 - loss: 1.5180 - val_accuracy: 0.5235 - val_loss: 1.3225\n",
      "Epoch 4/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.4929 - loss: 1.4258 - val_accuracy: 0.5580 - val_loss: 1.2489\n",
      "Epoch 5/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.5184 - loss: 1.3636 - val_accuracy: 0.5716 - val_loss: 1.2081\n",
      "Epoch 6/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.5379 - loss: 1.3045 - val_accuracy: 0.5921 - val_loss: 1.1555\n",
      "Epoch 7/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.5634 - loss: 1.2458 - val_accuracy: 0.6064 - val_loss: 1.1263\n",
      "Epoch 8/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.5798 - loss: 1.1985 - val_accuracy: 0.6322 - val_loss: 1.0506\n",
      "Epoch 9/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.5926 - loss: 1.1579 - val_accuracy: 0.6342 - val_loss: 1.0319\n",
      "Epoch 10/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.6115 - loss: 1.1140 - val_accuracy: 0.6372 - val_loss: 1.0223\n",
      "Epoch 11/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.6247 - loss: 1.0766 - val_accuracy: 0.6576 - val_loss: 0.9743\n",
      "Epoch 12/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.6344 - loss: 1.0462 - val_accuracy: 0.6706 - val_loss: 0.9426\n",
      "Epoch 13/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.6350 - loss: 1.0387 - val_accuracy: 0.6771 - val_loss: 0.9252\n",
      "Epoch 14/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.6490 - loss: 1.0031 - val_accuracy: 0.6700 - val_loss: 0.9207\n",
      "Epoch 15/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.6584 - loss: 0.9862 - val_accuracy: 0.6871 - val_loss: 0.8911\n",
      "Epoch 16/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.6700 - loss: 0.9485 - val_accuracy: 0.6929 - val_loss: 0.8681\n",
      "Epoch 17/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.6755 - loss: 0.9338 - val_accuracy: 0.7048 - val_loss: 0.8593\n",
      "Epoch 18/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.6807 - loss: 0.9160 - val_accuracy: 0.7066 - val_loss: 0.8430\n",
      "Epoch 19/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.6916 - loss: 0.8885 - val_accuracy: 0.7130 - val_loss: 0.8266\n",
      "Epoch 20/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.6911 - loss: 0.8770 - val_accuracy: 0.7160 - val_loss: 0.8146\n",
      "Epoch 21/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.6997 - loss: 0.8591 - val_accuracy: 0.7181 - val_loss: 0.8091\n",
      "Epoch 22/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.7045 - loss: 0.8438 - val_accuracy: 0.7160 - val_loss: 0.8164\n",
      "Epoch 23/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.7092 - loss: 0.8301 - val_accuracy: 0.7181 - val_loss: 0.8029\n",
      "Epoch 24/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.7175 - loss: 0.8142 - val_accuracy: 0.7295 - val_loss: 0.7812\n",
      "Epoch 25/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7221 - loss: 0.8038 - val_accuracy: 0.7338 - val_loss: 0.7631\n",
      "Epoch 26/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7257 - loss: 0.7946 - val_accuracy: 0.7260 - val_loss: 0.7872\n",
      "Epoch 27/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7324 - loss: 0.7720 - val_accuracy: 0.7384 - val_loss: 0.7515\n",
      "Epoch 28/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7336 - loss: 0.7651 - val_accuracy: 0.7358 - val_loss: 0.7568\n",
      "Epoch 29/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7374 - loss: 0.7491 - val_accuracy: 0.7425 - val_loss: 0.7423\n",
      "Epoch 30/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7450 - loss: 0.7365 - val_accuracy: 0.7390 - val_loss: 0.7521\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7497 - loss: 0.7370\n",
      "Epoch 1/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.2154 - loss: 2.1040 - val_accuracy: 0.4195 - val_loss: 1.6485\n",
      "Epoch 2/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.3668 - loss: 1.7318 - val_accuracy: 0.4769 - val_loss: 1.4811\n",
      "Epoch 3/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.4237 - loss: 1.5860 - val_accuracy: 0.5105 - val_loss: 1.3794\n",
      "Epoch 4/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.4591 - loss: 1.4981 - val_accuracy: 0.5334 - val_loss: 1.3374\n",
      "Epoch 5/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.4890 - loss: 1.4234 - val_accuracy: 0.5625 - val_loss: 1.2260\n",
      "Epoch 6/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.5150 - loss: 1.3563 - val_accuracy: 0.5819 - val_loss: 1.1752\n",
      "Epoch 7/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 19ms/step - accuracy: 0.5398 - loss: 1.2944 - val_accuracy: 0.5925 - val_loss: 1.1595\n",
      "Epoch 8/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.5601 - loss: 1.2464 - val_accuracy: 0.6133 - val_loss: 1.0935\n",
      "Epoch 9/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.5743 - loss: 1.2142 - val_accuracy: 0.6180 - val_loss: 1.0672\n",
      "Epoch 10/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.5899 - loss: 1.1669 - val_accuracy: 0.6370 - val_loss: 1.0299\n",
      "Epoch 11/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.6059 - loss: 1.1329 - val_accuracy: 0.6428 - val_loss: 1.0098\n",
      "Epoch 12/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.6160 - loss: 1.0987 - val_accuracy: 0.6581 - val_loss: 0.9837\n",
      "Epoch 13/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - accuracy: 0.6222 - loss: 1.0700 - val_accuracy: 0.6695 - val_loss: 0.9497\n",
      "Epoch 14/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - accuracy: 0.6371 - loss: 1.0463 - val_accuracy: 0.6735 - val_loss: 0.9401\n",
      "Epoch 15/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.6450 - loss: 1.0221 - val_accuracy: 0.6810 - val_loss: 0.9075\n",
      "Epoch 16/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.6560 - loss: 0.9797 - val_accuracy: 0.6885 - val_loss: 0.8855\n",
      "Epoch 17/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.6657 - loss: 0.9675 - val_accuracy: 0.6970 - val_loss: 0.8753\n",
      "Epoch 18/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.6690 - loss: 0.9455 - val_accuracy: 0.6951 - val_loss: 0.8750\n",
      "Epoch 19/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.6716 - loss: 0.9338 - val_accuracy: 0.6977 - val_loss: 0.8647\n",
      "Epoch 20/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.6856 - loss: 0.9077 - val_accuracy: 0.7043 - val_loss: 0.8434\n",
      "Epoch 21/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.6925 - loss: 0.8905 - val_accuracy: 0.7100 - val_loss: 0.8328\n",
      "Epoch 22/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.6885 - loss: 0.8807 - val_accuracy: 0.7056 - val_loss: 0.8416\n",
      "Epoch 23/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.6985 - loss: 0.8655 - val_accuracy: 0.7199 - val_loss: 0.8050\n",
      "Epoch 24/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7083 - loss: 0.8439 - val_accuracy: 0.7216 - val_loss: 0.8020\n",
      "Epoch 25/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7104 - loss: 0.8314 - val_accuracy: 0.7280 - val_loss: 0.7833\n",
      "Epoch 26/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7191 - loss: 0.8081 - val_accuracy: 0.7248 - val_loss: 0.7917\n",
      "Epoch 27/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7262 - loss: 0.8002 - val_accuracy: 0.7296 - val_loss: 0.7865\n",
      "Epoch 28/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7240 - loss: 0.7956 - val_accuracy: 0.7309 - val_loss: 0.7744\n",
      "Epoch 29/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.7327 - loss: 0.7764 - val_accuracy: 0.7305 - val_loss: 0.7843\n",
      "Epoch 30/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7342 - loss: 0.7696 - val_accuracy: 0.7340 - val_loss: 0.7719\n",
      "Epoch 31/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7385 - loss: 0.7483 - val_accuracy: 0.7392 - val_loss: 0.7532\n",
      "Epoch 32/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7435 - loss: 0.7358 - val_accuracy: 0.7416 - val_loss: 0.7500\n",
      "Epoch 33/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7458 - loss: 0.7334 - val_accuracy: 0.7379 - val_loss: 0.7484\n",
      "Epoch 34/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7486 - loss: 0.7208 - val_accuracy: 0.7443 - val_loss: 0.7362\n",
      "Epoch 35/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.7551 - loss: 0.7032 - val_accuracy: 0.7382 - val_loss: 0.7618\n",
      "Epoch 36/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7568 - loss: 0.6991 - val_accuracy: 0.7466 - val_loss: 0.7511\n",
      "Epoch 37/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.7577 - loss: 0.6914 - val_accuracy: 0.7513 - val_loss: 0.7320\n",
      "Epoch 38/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - accuracy: 0.7594 - loss: 0.6851 - val_accuracy: 0.7389 - val_loss: 0.7663\n",
      "Epoch 39/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7660 - loss: 0.6685 - val_accuracy: 0.7512 - val_loss: 0.7252\n",
      "Epoch 40/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7709 - loss: 0.6580 - val_accuracy: 0.7442 - val_loss: 0.7428\n",
      "Epoch 41/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7739 - loss: 0.6484 - val_accuracy: 0.7545 - val_loss: 0.7213\n",
      "Epoch 42/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7766 - loss: 0.6437 - val_accuracy: 0.7518 - val_loss: 0.7406\n",
      "Epoch 43/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7773 - loss: 0.6331 - val_accuracy: 0.7547 - val_loss: 0.7213\n",
      "Epoch 44/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7809 - loss: 0.6276 - val_accuracy: 0.7503 - val_loss: 0.7339\n",
      "Epoch 45/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7828 - loss: 0.6160 - val_accuracy: 0.7546 - val_loss: 0.7244\n",
      "Epoch 46/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7851 - loss: 0.6062 - val_accuracy: 0.7575 - val_loss: 0.7164\n",
      "Epoch 47/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7925 - loss: 0.5941 - val_accuracy: 0.7588 - val_loss: 0.7232\n",
      "Epoch 48/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7930 - loss: 0.5912 - val_accuracy: 0.7538 - val_loss: 0.7400\n",
      "Epoch 49/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7965 - loss: 0.5896 - val_accuracy: 0.7509 - val_loss: 0.7459\n",
      "Epoch 50/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7994 - loss: 0.5748 - val_accuracy: 0.7616 - val_loss: 0.7089\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7691 - loss: 0.6942\n",
      "Epoch 1/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 33ms/step - accuracy: 0.1940 - loss: 2.1602 - val_accuracy: 0.3848 - val_loss: 1.7100\n",
      "Epoch 2/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 32ms/step - accuracy: 0.3565 - loss: 1.7585 - val_accuracy: 0.4806 - val_loss: 1.4823\n",
      "Epoch 3/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 32ms/step - accuracy: 0.4244 - loss: 1.5891 - val_accuracy: 0.5084 - val_loss: 1.3935\n",
      "Epoch 4/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 32ms/step - accuracy: 0.4581 - loss: 1.4975 - val_accuracy: 0.5312 - val_loss: 1.3166\n",
      "Epoch 5/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 32ms/step - accuracy: 0.4873 - loss: 1.4279 - val_accuracy: 0.5573 - val_loss: 1.2482\n",
      "Epoch 6/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 32ms/step - accuracy: 0.5096 - loss: 1.3732 - val_accuracy: 0.5657 - val_loss: 1.2242\n",
      "Epoch 7/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 33ms/step - accuracy: 0.5317 - loss: 1.3225 - val_accuracy: 0.5884 - val_loss: 1.1716\n",
      "Epoch 8/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 32ms/step - accuracy: 0.5441 - loss: 1.2835 - val_accuracy: 0.6004 - val_loss: 1.1374\n",
      "Epoch 9/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 32ms/step - accuracy: 0.5562 - loss: 1.2525 - val_accuracy: 0.6015 - val_loss: 1.1313\n",
      "Epoch 10/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 32ms/step - accuracy: 0.5712 - loss: 1.2194 - val_accuracy: 0.6207 - val_loss: 1.0944\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6226 - loss: 1.0879\n",
      "Epoch 1/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 36ms/step - accuracy: 0.1908 - loss: 2.1490 - val_accuracy: 0.4069 - val_loss: 1.6984\n",
      "Epoch 2/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 35ms/step - accuracy: 0.3538 - loss: 1.7627 - val_accuracy: 0.4625 - val_loss: 1.5163\n",
      "Epoch 3/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 35ms/step - accuracy: 0.4091 - loss: 1.6237 - val_accuracy: 0.5002 - val_loss: 1.4102\n",
      "Epoch 4/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.4482 - loss: 1.5335 - val_accuracy: 0.5208 - val_loss: 1.3586\n",
      "Epoch 5/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.4720 - loss: 1.4607 - val_accuracy: 0.5419 - val_loss: 1.2897\n",
      "Epoch 6/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.4932 - loss: 1.4127 - val_accuracy: 0.5552 - val_loss: 1.2550\n",
      "Epoch 7/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.5138 - loss: 1.3636 - val_accuracy: 0.5711 - val_loss: 1.2082\n",
      "Epoch 8/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 37ms/step - accuracy: 0.5268 - loss: 1.3287 - val_accuracy: 0.5724 - val_loss: 1.1954\n",
      "Epoch 9/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.5421 - loss: 1.2813 - val_accuracy: 0.5888 - val_loss: 1.1643\n",
      "Epoch 10/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 35ms/step - accuracy: 0.5565 - loss: 1.2586 - val_accuracy: 0.5876 - val_loss: 1.1565\n",
      "Epoch 11/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.5698 - loss: 1.2213 - val_accuracy: 0.6125 - val_loss: 1.0981\n",
      "Epoch 12/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.5747 - loss: 1.2078 - val_accuracy: 0.6200 - val_loss: 1.0675\n",
      "Epoch 13/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.5921 - loss: 1.1534 - val_accuracy: 0.6206 - val_loss: 1.0773\n",
      "Epoch 14/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.5963 - loss: 1.1341 - val_accuracy: 0.6336 - val_loss: 1.0338\n",
      "Epoch 15/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.6015 - loss: 1.1258 - val_accuracy: 0.6433 - val_loss: 1.0162\n",
      "Epoch 16/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.6226 - loss: 1.0803 - val_accuracy: 0.6534 - val_loss: 0.9840\n",
      "Epoch 17/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 35ms/step - accuracy: 0.6266 - loss: 1.0647 - val_accuracy: 0.6644 - val_loss: 0.9692\n",
      "Epoch 18/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.6324 - loss: 1.0488 - val_accuracy: 0.6689 - val_loss: 0.9515\n",
      "Epoch 19/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.6365 - loss: 1.0374 - val_accuracy: 0.6668 - val_loss: 0.9560\n",
      "Epoch 20/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.6449 - loss: 1.0117 - val_accuracy: 0.6818 - val_loss: 0.9274\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6837 - loss: 0.9182\n",
      "Epoch 1/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 37ms/step - accuracy: 0.1912 - loss: 2.1521 - val_accuracy: 0.3992 - val_loss: 1.7015\n",
      "Epoch 2/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 35ms/step - accuracy: 0.3513 - loss: 1.7740 - val_accuracy: 0.4599 - val_loss: 1.5149\n",
      "Epoch 3/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 35ms/step - accuracy: 0.4097 - loss: 1.6213 - val_accuracy: 0.4722 - val_loss: 1.4409\n",
      "Epoch 4/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.4476 - loss: 1.5319 - val_accuracy: 0.5190 - val_loss: 1.3435\n",
      "Epoch 5/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.4705 - loss: 1.4730 - val_accuracy: 0.5348 - val_loss: 1.2903\n",
      "Epoch 6/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 35ms/step - accuracy: 0.4875 - loss: 1.4226 - val_accuracy: 0.5534 - val_loss: 1.2659\n",
      "Epoch 7/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 35ms/step - accuracy: 0.5160 - loss: 1.3701 - val_accuracy: 0.5645 - val_loss: 1.2352\n",
      "Epoch 8/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 35ms/step - accuracy: 0.5219 - loss: 1.3439 - val_accuracy: 0.5816 - val_loss: 1.1728\n",
      "Epoch 9/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 35ms/step - accuracy: 0.5413 - loss: 1.2985 - val_accuracy: 0.5904 - val_loss: 1.1654\n",
      "Epoch 10/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 35ms/step - accuracy: 0.5516 - loss: 1.2618 - val_accuracy: 0.6020 - val_loss: 1.1184\n",
      "Epoch 11/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.5682 - loss: 1.2309 - val_accuracy: 0.6174 - val_loss: 1.0961\n",
      "Epoch 12/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 35ms/step - accuracy: 0.5778 - loss: 1.2006 - val_accuracy: 0.6218 - val_loss: 1.0687\n",
      "Epoch 13/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 35ms/step - accuracy: 0.5849 - loss: 1.1782 - val_accuracy: 0.6235 - val_loss: 1.0619\n",
      "Epoch 14/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.5963 - loss: 1.1562 - val_accuracy: 0.6359 - val_loss: 1.0368\n",
      "Epoch 15/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.6003 - loss: 1.1402 - val_accuracy: 0.6465 - val_loss: 1.0105\n",
      "Epoch 16/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.6092 - loss: 1.1139 - val_accuracy: 0.6466 - val_loss: 0.9977\n",
      "Epoch 17/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.6162 - loss: 1.0973 - val_accuracy: 0.6574 - val_loss: 0.9805\n",
      "Epoch 18/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 35ms/step - accuracy: 0.6266 - loss: 1.0664 - val_accuracy: 0.6653 - val_loss: 0.9583\n",
      "Epoch 19/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 35ms/step - accuracy: 0.6317 - loss: 1.0593 - val_accuracy: 0.6684 - val_loss: 0.9450\n",
      "Epoch 20/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.6368 - loss: 1.0373 - val_accuracy: 0.6676 - val_loss: 0.9456\n",
      "Epoch 21/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.6443 - loss: 1.0270 - val_accuracy: 0.6700 - val_loss: 0.9518\n",
      "Epoch 22/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.6514 - loss: 0.9996 - val_accuracy: 0.6886 - val_loss: 0.9127\n",
      "Epoch 23/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.6511 - loss: 0.9887 - val_accuracy: 0.6888 - val_loss: 0.8932\n",
      "Epoch 24/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.6660 - loss: 0.9604 - val_accuracy: 0.6818 - val_loss: 0.9120\n",
      "Epoch 25/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 35ms/step - accuracy: 0.6637 - loss: 0.9608 - val_accuracy: 0.6962 - val_loss: 0.8733\n",
      "Epoch 26/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.6729 - loss: 0.9366 - val_accuracy: 0.6978 - val_loss: 0.8773\n",
      "Epoch 27/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 35ms/step - accuracy: 0.6824 - loss: 0.9163 - val_accuracy: 0.7068 - val_loss: 0.8486\n",
      "Epoch 28/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 35ms/step - accuracy: 0.6855 - loss: 0.9001 - val_accuracy: 0.7069 - val_loss: 0.8427\n",
      "Epoch 29/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.6873 - loss: 0.8983 - val_accuracy: 0.7098 - val_loss: 0.8316\n",
      "Epoch 30/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.6919 - loss: 0.8891 - val_accuracy: 0.7111 - val_loss: 0.8377\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7155 - loss: 0.8220\n",
      "Epoch 1/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 36ms/step - accuracy: 0.2049 - loss: 2.1195 - val_accuracy: 0.4109 - val_loss: 1.6411\n",
      "Epoch 2/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.3675 - loss: 1.7221 - val_accuracy: 0.4657 - val_loss: 1.5102\n",
      "Epoch 3/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.4190 - loss: 1.5991 - val_accuracy: 0.4997 - val_loss: 1.4033\n",
      "Epoch 4/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 34ms/step - accuracy: 0.4523 - loss: 1.5082 - val_accuracy: 0.5201 - val_loss: 1.3430\n",
      "Epoch 5/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 34ms/step - accuracy: 0.4783 - loss: 1.4519 - val_accuracy: 0.5281 - val_loss: 1.2963\n",
      "Epoch 6/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 34ms/step - accuracy: 0.5034 - loss: 1.3937 - val_accuracy: 0.5566 - val_loss: 1.2430\n",
      "Epoch 7/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 35ms/step - accuracy: 0.5150 - loss: 1.3418 - val_accuracy: 0.5806 - val_loss: 1.1998\n",
      "Epoch 8/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.5346 - loss: 1.3018 - val_accuracy: 0.5824 - val_loss: 1.1802\n",
      "Epoch 9/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 38ms/step - accuracy: 0.5499 - loss: 1.2652 - val_accuracy: 0.5944 - val_loss: 1.1533\n",
      "Epoch 10/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.5620 - loss: 1.2348 - val_accuracy: 0.6069 - val_loss: 1.1078\n",
      "Epoch 11/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.5829 - loss: 1.1886 - val_accuracy: 0.6196 - val_loss: 1.0721\n",
      "Epoch 12/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.5908 - loss: 1.1697 - val_accuracy: 0.6318 - val_loss: 1.0592\n",
      "Epoch 13/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.5958 - loss: 1.1506 - val_accuracy: 0.6364 - val_loss: 1.0375\n",
      "Epoch 14/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.6099 - loss: 1.1186 - val_accuracy: 0.6342 - val_loss: 1.0312\n",
      "Epoch 15/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.6125 - loss: 1.1035 - val_accuracy: 0.6540 - val_loss: 0.9963\n",
      "Epoch 16/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.6239 - loss: 1.0801 - val_accuracy: 0.6512 - val_loss: 0.9804\n",
      "Epoch 17/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.6326 - loss: 1.0546 - val_accuracy: 0.6615 - val_loss: 0.9617\n",
      "Epoch 18/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.6338 - loss: 1.0436 - val_accuracy: 0.6618 - val_loss: 0.9593\n",
      "Epoch 19/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 35ms/step - accuracy: 0.6412 - loss: 1.0152 - val_accuracy: 0.6758 - val_loss: 0.9196\n",
      "Epoch 20/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.6485 - loss: 1.0077 - val_accuracy: 0.6850 - val_loss: 0.9007\n",
      "Epoch 21/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.6547 - loss: 0.9852 - val_accuracy: 0.6751 - val_loss: 0.9182\n",
      "Epoch 22/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.6679 - loss: 0.9505 - val_accuracy: 0.6927 - val_loss: 0.8792\n",
      "Epoch 23/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.6716 - loss: 0.9400 - val_accuracy: 0.6912 - val_loss: 0.8734\n",
      "Epoch 24/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.6758 - loss: 0.9324 - val_accuracy: 0.6965 - val_loss: 0.8713\n",
      "Epoch 25/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.6804 - loss: 0.9152 - val_accuracy: 0.6973 - val_loss: 0.8693\n",
      "Epoch 26/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.6837 - loss: 0.9115 - val_accuracy: 0.7038 - val_loss: 0.8471\n",
      "Epoch 27/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.6855 - loss: 0.8964 - val_accuracy: 0.7135 - val_loss: 0.8200\n",
      "Epoch 28/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.6959 - loss: 0.8759 - val_accuracy: 0.7108 - val_loss: 0.8191\n",
      "Epoch 29/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.6970 - loss: 0.8675 - val_accuracy: 0.7003 - val_loss: 0.8461\n",
      "Epoch 30/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.7023 - loss: 0.8564 - val_accuracy: 0.7165 - val_loss: 0.8090\n",
      "Epoch 31/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.7083 - loss: 0.8399 - val_accuracy: 0.7185 - val_loss: 0.8083\n",
      "Epoch 32/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.7139 - loss: 0.8207 - val_accuracy: 0.7160 - val_loss: 0.8045\n",
      "Epoch 33/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.7173 - loss: 0.8141 - val_accuracy: 0.7264 - val_loss: 0.7852\n",
      "Epoch 34/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.7161 - loss: 0.8101 - val_accuracy: 0.7241 - val_loss: 0.7913\n",
      "Epoch 35/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.7188 - loss: 0.8021 - val_accuracy: 0.7306 - val_loss: 0.7753\n",
      "Epoch 36/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.7232 - loss: 0.7949 - val_accuracy: 0.7294 - val_loss: 0.7692\n",
      "Epoch 37/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.7260 - loss: 0.7794 - val_accuracy: 0.7329 - val_loss: 0.7670\n",
      "Epoch 38/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.7334 - loss: 0.7635 - val_accuracy: 0.7299 - val_loss: 0.7828\n",
      "Epoch 39/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.7369 - loss: 0.7612 - val_accuracy: 0.7363 - val_loss: 0.7580\n",
      "Epoch 40/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.7324 - loss: 0.7566 - val_accuracy: 0.7376 - val_loss: 0.7480\n",
      "Epoch 41/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.7388 - loss: 0.7511 - val_accuracy: 0.7380 - val_loss: 0.7405\n",
      "Epoch 42/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.7431 - loss: 0.7385 - val_accuracy: 0.7379 - val_loss: 0.7519\n",
      "Epoch 43/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.7445 - loss: 0.7303 - val_accuracy: 0.7444 - val_loss: 0.7320\n",
      "Epoch 44/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 37ms/step - accuracy: 0.7501 - loss: 0.7191 - val_accuracy: 0.7452 - val_loss: 0.7492\n",
      "Epoch 45/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.7498 - loss: 0.7164 - val_accuracy: 0.7417 - val_loss: 0.7361\n",
      "Epoch 46/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.7575 - loss: 0.7037 - val_accuracy: 0.7395 - val_loss: 0.7443\n",
      "Epoch 47/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.7595 - loss: 0.6929 - val_accuracy: 0.7399 - val_loss: 0.7540\n",
      "Epoch 48/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.7562 - loss: 0.6964 - val_accuracy: 0.7438 - val_loss: 0.7325\n",
      "Epoch 49/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.7602 - loss: 0.6859 - val_accuracy: 0.7516 - val_loss: 0.7225\n",
      "Epoch 50/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 37ms/step - accuracy: 0.7607 - loss: 0.6849 - val_accuracy: 0.7501 - val_loss: 0.7236\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7558 - loss: 0.7077\n",
      "Epoch 1/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 72ms/step - accuracy: 0.1683 - loss: 2.2039 - val_accuracy: 0.3475 - val_loss: 1.8176\n",
      "Epoch 2/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 72ms/step - accuracy: 0.3075 - loss: 1.8631 - val_accuracy: 0.4284 - val_loss: 1.6156\n",
      "Epoch 3/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.3660 - loss: 1.7193 - val_accuracy: 0.4678 - val_loss: 1.5089\n",
      "Epoch 4/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 74ms/step - accuracy: 0.3980 - loss: 1.6328 - val_accuracy: 0.4903 - val_loss: 1.4541\n",
      "Epoch 5/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 72ms/step - accuracy: 0.4332 - loss: 1.5587 - val_accuracy: 0.5133 - val_loss: 1.3805\n",
      "Epoch 6/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 66ms/step - accuracy: 0.4526 - loss: 1.5058 - val_accuracy: 0.5286 - val_loss: 1.3309\n",
      "Epoch 7/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 65ms/step - accuracy: 0.4739 - loss: 1.4629 - val_accuracy: 0.5380 - val_loss: 1.3090\n",
      "Epoch 8/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 65ms/step - accuracy: 0.4848 - loss: 1.4321 - val_accuracy: 0.5430 - val_loss: 1.2921\n",
      "Epoch 9/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 66ms/step - accuracy: 0.5001 - loss: 1.3909 - val_accuracy: 0.5559 - val_loss: 1.2565\n",
      "Epoch 10/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 66ms/step - accuracy: 0.5175 - loss: 1.3579 - val_accuracy: 0.5649 - val_loss: 1.2374\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5710 - loss: 1.2373\n",
      "Epoch 1/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 65ms/step - accuracy: 0.1712 - loss: 2.2095 - val_accuracy: 0.3640 - val_loss: 1.8039\n",
      "Epoch 2/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 66ms/step - accuracy: 0.3209 - loss: 1.8599 - val_accuracy: 0.4207 - val_loss: 1.6235\n",
      "Epoch 3/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 65ms/step - accuracy: 0.3794 - loss: 1.7085 - val_accuracy: 0.4780 - val_loss: 1.4818\n",
      "Epoch 4/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 66ms/step - accuracy: 0.4267 - loss: 1.5928 - val_accuracy: 0.4879 - val_loss: 1.4264\n",
      "Epoch 5/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 66ms/step - accuracy: 0.4521 - loss: 1.5252 - val_accuracy: 0.5204 - val_loss: 1.3636\n",
      "Epoch 6/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 67ms/step - accuracy: 0.4697 - loss: 1.4649 - val_accuracy: 0.5360 - val_loss: 1.3085\n",
      "Epoch 7/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 66ms/step - accuracy: 0.4880 - loss: 1.4283 - val_accuracy: 0.5453 - val_loss: 1.2736\n",
      "Epoch 8/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 66ms/step - accuracy: 0.4999 - loss: 1.3926 - val_accuracy: 0.5602 - val_loss: 1.2388\n",
      "Epoch 9/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 65ms/step - accuracy: 0.5177 - loss: 1.3486 - val_accuracy: 0.5579 - val_loss: 1.2399\n",
      "Epoch 10/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 73ms/step - accuracy: 0.5244 - loss: 1.3322 - val_accuracy: 0.5785 - val_loss: 1.1844\n",
      "Epoch 11/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 75ms/step - accuracy: 0.5363 - loss: 1.3036 - val_accuracy: 0.5948 - val_loss: 1.1583\n",
      "Epoch 12/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.5494 - loss: 1.2725 - val_accuracy: 0.6002 - val_loss: 1.1396\n",
      "Epoch 13/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.5610 - loss: 1.2421 - val_accuracy: 0.6102 - val_loss: 1.1219\n",
      "Epoch 14/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.5675 - loss: 1.2194 - val_accuracy: 0.6181 - val_loss: 1.0914\n",
      "Epoch 15/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.5750 - loss: 1.1956 - val_accuracy: 0.6245 - val_loss: 1.0768\n",
      "Epoch 16/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.5852 - loss: 1.1872 - val_accuracy: 0.6216 - val_loss: 1.0747\n",
      "Epoch 17/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.5946 - loss: 1.1566 - val_accuracy: 0.6300 - val_loss: 1.0550\n",
      "Epoch 18/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.5952 - loss: 1.1500 - val_accuracy: 0.6327 - val_loss: 1.0328\n",
      "Epoch 19/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.6044 - loss: 1.1291 - val_accuracy: 0.6331 - val_loss: 1.0406\n",
      "Epoch 20/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.6037 - loss: 1.1285 - val_accuracy: 0.6375 - val_loss: 1.0309\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6355 - loss: 1.0267\n",
      "Epoch 1/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 71ms/step - accuracy: 0.1757 - loss: 2.1941 - val_accuracy: 0.3765 - val_loss: 1.7828\n",
      "Epoch 2/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 70ms/step - accuracy: 0.3367 - loss: 1.8177 - val_accuracy: 0.4433 - val_loss: 1.5655\n",
      "Epoch 3/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.3927 - loss: 1.6579 - val_accuracy: 0.4807 - val_loss: 1.4596\n",
      "Epoch 4/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.4341 - loss: 1.5719 - val_accuracy: 0.5045 - val_loss: 1.3988\n",
      "Epoch 5/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 70ms/step - accuracy: 0.4617 - loss: 1.4926 - val_accuracy: 0.5236 - val_loss: 1.3558\n",
      "Epoch 6/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.4765 - loss: 1.4614 - val_accuracy: 0.5409 - val_loss: 1.2994\n",
      "Epoch 7/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 73ms/step - accuracy: 0.4939 - loss: 1.4175 - val_accuracy: 0.5522 - val_loss: 1.2708\n",
      "Epoch 8/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 73ms/step - accuracy: 0.5090 - loss: 1.3745 - val_accuracy: 0.5601 - val_loss: 1.2373\n",
      "Epoch 9/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 69ms/step - accuracy: 0.5229 - loss: 1.3450 - val_accuracy: 0.5752 - val_loss: 1.2083\n",
      "Epoch 10/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.5340 - loss: 1.3208 - val_accuracy: 0.5822 - val_loss: 1.1765\n",
      "Epoch 11/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 78ms/step - accuracy: 0.5432 - loss: 1.2896 - val_accuracy: 0.5834 - val_loss: 1.1730\n",
      "Epoch 12/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 73ms/step - accuracy: 0.5526 - loss: 1.2671 - val_accuracy: 0.5926 - val_loss: 1.1532\n",
      "Epoch 13/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.5587 - loss: 1.2439 - val_accuracy: 0.5995 - val_loss: 1.1296\n",
      "Epoch 14/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 74ms/step - accuracy: 0.5686 - loss: 1.2258 - val_accuracy: 0.6123 - val_loss: 1.1020\n",
      "Epoch 15/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 74ms/step - accuracy: 0.5778 - loss: 1.1964 - val_accuracy: 0.6104 - val_loss: 1.1048\n",
      "Epoch 16/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 72ms/step - accuracy: 0.5876 - loss: 1.1768 - val_accuracy: 0.6208 - val_loss: 1.0705\n",
      "Epoch 17/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 72ms/step - accuracy: 0.5941 - loss: 1.1568 - val_accuracy: 0.6285 - val_loss: 1.0555\n",
      "Epoch 18/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 78ms/step - accuracy: 0.5998 - loss: 1.1520 - val_accuracy: 0.6294 - val_loss: 1.0454\n",
      "Epoch 19/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 70ms/step - accuracy: 0.5999 - loss: 1.1258 - val_accuracy: 0.6333 - val_loss: 1.0236\n",
      "Epoch 20/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 73ms/step - accuracy: 0.6086 - loss: 1.1166 - val_accuracy: 0.6354 - val_loss: 1.0268\n",
      "Epoch 21/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.6111 - loss: 1.1053 - val_accuracy: 0.6429 - val_loss: 0.9996\n",
      "Epoch 22/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 74ms/step - accuracy: 0.6226 - loss: 1.0837 - val_accuracy: 0.6386 - val_loss: 1.0208\n",
      "Epoch 23/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 73ms/step - accuracy: 0.6258 - loss: 1.0689 - val_accuracy: 0.6496 - val_loss: 0.9869\n",
      "Epoch 24/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 69ms/step - accuracy: 0.6282 - loss: 1.0597 - val_accuracy: 0.6561 - val_loss: 0.9616\n",
      "Epoch 25/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 74ms/step - accuracy: 0.6340 - loss: 1.0444 - val_accuracy: 0.6513 - val_loss: 0.9753\n",
      "Epoch 26/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 75ms/step - accuracy: 0.6357 - loss: 1.0380 - val_accuracy: 0.6644 - val_loss: 0.9418\n",
      "Epoch 27/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 73ms/step - accuracy: 0.6439 - loss: 1.0177 - val_accuracy: 0.6645 - val_loss: 0.9475\n",
      "Epoch 28/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 72ms/step - accuracy: 0.6469 - loss: 1.0170 - val_accuracy: 0.6702 - val_loss: 0.9287\n",
      "Epoch 29/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 72ms/step - accuracy: 0.6485 - loss: 0.9981 - val_accuracy: 0.6682 - val_loss: 0.9341\n",
      "Epoch 30/30\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 72ms/step - accuracy: 0.6506 - loss: 0.9906 - val_accuracy: 0.6753 - val_loss: 0.9157\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6851 - loss: 0.9046\n",
      "Epoch 1/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 72ms/step - accuracy: 0.1595 - loss: 2.2262 - val_accuracy: 0.3489 - val_loss: 1.8441\n",
      "Epoch 2/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 65ms/step - accuracy: 0.3119 - loss: 1.8837 - val_accuracy: 0.4379 - val_loss: 1.6159\n",
      "Epoch 3/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 66ms/step - accuracy: 0.3796 - loss: 1.7107 - val_accuracy: 0.4750 - val_loss: 1.4789\n",
      "Epoch 4/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 66ms/step - accuracy: 0.4185 - loss: 1.5989 - val_accuracy: 0.4899 - val_loss: 1.4174\n",
      "Epoch 5/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 66ms/step - accuracy: 0.4481 - loss: 1.5312 - val_accuracy: 0.5231 - val_loss: 1.3530\n",
      "Epoch 6/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 66ms/step - accuracy: 0.4602 - loss: 1.4933 - val_accuracy: 0.5214 - val_loss: 1.3241\n",
      "Epoch 7/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 65ms/step - accuracy: 0.4806 - loss: 1.4418 - val_accuracy: 0.5407 - val_loss: 1.2765\n",
      "Epoch 8/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 65ms/step - accuracy: 0.4990 - loss: 1.3959 - val_accuracy: 0.5517 - val_loss: 1.2530\n",
      "Epoch 9/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 65ms/step - accuracy: 0.5167 - loss: 1.3613 - val_accuracy: 0.5676 - val_loss: 1.2133\n",
      "Epoch 10/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 65ms/step - accuracy: 0.5211 - loss: 1.3256 - val_accuracy: 0.5825 - val_loss: 1.1866\n",
      "Epoch 11/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 65ms/step - accuracy: 0.5336 - loss: 1.3042 - val_accuracy: 0.5911 - val_loss: 1.1605\n",
      "Epoch 12/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 65ms/step - accuracy: 0.5460 - loss: 1.2803 - val_accuracy: 0.5951 - val_loss: 1.1401\n",
      "Epoch 13/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 65ms/step - accuracy: 0.5583 - loss: 1.2519 - val_accuracy: 0.6016 - val_loss: 1.1290\n",
      "Epoch 14/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 65ms/step - accuracy: 0.5652 - loss: 1.2295 - val_accuracy: 0.6053 - val_loss: 1.1374\n",
      "Epoch 15/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 65ms/step - accuracy: 0.5691 - loss: 1.2166 - val_accuracy: 0.6118 - val_loss: 1.0960\n",
      "Epoch 16/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.5816 - loss: 1.1912 - val_accuracy: 0.6274 - val_loss: 1.0632\n",
      "Epoch 17/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.5898 - loss: 1.1712 - val_accuracy: 0.6132 - val_loss: 1.0863\n",
      "Epoch 18/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.5900 - loss: 1.1589 - val_accuracy: 0.6239 - val_loss: 1.0642\n",
      "Epoch 19/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 70ms/step - accuracy: 0.5979 - loss: 1.1426 - val_accuracy: 0.6406 - val_loss: 1.0238\n",
      "Epoch 20/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.6078 - loss: 1.1184 - val_accuracy: 0.6444 - val_loss: 1.0124\n",
      "Epoch 21/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.6122 - loss: 1.1095 - val_accuracy: 0.6512 - val_loss: 0.9959\n",
      "Epoch 22/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.6168 - loss: 1.0914 - val_accuracy: 0.6543 - val_loss: 0.9808\n",
      "Epoch 23/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.6201 - loss: 1.0823 - val_accuracy: 0.6524 - val_loss: 0.9896\n",
      "Epoch 24/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.6289 - loss: 1.0619 - val_accuracy: 0.6619 - val_loss: 0.9619\n",
      "Epoch 25/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.6328 - loss: 1.0447 - val_accuracy: 0.6681 - val_loss: 0.9621\n",
      "Epoch 26/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.6293 - loss: 1.0464 - val_accuracy: 0.6680 - val_loss: 0.9487\n",
      "Epoch 27/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.6371 - loss: 1.0343 - val_accuracy: 0.6669 - val_loss: 0.9446\n",
      "Epoch 28/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.6405 - loss: 1.0269 - val_accuracy: 0.6735 - val_loss: 0.9274\n",
      "Epoch 29/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.6458 - loss: 1.0021 - val_accuracy: 0.6739 - val_loss: 0.9330\n",
      "Epoch 30/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 70ms/step - accuracy: 0.6469 - loss: 1.0042 - val_accuracy: 0.6828 - val_loss: 0.9034\n",
      "Epoch 31/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.6524 - loss: 0.9912 - val_accuracy: 0.6844 - val_loss: 0.8981\n",
      "Epoch 32/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 70ms/step - accuracy: 0.6564 - loss: 0.9802 - val_accuracy: 0.6831 - val_loss: 0.9012\n",
      "Epoch 33/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 70ms/step - accuracy: 0.6621 - loss: 0.9673 - val_accuracy: 0.6780 - val_loss: 0.9131\n",
      "Epoch 34/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.6635 - loss: 0.9604 - val_accuracy: 0.6888 - val_loss: 0.8814\n",
      "Epoch 35/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 70ms/step - accuracy: 0.6657 - loss: 0.9514 - val_accuracy: 0.6885 - val_loss: 0.8873\n",
      "Epoch 36/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.6694 - loss: 0.9399 - val_accuracy: 0.6950 - val_loss: 0.8746\n",
      "Epoch 37/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.6722 - loss: 0.9341 - val_accuracy: 0.6955 - val_loss: 0.8745\n",
      "Epoch 38/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.6786 - loss: 0.9284 - val_accuracy: 0.6879 - val_loss: 0.8838\n",
      "Epoch 39/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.6789 - loss: 0.9221 - val_accuracy: 0.7017 - val_loss: 0.8515\n",
      "Epoch 40/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.6832 - loss: 0.9072 - val_accuracy: 0.7001 - val_loss: 0.8541\n",
      "Epoch 41/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.6863 - loss: 0.9055 - val_accuracy: 0.6988 - val_loss: 0.8617\n",
      "Epoch 42/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.6887 - loss: 0.8965 - val_accuracy: 0.7058 - val_loss: 0.8335\n",
      "Epoch 43/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.6939 - loss: 0.8838 - val_accuracy: 0.7049 - val_loss: 0.8405\n",
      "Epoch 44/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.6970 - loss: 0.8698 - val_accuracy: 0.7113 - val_loss: 0.8228\n",
      "Epoch 45/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 70ms/step - accuracy: 0.7024 - loss: 0.8609 - val_accuracy: 0.7087 - val_loss: 0.8391\n",
      "Epoch 46/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.7006 - loss: 0.8603 - val_accuracy: 0.7129 - val_loss: 0.8173\n",
      "Epoch 47/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 70ms/step - accuracy: 0.7062 - loss: 0.8429 - val_accuracy: 0.7133 - val_loss: 0.8119\n",
      "Epoch 48/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.7029 - loss: 0.8501 - val_accuracy: 0.7167 - val_loss: 0.8075\n",
      "Epoch 49/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 70ms/step - accuracy: 0.7084 - loss: 0.8413 - val_accuracy: 0.7162 - val_loss: 0.8123\n",
      "Epoch 50/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 68ms/step - accuracy: 0.7065 - loss: 0.8430 - val_accuracy: 0.7112 - val_loss: 0.8170\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7133 - loss: 0.8110\n",
      "Epoch 1/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 130ms/step - accuracy: 0.1627 - loss: 2.2249 - val_accuracy: 0.3364 - val_loss: 1.8833\n",
      "Epoch 2/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 129ms/step - accuracy: 0.2904 - loss: 1.9158 - val_accuracy: 0.3949 - val_loss: 1.7043\n",
      "Epoch 3/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 132ms/step - accuracy: 0.3338 - loss: 1.7918 - val_accuracy: 0.4302 - val_loss: 1.6221\n",
      "Epoch 4/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 132ms/step - accuracy: 0.3722 - loss: 1.7030 - val_accuracy: 0.4580 - val_loss: 1.5245\n",
      "Epoch 5/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 132ms/step - accuracy: 0.4047 - loss: 1.6325 - val_accuracy: 0.4806 - val_loss: 1.4716\n",
      "Epoch 6/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 132ms/step - accuracy: 0.4274 - loss: 1.5819 - val_accuracy: 0.4990 - val_loss: 1.4327\n",
      "Epoch 7/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 132ms/step - accuracy: 0.4346 - loss: 1.5512 - val_accuracy: 0.5092 - val_loss: 1.3872\n",
      "Epoch 8/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 132ms/step - accuracy: 0.4527 - loss: 1.5103 - val_accuracy: 0.5161 - val_loss: 1.3626\n",
      "Epoch 9/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 132ms/step - accuracy: 0.4670 - loss: 1.4764 - val_accuracy: 0.5224 - val_loss: 1.3428\n",
      "Epoch 10/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 132ms/step - accuracy: 0.4766 - loss: 1.4551 - val_accuracy: 0.5301 - val_loss: 1.3499\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5348 - loss: 1.3451\n",
      "Epoch 1/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 134ms/step - accuracy: 0.1532 - loss: 2.2408 - val_accuracy: 0.3408 - val_loss: 1.9052\n",
      "Epoch 2/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 133ms/step - accuracy: 0.2873 - loss: 1.9400 - val_accuracy: 0.4009 - val_loss: 1.7169\n",
      "Epoch 3/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 132ms/step - accuracy: 0.3459 - loss: 1.7926 - val_accuracy: 0.4405 - val_loss: 1.5910\n",
      "Epoch 4/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 133ms/step - accuracy: 0.3840 - loss: 1.6923 - val_accuracy: 0.4640 - val_loss: 1.5175\n",
      "Epoch 5/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 132ms/step - accuracy: 0.4138 - loss: 1.6164 - val_accuracy: 0.4848 - val_loss: 1.4467\n",
      "Epoch 6/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 132ms/step - accuracy: 0.4364 - loss: 1.5630 - val_accuracy: 0.4994 - val_loss: 1.4057\n",
      "Epoch 7/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 132ms/step - accuracy: 0.4544 - loss: 1.5159 - val_accuracy: 0.5084 - val_loss: 1.3726\n",
      "Epoch 8/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 132ms/step - accuracy: 0.4627 - loss: 1.4871 - val_accuracy: 0.5264 - val_loss: 1.3383\n",
      "Epoch 9/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 132ms/step - accuracy: 0.4770 - loss: 1.4543 - val_accuracy: 0.5416 - val_loss: 1.3014\n",
      "Epoch 10/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 132ms/step - accuracy: 0.4900 - loss: 1.4221 - val_accuracy: 0.5476 - val_loss: 1.2805\n",
      "Epoch 11/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 132ms/step - accuracy: 0.5020 - loss: 1.3991 - val_accuracy: 0.5507 - val_loss: 1.2663\n",
      "Epoch 12/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 133ms/step - accuracy: 0.5113 - loss: 1.3725 - val_accuracy: 0.5632 - val_loss: 1.2372\n",
      "Epoch 13/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 133ms/step - accuracy: 0.5172 - loss: 1.3543 - val_accuracy: 0.5678 - val_loss: 1.2233\n",
      "Epoch 14/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 132ms/step - accuracy: 0.5272 - loss: 1.3343 - val_accuracy: 0.5694 - val_loss: 1.2080\n",
      "Epoch 15/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 132ms/step - accuracy: 0.5299 - loss: 1.3219 - val_accuracy: 0.5790 - val_loss: 1.1866\n",
      "Epoch 16/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 133ms/step - accuracy: 0.5399 - loss: 1.3051 - val_accuracy: 0.5816 - val_loss: 1.1872\n",
      "Epoch 17/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 132ms/step - accuracy: 0.5426 - loss: 1.2897 - val_accuracy: 0.5882 - val_loss: 1.1669\n",
      "Epoch 18/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 133ms/step - accuracy: 0.5508 - loss: 1.2736 - val_accuracy: 0.5851 - val_loss: 1.1585\n",
      "Epoch 19/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 132ms/step - accuracy: 0.5509 - loss: 1.2714 - val_accuracy: 0.5956 - val_loss: 1.1398\n",
      "Epoch 20/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 132ms/step - accuracy: 0.5634 - loss: 1.2419 - val_accuracy: 0.5988 - val_loss: 1.1230\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6009 - loss: 1.1188\n",
      "Epoch 1/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 134ms/step - accuracy: 0.1572 - loss: 2.2385 - val_accuracy: 0.3278 - val_loss: 1.9183\n",
      "Epoch 2/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 132ms/step - accuracy: 0.2847 - loss: 1.9324 - val_accuracy: 0.4031 - val_loss: 1.7089\n",
      "Epoch 3/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 133ms/step - accuracy: 0.3357 - loss: 1.8081 - val_accuracy: 0.4403 - val_loss: 1.6014\n",
      "Epoch 4/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 133ms/step - accuracy: 0.3828 - loss: 1.7012 - val_accuracy: 0.4693 - val_loss: 1.5250\n",
      "Epoch 5/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 133ms/step - accuracy: 0.4117 - loss: 1.6345 - val_accuracy: 0.4853 - val_loss: 1.4699\n",
      "Epoch 6/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 133ms/step - accuracy: 0.4286 - loss: 1.5925 - val_accuracy: 0.4955 - val_loss: 1.4261\n",
      "Epoch 7/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 131ms/step - accuracy: 0.4455 - loss: 1.5409 - val_accuracy: 0.5140 - val_loss: 1.3842\n",
      "Epoch 8/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 129ms/step - accuracy: 0.4597 - loss: 1.4980 - val_accuracy: 0.5262 - val_loss: 1.3611\n",
      "Epoch 9/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 128ms/step - accuracy: 0.4711 - loss: 1.4740 - val_accuracy: 0.5420 - val_loss: 1.3226\n",
      "Epoch 10/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 129ms/step - accuracy: 0.4826 - loss: 1.4421 - val_accuracy: 0.5367 - val_loss: 1.2957\n",
      "Epoch 11/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 128ms/step - accuracy: 0.4925 - loss: 1.4159 - val_accuracy: 0.5509 - val_loss: 1.2704\n",
      "Epoch 12/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 128ms/step - accuracy: 0.5012 - loss: 1.4022 - val_accuracy: 0.5553 - val_loss: 1.2534\n",
      "Epoch 13/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 128ms/step - accuracy: 0.5038 - loss: 1.3818 - val_accuracy: 0.5565 - val_loss: 1.2528\n",
      "Epoch 14/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 128ms/step - accuracy: 0.5212 - loss: 1.3543 - val_accuracy: 0.5657 - val_loss: 1.2318\n",
      "Epoch 15/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 129ms/step - accuracy: 0.5244 - loss: 1.3273 - val_accuracy: 0.5706 - val_loss: 1.2231\n",
      "Epoch 16/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 129ms/step - accuracy: 0.5254 - loss: 1.3262 - val_accuracy: 0.5827 - val_loss: 1.1879\n",
      "Epoch 17/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 129ms/step - accuracy: 0.5342 - loss: 1.3111 - val_accuracy: 0.5817 - val_loss: 1.1818\n",
      "Epoch 18/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 128ms/step - accuracy: 0.5452 - loss: 1.2876 - val_accuracy: 0.5893 - val_loss: 1.1730\n",
      "Epoch 19/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 128ms/step - accuracy: 0.5502 - loss: 1.2774 - val_accuracy: 0.5912 - val_loss: 1.1515\n",
      "Epoch 20/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 128ms/step - accuracy: 0.5495 - loss: 1.2625 - val_accuracy: 0.5995 - val_loss: 1.1379\n",
      "Epoch 21/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 129ms/step - accuracy: 0.5607 - loss: 1.2429 - val_accuracy: 0.6014 - val_loss: 1.1312\n",
      "Epoch 22/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 129ms/step - accuracy: 0.5624 - loss: 1.2269 - val_accuracy: 0.6041 - val_loss: 1.1220\n",
      "Epoch 23/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 134ms/step - accuracy: 0.5691 - loss: 1.2243 - val_accuracy: 0.6149 - val_loss: 1.1009\n",
      "Epoch 24/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 133ms/step - accuracy: 0.5732 - loss: 1.2208 - val_accuracy: 0.6089 - val_loss: 1.1074\n",
      "Epoch 25/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 132ms/step - accuracy: 0.5775 - loss: 1.1951 - val_accuracy: 0.6238 - val_loss: 1.0734\n",
      "Epoch 26/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 132ms/step - accuracy: 0.5809 - loss: 1.1894 - val_accuracy: 0.6219 - val_loss: 1.0786\n",
      "Epoch 27/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 133ms/step - accuracy: 0.5879 - loss: 1.1706 - val_accuracy: 0.6256 - val_loss: 1.0697\n",
      "Epoch 28/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 133ms/step - accuracy: 0.5886 - loss: 1.1726 - val_accuracy: 0.6226 - val_loss: 1.0621\n",
      "Epoch 29/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 133ms/step - accuracy: 0.5931 - loss: 1.1606 - val_accuracy: 0.6314 - val_loss: 1.0411\n",
      "Epoch 30/30\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 133ms/step - accuracy: 0.5982 - loss: 1.1400 - val_accuracy: 0.6386 - val_loss: 1.0311\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6416 - loss: 1.0229\n",
      "Epoch 1/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 134ms/step - accuracy: 0.1539 - loss: 2.2366 - val_accuracy: 0.3279 - val_loss: 1.8925\n",
      "Epoch 2/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 132ms/step - accuracy: 0.2853 - loss: 1.9380 - val_accuracy: 0.3876 - val_loss: 1.7549\n",
      "Epoch 3/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 133ms/step - accuracy: 0.3342 - loss: 1.8222 - val_accuracy: 0.4203 - val_loss: 1.6433\n",
      "Epoch 4/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 133ms/step - accuracy: 0.3632 - loss: 1.7429 - val_accuracy: 0.4378 - val_loss: 1.5911\n",
      "Epoch 5/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 133ms/step - accuracy: 0.3846 - loss: 1.6905 - val_accuracy: 0.4655 - val_loss: 1.5118\n",
      "Epoch 6/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 133ms/step - accuracy: 0.4126 - loss: 1.6243 - val_accuracy: 0.4856 - val_loss: 1.4593\n",
      "Epoch 7/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 132ms/step - accuracy: 0.4327 - loss: 1.5684 - val_accuracy: 0.4986 - val_loss: 1.4118\n",
      "Epoch 8/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 133ms/step - accuracy: 0.4474 - loss: 1.5308 - val_accuracy: 0.5120 - val_loss: 1.3721\n",
      "Epoch 9/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 133ms/step - accuracy: 0.4586 - loss: 1.4940 - val_accuracy: 0.5221 - val_loss: 1.3383\n",
      "Epoch 10/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 133ms/step - accuracy: 0.4728 - loss: 1.4637 - val_accuracy: 0.5315 - val_loss: 1.3149\n",
      "Epoch 11/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 133ms/step - accuracy: 0.4890 - loss: 1.4262 - val_accuracy: 0.5444 - val_loss: 1.2832\n",
      "Epoch 12/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 134ms/step - accuracy: 0.4992 - loss: 1.3960 - val_accuracy: 0.5557 - val_loss: 1.2488\n",
      "Epoch 13/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 134ms/step - accuracy: 0.5052 - loss: 1.3894 - val_accuracy: 0.5523 - val_loss: 1.2449\n",
      "Epoch 14/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 133ms/step - accuracy: 0.5148 - loss: 1.3571 - val_accuracy: 0.5641 - val_loss: 1.2222\n",
      "Epoch 15/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 132ms/step - accuracy: 0.5224 - loss: 1.3404 - val_accuracy: 0.5698 - val_loss: 1.2016\n",
      "Epoch 16/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 139ms/step - accuracy: 0.5270 - loss: 1.3281 - val_accuracy: 0.5841 - val_loss: 1.1807\n",
      "Epoch 17/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 134ms/step - accuracy: 0.5377 - loss: 1.3088 - val_accuracy: 0.5876 - val_loss: 1.1692\n",
      "Epoch 18/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 126ms/step - accuracy: 0.5429 - loss: 1.2850 - val_accuracy: 0.5923 - val_loss: 1.1609\n",
      "Epoch 19/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 126ms/step - accuracy: 0.5505 - loss: 1.2678 - val_accuracy: 0.5900 - val_loss: 1.1601\n",
      "Epoch 20/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 127ms/step - accuracy: 0.5534 - loss: 1.2640 - val_accuracy: 0.5967 - val_loss: 1.1339\n",
      "Epoch 21/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 127ms/step - accuracy: 0.5614 - loss: 1.2445 - val_accuracy: 0.6011 - val_loss: 1.1312\n",
      "Epoch 22/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 127ms/step - accuracy: 0.5687 - loss: 1.2241 - val_accuracy: 0.6134 - val_loss: 1.1060\n",
      "Epoch 23/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 127ms/step - accuracy: 0.5730 - loss: 1.2148 - val_accuracy: 0.6100 - val_loss: 1.1101\n",
      "Epoch 24/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 127ms/step - accuracy: 0.5704 - loss: 1.2179 - val_accuracy: 0.6161 - val_loss: 1.0944\n",
      "Epoch 25/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 126ms/step - accuracy: 0.5758 - loss: 1.2124 - val_accuracy: 0.6160 - val_loss: 1.0957\n",
      "Epoch 26/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 127ms/step - accuracy: 0.5812 - loss: 1.1933 - val_accuracy: 0.6242 - val_loss: 1.0702\n",
      "Epoch 27/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 127ms/step - accuracy: 0.5830 - loss: 1.1831 - val_accuracy: 0.6269 - val_loss: 1.0667\n",
      "Epoch 28/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 127ms/step - accuracy: 0.5933 - loss: 1.1665 - val_accuracy: 0.6320 - val_loss: 1.0495\n",
      "Epoch 29/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 126ms/step - accuracy: 0.5918 - loss: 1.1538 - val_accuracy: 0.6353 - val_loss: 1.0408\n",
      "Epoch 30/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 128ms/step - accuracy: 0.5973 - loss: 1.1535 - val_accuracy: 0.6370 - val_loss: 1.0387\n",
      "Epoch 31/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 127ms/step - accuracy: 0.6049 - loss: 1.1356 - val_accuracy: 0.6192 - val_loss: 1.0907\n",
      "Epoch 32/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 128ms/step - accuracy: 0.6006 - loss: 1.1383 - val_accuracy: 0.6410 - val_loss: 1.0212\n",
      "Epoch 33/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 127ms/step - accuracy: 0.6079 - loss: 1.1255 - val_accuracy: 0.6447 - val_loss: 1.0175\n",
      "Epoch 34/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 132ms/step - accuracy: 0.6092 - loss: 1.1137 - val_accuracy: 0.6231 - val_loss: 1.0580\n",
      "Epoch 35/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 140ms/step - accuracy: 0.6101 - loss: 1.1162 - val_accuracy: 0.6481 - val_loss: 1.0025\n",
      "Epoch 36/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 136ms/step - accuracy: 0.6173 - loss: 1.0944 - val_accuracy: 0.6508 - val_loss: 1.0001\n",
      "Epoch 37/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 136ms/step - accuracy: 0.6250 - loss: 1.0832 - val_accuracy: 0.6533 - val_loss: 0.9987\n",
      "Epoch 38/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 135ms/step - accuracy: 0.6214 - loss: 1.0813 - val_accuracy: 0.6570 - val_loss: 0.9797\n",
      "Epoch 39/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 134ms/step - accuracy: 0.6208 - loss: 1.0799 - val_accuracy: 0.6633 - val_loss: 0.9712\n",
      "Epoch 40/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 136ms/step - accuracy: 0.6296 - loss: 1.0642 - val_accuracy: 0.6629 - val_loss: 0.9676\n",
      "Epoch 41/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 136ms/step - accuracy: 0.6306 - loss: 1.0519 - val_accuracy: 0.6530 - val_loss: 0.9792\n",
      "Epoch 42/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 135ms/step - accuracy: 0.6276 - loss: 1.0605 - val_accuracy: 0.6633 - val_loss: 0.9662\n",
      "Epoch 43/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 135ms/step - accuracy: 0.6354 - loss: 1.0483 - val_accuracy: 0.6631 - val_loss: 0.9609\n",
      "Epoch 44/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 136ms/step - accuracy: 0.6376 - loss: 1.0386 - val_accuracy: 0.6684 - val_loss: 0.9429\n",
      "Epoch 45/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 135ms/step - accuracy: 0.6423 - loss: 1.0240 - val_accuracy: 0.6737 - val_loss: 0.9378\n",
      "Epoch 46/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 136ms/step - accuracy: 0.6416 - loss: 1.0265 - val_accuracy: 0.6665 - val_loss: 0.9457\n",
      "Epoch 47/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 136ms/step - accuracy: 0.6426 - loss: 1.0150 - val_accuracy: 0.6729 - val_loss: 0.9354\n",
      "Epoch 48/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 136ms/step - accuracy: 0.6466 - loss: 1.0105 - val_accuracy: 0.6766 - val_loss: 0.9285\n",
      "Epoch 49/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 135ms/step - accuracy: 0.6491 - loss: 1.0070 - val_accuracy: 0.6677 - val_loss: 0.9429\n",
      "Epoch 50/50\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 136ms/step - accuracy: 0.6526 - loss: 0.9948 - val_accuracy: 0.6816 - val_loss: 0.9216\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6849 - loss: 0.9103\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 19ms/step - accuracy: 0.2737 - loss: 1.9261 - val_accuracy: 0.5280 - val_loss: 1.2891\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.5167 - loss: 1.3518 - val_accuracy: 0.6095 - val_loss: 1.1103\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.5944 - loss: 1.1409 - val_accuracy: 0.6472 - val_loss: 1.0002\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.6483 - loss: 1.0093 - val_accuracy: 0.6815 - val_loss: 0.9285\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 21ms/step - accuracy: 0.6746 - loss: 0.9346 - val_accuracy: 0.6899 - val_loss: 0.9064\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.7024 - loss: 0.8671 - val_accuracy: 0.7017 - val_loss: 0.8632\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 19ms/step - accuracy: 0.7127 - loss: 0.8328 - val_accuracy: 0.7157 - val_loss: 0.8375\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.7305 - loss: 0.7829 - val_accuracy: 0.7246 - val_loss: 0.8168\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.7430 - loss: 0.7400 - val_accuracy: 0.7293 - val_loss: 0.7957\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.7546 - loss: 0.7071 - val_accuracy: 0.7263 - val_loss: 0.8146\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7268 - loss: 0.8069\n",
      "Epoch 1/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.2954 - loss: 1.8958 - val_accuracy: 0.5336 - val_loss: 1.2881\n",
      "Epoch 2/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.5231 - loss: 1.3347 - val_accuracy: 0.6140 - val_loss: 1.0937\n",
      "Epoch 3/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.6040 - loss: 1.1356 - val_accuracy: 0.6569 - val_loss: 0.9568\n",
      "Epoch 4/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - accuracy: 0.6548 - loss: 0.9945 - val_accuracy: 0.6853 - val_loss: 0.8923\n",
      "Epoch 5/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.6831 - loss: 0.9210 - val_accuracy: 0.6979 - val_loss: 0.8748\n",
      "Epoch 6/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.7012 - loss: 0.8611 - val_accuracy: 0.7116 - val_loss: 0.8455\n",
      "Epoch 7/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.7189 - loss: 0.8072 - val_accuracy: 0.7234 - val_loss: 0.8116\n",
      "Epoch 8/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.7356 - loss: 0.7677 - val_accuracy: 0.7300 - val_loss: 0.7865\n",
      "Epoch 9/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.7439 - loss: 0.7408 - val_accuracy: 0.7317 - val_loss: 0.7858\n",
      "Epoch 10/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.7523 - loss: 0.7072 - val_accuracy: 0.7329 - val_loss: 0.7821\n",
      "Epoch 11/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.7620 - loss: 0.6821 - val_accuracy: 0.7382 - val_loss: 0.8081\n",
      "Epoch 12/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.7676 - loss: 0.6595 - val_accuracy: 0.7482 - val_loss: 0.7640\n",
      "Epoch 13/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.7787 - loss: 0.6285 - val_accuracy: 0.7330 - val_loss: 0.8271\n",
      "Epoch 14/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.7914 - loss: 0.5987 - val_accuracy: 0.7462 - val_loss: 0.8005\n",
      "Epoch 15/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.7951 - loss: 0.5855 - val_accuracy: 0.7380 - val_loss: 0.8161\n",
      "Epoch 16/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.7971 - loss: 0.5707 - val_accuracy: 0.7432 - val_loss: 0.8249\n",
      "Epoch 17/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.8111 - loss: 0.5321 - val_accuracy: 0.7463 - val_loss: 0.8327\n",
      "Epoch 18/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.8126 - loss: 0.5239 - val_accuracy: 0.7493 - val_loss: 0.8773\n",
      "Epoch 19/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.8153 - loss: 0.5167 - val_accuracy: 0.7507 - val_loss: 0.8333\n",
      "Epoch 20/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.8229 - loss: 0.5026 - val_accuracy: 0.7467 - val_loss: 0.8844\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7499 - loss: 0.8749\n",
      "Epoch 1/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - accuracy: 0.3025 - loss: 1.8654 - val_accuracy: 0.5474 - val_loss: 1.2762\n",
      "Epoch 2/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.5403 - loss: 1.2964 - val_accuracy: 0.6334 - val_loss: 1.0469\n",
      "Epoch 3/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.6062 - loss: 1.1195 - val_accuracy: 0.6628 - val_loss: 0.9754\n",
      "Epoch 4/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.6567 - loss: 0.9964 - val_accuracy: 0.6842 - val_loss: 0.9230\n",
      "Epoch 5/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.6851 - loss: 0.9072 - val_accuracy: 0.7105 - val_loss: 0.8271\n",
      "Epoch 6/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.7112 - loss: 0.8320 - val_accuracy: 0.7129 - val_loss: 0.8315\n",
      "Epoch 7/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.7230 - loss: 0.7957 - val_accuracy: 0.7326 - val_loss: 0.7867\n",
      "Epoch 8/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.7372 - loss: 0.7565 - val_accuracy: 0.7113 - val_loss: 0.8331\n",
      "Epoch 9/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.7475 - loss: 0.7264 - val_accuracy: 0.7388 - val_loss: 0.7702\n",
      "Epoch 10/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.7616 - loss: 0.6850 - val_accuracy: 0.7504 - val_loss: 0.7599\n",
      "Epoch 11/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.7723 - loss: 0.6585 - val_accuracy: 0.7420 - val_loss: 0.7881\n",
      "Epoch 12/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.7807 - loss: 0.6294 - val_accuracy: 0.7447 - val_loss: 0.7842\n",
      "Epoch 13/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.7842 - loss: 0.6059 - val_accuracy: 0.7479 - val_loss: 0.7575\n",
      "Epoch 14/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.7950 - loss: 0.5867 - val_accuracy: 0.7464 - val_loss: 0.8090\n",
      "Epoch 15/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - accuracy: 0.8019 - loss: 0.5744 - val_accuracy: 0.7482 - val_loss: 0.7784\n",
      "Epoch 16/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.8091 - loss: 0.5362 - val_accuracy: 0.7475 - val_loss: 0.8153\n",
      "Epoch 17/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.8130 - loss: 0.5243 - val_accuracy: 0.7568 - val_loss: 0.7786\n",
      "Epoch 18/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.8182 - loss: 0.5133 - val_accuracy: 0.7539 - val_loss: 0.8178\n",
      "Epoch 19/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.8287 - loss: 0.4793 - val_accuracy: 0.7554 - val_loss: 0.8152\n",
      "Epoch 20/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - accuracy: 0.8310 - loss: 0.4833 - val_accuracy: 0.7508 - val_loss: 0.8320\n",
      "Epoch 21/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.8381 - loss: 0.4559 - val_accuracy: 0.7557 - val_loss: 0.8734\n",
      "Epoch 22/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.8390 - loss: 0.4526 - val_accuracy: 0.7512 - val_loss: 0.8738\n",
      "Epoch 23/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.8470 - loss: 0.4359 - val_accuracy: 0.7310 - val_loss: 1.0115\n",
      "Epoch 24/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.8454 - loss: 0.4351 - val_accuracy: 0.7481 - val_loss: 0.9034\n",
      "Epoch 25/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.8500 - loss: 0.4138 - val_accuracy: 0.7494 - val_loss: 0.9440\n",
      "Epoch 26/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.8559 - loss: 0.4017 - val_accuracy: 0.7526 - val_loss: 0.9157\n",
      "Epoch 27/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.8549 - loss: 0.4024 - val_accuracy: 0.7397 - val_loss: 0.9432\n",
      "Epoch 28/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.8616 - loss: 0.3857 - val_accuracy: 0.7503 - val_loss: 1.0044\n",
      "Epoch 29/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.8675 - loss: 0.3729 - val_accuracy: 0.7445 - val_loss: 0.9299\n",
      "Epoch 30/30\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.8657 - loss: 0.3618 - val_accuracy: 0.7489 - val_loss: 0.9890\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7535 - loss: 0.9706\n",
      "Epoch 1/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - accuracy: 0.2914 - loss: 1.8998 - val_accuracy: 0.4964 - val_loss: 1.4160\n",
      "Epoch 2/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.5213 - loss: 1.3259 - val_accuracy: 0.6257 - val_loss: 1.0688\n",
      "Epoch 3/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.6090 - loss: 1.1146 - val_accuracy: 0.6482 - val_loss: 0.9917\n",
      "Epoch 4/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.6535 - loss: 0.9926 - val_accuracy: 0.6839 - val_loss: 0.8976\n",
      "Epoch 5/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.6855 - loss: 0.9066 - val_accuracy: 0.7068 - val_loss: 0.8338\n",
      "Epoch 6/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.7065 - loss: 0.8397 - val_accuracy: 0.7269 - val_loss: 0.7914\n",
      "Epoch 7/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.7323 - loss: 0.7751 - val_accuracy: 0.7150 - val_loss: 0.8404\n",
      "Epoch 8/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.7467 - loss: 0.7367 - val_accuracy: 0.7283 - val_loss: 0.8288\n",
      "Epoch 9/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.7582 - loss: 0.6956 - val_accuracy: 0.7371 - val_loss: 0.7810\n",
      "Epoch 10/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.7726 - loss: 0.6548 - val_accuracy: 0.7484 - val_loss: 0.7627\n",
      "Epoch 11/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.7848 - loss: 0.6197 - val_accuracy: 0.7483 - val_loss: 0.7748\n",
      "Epoch 12/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.7992 - loss: 0.5811 - val_accuracy: 0.7479 - val_loss: 0.7641\n",
      "Epoch 13/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.8006 - loss: 0.5646 - val_accuracy: 0.7501 - val_loss: 0.7723\n",
      "Epoch 14/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.8094 - loss: 0.5382 - val_accuracy: 0.7373 - val_loss: 0.8192\n",
      "Epoch 15/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.8144 - loss: 0.5321 - val_accuracy: 0.7516 - val_loss: 0.8113\n",
      "Epoch 16/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.8225 - loss: 0.5065 - val_accuracy: 0.7444 - val_loss: 0.8412\n",
      "Epoch 17/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.8268 - loss: 0.4908 - val_accuracy: 0.7529 - val_loss: 0.8203\n",
      "Epoch 18/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.8321 - loss: 0.4671 - val_accuracy: 0.7473 - val_loss: 0.8304\n",
      "Epoch 19/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.8431 - loss: 0.4458 - val_accuracy: 0.7479 - val_loss: 0.8650\n",
      "Epoch 20/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.8440 - loss: 0.4345 - val_accuracy: 0.7586 - val_loss: 0.8387\n",
      "Epoch 21/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.8520 - loss: 0.4213 - val_accuracy: 0.7533 - val_loss: 0.8805\n",
      "Epoch 22/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.8529 - loss: 0.4095 - val_accuracy: 0.7574 - val_loss: 0.9278\n",
      "Epoch 23/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.8542 - loss: 0.4025 - val_accuracy: 0.7497 - val_loss: 0.9161\n",
      "Epoch 24/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.8662 - loss: 0.3790 - val_accuracy: 0.7521 - val_loss: 0.9668\n",
      "Epoch 25/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.8642 - loss: 0.3792 - val_accuracy: 0.7594 - val_loss: 0.9504\n",
      "Epoch 26/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - accuracy: 0.8723 - loss: 0.3574 - val_accuracy: 0.7522 - val_loss: 0.9447\n",
      "Epoch 27/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.8716 - loss: 0.3548 - val_accuracy: 0.7583 - val_loss: 1.0186\n",
      "Epoch 28/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.8731 - loss: 0.3494 - val_accuracy: 0.7583 - val_loss: 1.0095\n",
      "Epoch 29/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.8793 - loss: 0.3381 - val_accuracy: 0.7514 - val_loss: 0.9671\n",
      "Epoch 30/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.8826 - loss: 0.3291 - val_accuracy: 0.7460 - val_loss: 1.1111\n",
      "Epoch 31/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.8842 - loss: 0.3210 - val_accuracy: 0.7543 - val_loss: 0.9999\n",
      "Epoch 32/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.8890 - loss: 0.3119 - val_accuracy: 0.7452 - val_loss: 1.0918\n",
      "Epoch 33/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.8907 - loss: 0.3099 - val_accuracy: 0.7536 - val_loss: 1.1759\n",
      "Epoch 34/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.8888 - loss: 0.3076 - val_accuracy: 0.7519 - val_loss: 1.1270\n",
      "Epoch 35/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.8923 - loss: 0.2991 - val_accuracy: 0.7512 - val_loss: 1.1974\n",
      "Epoch 36/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.8924 - loss: 0.3026 - val_accuracy: 0.7528 - val_loss: 1.2048\n",
      "Epoch 37/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.8996 - loss: 0.2754 - val_accuracy: 0.7533 - val_loss: 1.1431\n",
      "Epoch 38/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.8987 - loss: 0.2780 - val_accuracy: 0.7566 - val_loss: 1.1241\n",
      "Epoch 39/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.8969 - loss: 0.2873 - val_accuracy: 0.7580 - val_loss: 1.2139\n",
      "Epoch 40/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.8997 - loss: 0.2714 - val_accuracy: 0.7525 - val_loss: 1.2050\n",
      "Epoch 41/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9038 - loss: 0.2668 - val_accuracy: 0.7514 - val_loss: 1.2666\n",
      "Epoch 42/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9104 - loss: 0.2544 - val_accuracy: 0.7557 - val_loss: 1.2545\n",
      "Epoch 43/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9109 - loss: 0.2514 - val_accuracy: 0.7470 - val_loss: 1.2911\n",
      "Epoch 44/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9045 - loss: 0.2667 - val_accuracy: 0.7497 - val_loss: 1.3249\n",
      "Epoch 45/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9095 - loss: 0.2546 - val_accuracy: 0.7591 - val_loss: 1.2903\n",
      "Epoch 46/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9155 - loss: 0.2443 - val_accuracy: 0.7553 - val_loss: 1.3199\n",
      "Epoch 47/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9083 - loss: 0.2582 - val_accuracy: 0.7457 - val_loss: 1.3058\n",
      "Epoch 48/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9164 - loss: 0.2337 - val_accuracy: 0.7526 - val_loss: 1.3721\n",
      "Epoch 49/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9153 - loss: 0.2461 - val_accuracy: 0.7537 - val_loss: 1.3965\n",
      "Epoch 50/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9143 - loss: 0.2357 - val_accuracy: 0.7501 - val_loss: 1.3501\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7504 - loss: 1.3371\n",
      "Epoch 1/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 36ms/step - accuracy: 0.2745 - loss: 1.9355 - val_accuracy: 0.5134 - val_loss: 1.3387\n",
      "Epoch 2/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.5003 - loss: 1.3868 - val_accuracy: 0.6043 - val_loss: 1.1109\n",
      "Epoch 3/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.5805 - loss: 1.1775 - val_accuracy: 0.6487 - val_loss: 0.9940\n",
      "Epoch 4/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.6375 - loss: 1.0438 - val_accuracy: 0.6833 - val_loss: 0.9063\n",
      "Epoch 5/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 38ms/step - accuracy: 0.6673 - loss: 0.9598 - val_accuracy: 0.6940 - val_loss: 0.8840\n",
      "Epoch 6/10\n",
      "\u001b[1m 17/782\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 49ms/step - accuracy: 0.6726 - loss: 0.9251"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m epochs:\n\u001b[1;32m      7\u001b[0m     model \u001b[38;5;241m=\u001b[39m create_model(lr)\n\u001b[0;32m----> 8\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     _, test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(x_test, y_test)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m test_acc \u001b[38;5;241m>\u001b[39m best_acc:\n",
      "File \u001b[0;32m~/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m~/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/Documents/Github/practical-nlp-code-personal/.conda/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Realizar una búsqueda en cuadrícula de hiperparámetros\n",
    "best_acc = 0\n",
    "best_params = None\n",
    "for lr in learning_rates:\n",
    "    for bs in batch_sizes:\n",
    "        for ep in epochs:\n",
    "            model = create_model(lr)\n",
    "            history = model.fit(x_train, y_train, \n",
    "                                batch_size=bs, epochs=ep, \n",
    "                                validation_data=(x_test, y_test))\n",
    "            _, test_acc = model.evaluate(x_test, y_test)\n",
    "            if test_acc > best_acc:\n",
    "                best_acc = test_acc\n",
    "                best_params = (lr, bs, ep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best accuracy:', best_acc)\n",
    "print('Best parameters:', best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los mejores resultados se obtienen con una tasa de aprendizaje de 0.001, tamaño de lote de 128 y 30 épocas de entrenamiento, alcanzando una precisión de 76.49% en el conjunto de prueba. Esto representa una mejora de casi 11 puntos porcentuales respecto al modelo base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento 4: Técnicas Avanzadas (Batch Normalization)\n",
    "En esta parte se decidio implementar la Normalización por Lotes o Batch Normalization la cual en teoria, ayudaría a mejorar el rendimiento del modelo al normalizar las activaciones en cada lote durante el entrenamiento, lo que permitiría que el modelo converja más rápido y sea más estable. Esto se traduce en una mayor capacidad de generalización y precisión en la tarea de clasificación de imágenes.\n",
    "\n",
    "Una vez explicado ello implementó la técnica de Batch Normalization en el modelo de CNN. La Normalización por Lotes es una técnica que ayuda a acelerar y estabilizar el entrenamiento de redes neuronales profundas al normalizar las activaciones de cada capa.\n",
    "Se modificó la arquitectura del modelo agregando capas de BatchNormalization en la primera y tercera capa, asi para encontrar un equilibrio entre los beneficios de la normalización y el costo computacional adicional que implica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define un modelo con Normalización por lotes (Batch Normalization)\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "model_bn = Sequential(\n",
    "    [\n",
    "        Conv2D(32, (3, 3), activation=\"relu\", input_shape=(32, 32, 3)),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        Flatten(),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo se compiló utilizando el optimizador Adam con una tasa de aprendizaje de 0.001, la función de pérdida categorical crossentropy y se midió la precisión como métrica. Se entrenó por 30 épocas con un tamaño de lote de 128, los cuales son los valores que en el experimento 3 dieron mejores resultados a la hora de entrenar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar y entrenar el modelo\n",
    "model_bn.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history_bn = model_bn.fit(\n",
    "    x_train, y_train, batch_size=128, epochs=30, validation_data=(x_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo modificado en el conjunto de test\n",
    "test_loss_bn, test_acc_bn = model_bn.evaluate(x_test, y_test)\n",
    "print('Test accuracy (modelo Batch Normalization):', test_acc_bn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo tuvo una precisión de 77.50%, este comprueba que efectivamente, de ser aplicados de manera correcta las técnicas avanzadas pueden ayudar a mejorar la precisión de los modelos construidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados y Discusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los experimentos realizados demuestran que tanto la arquitectura como los hiperparámetros tienen un impacto significativo en el rendimiento de las CNNs para la clasificación de imágenes.\n",
    "\n",
    "Agregar más capas convolucionales, aumentar el número de filtros y aplicar ciertas técnicas permite al modelo aprender características más complejas y discriminativas. La capa de dropout ayuda a reducir el sobreajuste, mejorando la capacidad de generalización. Por otro lado, ajustar hiperparámetros como la tasa de aprendizaje, el tamaño de lote y el número de épocas es crucial para encontrar la configuración óptima que permita al modelo converger adecuadamente y obtener un buen desempeño.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se demostró que realizar cambios en la arquitectura, como agregar más capas convolucionales, aumentar el número de filtros e incluir dropout, así como ajustar hiperparámetros clave como la tasa de aprendizaje, el tamaño de lote y el número de épocas, permite mejorar significativamente la precisión del modelo base.\n",
    "\n",
    "Los resultados obtenidos resaltan la importancia de experimentar con diferentes configuraciones al construir modelos de CNNs para obtener un buen desempeño en tareas de visión por computadora. Como trabajo futuro, se podrían explorar técnicas adicionales y arquitecturas más avanzadas para seguir mejorando la capacidad de clasificación de imágenes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " cifar10. (n.d.). TensorFlow. https://www.tensorflow.org/datasets/catalog/cifar10\n",
    " \n",
    " Krizhevsky, A., & Hinton, G. (2009). Learning multiple layers of features from tiny images. https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf\n",
    "\n",
    " Chollet, F. (2018). Deep learning with Python. Simon and Schuster. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
